{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook includes toy examples to demonstrate how to tune User Defined Functions with `flaml.tune`.\n",
    "\n",
    "FLAML requires `Python>=3.7`. To run this notebook example, please install flaml with the `notebook` option:\n",
    "```bash\n",
    "pip install flaml[notebook]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flaml[notebook]\n",
    "# from v0.6.6, catboost is made an optional dependency to build conda package.\n",
    "# to install catboost without installing the notebook option, you can run:\n",
    "# %pip install flaml[catboost]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tuning procedure\n",
    "## 1. A basic tuning example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set a search space'''\n",
    "from flaml import tune\n",
    "config_search_space = {\n",
    "    \"x\": tune.lograndint(lower=1, upper=100000),\n",
    "    \"y\": tune.randint(lower=1, upper=100000)\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Write a evaluation function'''\n",
    "import time\n",
    "def evaluate_config(config: dict):\n",
    "    \"\"\"evaluate a hyperparameter configuration\"\"\"\n",
    "    score = (config[\"x\"] - 85000) ** 2 - config[\"x\"] / config[\"y\"]\n",
    "    # usually the evaluation takes an non-neglible cost\n",
    "    # and the cost could be related to certain hyperparameters\n",
    "    # here we simulate this cost by calling the time.sleep() function\n",
    "    # here we assume the cost is proportional to x\n",
    "    faked_evaluation_cost = config[\"x\"] / 100000\n",
    "    time.sleep(faked_evaluation_cost)\n",
    "    # we can return a single float as a score on the input config:\n",
    "    # return score\n",
    "    # or, we can return a dictionary that maps metric name to metric value:\n",
    "    return {\"score\": score, \"evaluation_cost\": faked_evaluation_cost, \"constraint_metric\": config[\"x\"] * config[\"y\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-08-19 14:40:13,268]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 08-19 14:40:13] {506} INFO - trial 1 config: {'x': 3, 'y': 13184}\n",
      "[flaml.tune.tune: 08-19 14:40:13] {506} INFO - trial 2 config: {'x': 6134, 'y': 2076}\n",
      "[flaml.tune.tune: 08-19 14:40:13] {506} INFO - trial 3 config: {'x': 1143, 'y': 74880}\n",
      "[flaml.tune.tune: 08-19 14:40:13] {506} INFO - trial 4 config: {'x': 5539, 'y': 1}\n",
      "[flaml.tune.tune: 08-19 14:40:13] {506} INFO - trial 5 config: {'x': 6793, 'y': 16190}\n",
      "[flaml.tune.tune: 08-19 14:40:13] {506} INFO - trial 6 config: {'x': 220, 'y': 22480}\n",
      "[flaml.tune.tune: 08-19 14:40:13] {506} INFO - trial 7 config: {'x': 6, 'y': 76053}\n",
      "[flaml.tune.tune: 08-19 14:40:13] {506} INFO - trial 8 config: {'x': 4, 'y': 8834}\n",
      "[flaml.tune.tune: 08-19 14:40:13] {506} INFO - trial 9 config: {'x': 2148, 'y': 95339}\n",
      "[flaml.tune.tune: 08-19 14:40:13] {506} INFO - trial 10 config: {'x': 1, 'y': 51219}\n",
      "[flaml.tune.tune: 08-19 14:40:13] {506} INFO - trial 11 config: {'x': 10155, 'y': 61252}\n",
      "[flaml.tune.tune: 08-19 14:40:13] {506} INFO - trial 12 config: {'x': 51672, 'y': 61799}\n",
      "[flaml.tune.tune: 08-19 14:40:14] {506} INFO - trial 13 config: {'x': 18407, 'y': 72736}\n",
      "[flaml.tune.tune: 08-19 14:40:14] {506} INFO - trial 14 config: {'x': 99999, 'y': 50862}\n",
      "[flaml.tune.tune: 08-19 14:40:15] {506} INFO - trial 15 config: {'x': 2, 'y': 372}\n",
      "[flaml.tune.tune: 08-19 14:40:15] {506} INFO - trial 16 config: {'x': 99999, 'y': 39100}\n",
      "[flaml.tune.tune: 08-19 14:40:16] {506} INFO - trial 17 config: {'x': 40494, 'y': 50862}\n",
      "[flaml.tune.tune: 08-19 14:40:16] {506} INFO - trial 18 config: {'x': 60615, 'y': 25643}\n",
      "[flaml.tune.tune: 08-19 14:40:17] {506} INFO - trial 19 config: {'x': 99999, 'y': 52557}\n",
      "[flaml.tune.tune: 08-19 14:40:18] {506} INFO - trial 20 config: {'x': 3350, 'y': 29188}\n",
      "[flaml.tune.tune: 08-19 14:40:18] {506} INFO - trial 21 config: {'x': 6, 'y': 25996}\n",
      "[flaml.tune.tune: 08-19 14:40:18] {506} INFO - trial 22 config: {'x': 36654, 'y': 71457}\n",
      "[flaml.tune.tune: 08-19 14:40:18] {506} INFO - trial 23 config: {'x': 376, 'y': 14217}\n",
      "[flaml.tune.tune: 08-19 14:40:18] {506} INFO - trial 24 config: {'x': 99999, 'y': 64368}\n",
      "[flaml.tune.tune: 08-19 14:40:19] {506} INFO - trial 25 config: {'x': 51439, 'y': 97709}\n",
      "[flaml.tune.tune: 08-19 14:40:20] {506} INFO - trial 26 config: {'x': 24442, 'y': 71457}\n",
      "[flaml.tune.tune: 08-19 14:40:20] {506} INFO - trial 27 config: {'x': 60949, 'y': 50896}\n",
      "[flaml.tune.tune: 08-19 14:40:21] {506} INFO - trial 28 config: {'x': 73238, 'y': 99999}\n",
      "[flaml.tune.tune: 08-19 14:40:21] {506} INFO - trial 29 config: {'x': 51439, 'y': 86194}\n",
      "[flaml.tune.tune: 08-19 14:40:22] {506} INFO - trial 30 config: {'x': 99999, 'y': 77840}\n"
     ]
    }
   ],
   "source": [
    "''''Performs tuning'''\n",
    "# require: pip install flaml[blendsearch]\n",
    "analysis = tune.run(\n",
    "    evaluate_config,  # the function to evaluate a config\n",
    "    config=config_search_space,  # the search space defined\n",
    "    metric=\"score\",\n",
    "    mode=\"min\",  # the optimization mode, \"min\" or \"max\"\n",
    "    num_samples=-1,  # the maximal number of configs to try, -1 means infinite\n",
    "    time_budget_s=10,  # the time budget in seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 138344643.26761267, 'evaluation_cost': 0.73238, 'constraint_metric': 7323726762, 'training_iteration': 0, 'config': {'x': 73238, 'y': 99999}, 'config/x': 73238, 'config/y': 99999, 'experiment_tag': 'exp', 'time_total_s': 0.7341301441192627}\n"
     ]
    }
   ],
   "source": [
    "'''Investigate results'''\n",
    "print(analysis.best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(analysis.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical search space \n",
    "Hierarchical search space is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set a hierarchical search space'''\n",
    "from flaml import tune\n",
    "gbtree_hp_space = {\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"n_estimators\": tune.lograndint(lower=4, upper=64),\n",
    "        \"max_leaves\": tune.lograndint(lower=4, upper=64),\n",
    "        \"learning_rate\": tune.loguniform(lower=1 / 1024, upper=1.0),\n",
    "    }\n",
    "gblinear_hp_space = {\n",
    "    \"booster\": \"gblinear\",\n",
    "    \"lambda\": tune.uniform(0, 1),\n",
    "    \"alpha\": tune.loguniform(0.0001, 1),\n",
    "}\n",
    "\n",
    "full_space = {\n",
    "    \"xgb_config\": tune.choice([gbtree_hp_space, gblinear_hp_space]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Write a evaluation function'''\n",
    "import xgboost as xgb\n",
    "def xgb_obj(X_train, X_test, y_train, y_test, config):\n",
    "    config = config[\"xgb_config\"]\n",
    "    params = config2params(config)\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    booster_type = config.get(\"booster\")\n",
    "\n",
    "    if booster_type == \"gblinear\":\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "        )\n",
    "    else:\n",
    "        _n_estimators = params.pop(\"n_estimators\")\n",
    "        model = xgb.train(params, dtrain, _n_estimators)\n",
    "\n",
    "    # get validation loss\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    y_test_predict = model.predict(dtest)\n",
    "    test_loss = 1.0 - r2_score(y_test, y_test_predict)\n",
    "    return {\"loss\": test_loss}\n",
    "\n",
    "def config2params(config: dict) -> dict:\n",
    "    params = config.copy()\n",
    "    max_depth = params[\"max_depth\"] = params.get(\"max_depth\", 0)\n",
    "    if max_depth == 0:\n",
    "        params[\"grow_policy\"] = params.get(\"grow_policy\", \"lossguide\")\n",
    "        params[\"tree_method\"] = params.get(\"tree_method\", \"hist\")\n",
    "    # params[\"booster\"] = params.get(\"booster\", \"gbtree\")\n",
    "    params[\"use_label_encoder\"] = params.get(\"use_label_encoder\", False)\n",
    "    if \"n_jobs\" in config:\n",
    "        params[\"nthread\"] = params.pop(\"n_jobs\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-19 14:40:24,252]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 08-19 14:40:24] {506} INFO - trial 1 config: {'xgb_config': {'booster': 'gblinear', 'lambda': 0.6472660813321921, 'alpha': 0.0028264214081400044}}\n",
      "[flaml.tune.tune: 08-19 14:40:24] {506} INFO - trial 2 config: {'xgb_config': {'n_estimators': 22, 'max_leaves': 31, 'learning_rate': 0.0309282737630552, 'booster': 'gbtree'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset from ./openml_ds537.pkl\n",
      "Dataset name: houses\n",
      "X_train.shape: (15480, 8), y_train.shape: (15480,);\n",
      "X_test.shape: (5160, 8), y_test.shape: (5160,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 08-19 14:40:24] {506} INFO - trial 3 config: {'xgb_config': {'n_estimators': 32, 'max_leaves': 6, 'learning_rate': 0.0018014797394283806, 'booster': 'gbtree'}}\n",
      "[flaml.tune.tune: 08-19 14:40:24] {506} INFO - trial 4 config: {'xgb_config': {'lambda': 0.003948266327914451, 'alpha': 0.011188427539040417, 'booster': 'gblinear'}}\n",
      "[flaml.tune.tune: 08-19 14:40:24] {506} INFO - trial 5 config: {'xgb_config': {'n_estimators': 28, 'max_leaves': 8, 'learning_rate': 0.5655557791092936, 'booster': 'gbtree'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis {'dbf6ef12': {'loss': 0.5530998765438139, 'training_iteration': 0, 'config': {'xgb_config': {'booster': 'gblinear', 'lambda': 0.6472660813321921, 'alpha': 0.0028264214081400044}}, 'config/xgb_config': {'booster': 'gblinear', 'lambda': 0.6472660813321921, 'alpha': 0.0028264214081400044}, 'experiment_tag': 'exp', 'time_total_s': 0.07804250717163086}, 'dc032020': {'loss': 1.289694461478887, 'training_iteration': 0, 'config': {'xgb_config': {'n_estimators': 22, 'max_leaves': 31, 'learning_rate': 0.0309282737630552, 'booster': 'gbtree'}}, 'config/xgb_config': {'n_estimators': 22, 'max_leaves': 31, 'learning_rate': 0.0309282737630552, 'booster': 'gbtree'}, 'experiment_tag': 'exp', 'time_total_s': 0.22603940963745117}, 'dc25db7e': {'loss': 3.7816208622407053, 'training_iteration': 0, 'config': {'xgb_config': {'n_estimators': 32, 'max_leaves': 6, 'learning_rate': 0.0018014797394283806, 'booster': 'gbtree'}}, 'config/xgb_config': {'n_estimators': 32, 'max_leaves': 6, 'learning_rate': 0.0018014797394283806, 'booster': 'gbtree'}, 'experiment_tag': 'exp', 'time_total_s': 0.11999368667602539}, 'dc386712': {'loss': 0.5397436046686308, 'training_iteration': 0, 'config': {'xgb_config': {'lambda': 0.003948266327914451, 'alpha': 0.011188427539040417, 'booster': 'gblinear'}}, 'config/xgb_config': {'lambda': 0.003948266327914451, 'alpha': 0.011188427539040417, 'booster': 'gblinear'}, 'experiment_tag': 'exp', 'time_total_s': 0.05386686325073242}, 'dc40e536': {'loss': 0.2125826916163286, 'training_iteration': 0, 'config': {'xgb_config': {'n_estimators': 28, 'max_leaves': 8, 'learning_rate': 0.5655557791092936, 'booster': 'gbtree'}}, 'config/xgb_config': {'n_estimators': 28, 'max_leaves': 8, 'learning_rate': 0.5655557791092936, 'booster': 'gbtree'}, 'experiment_tag': 'exp', 'time_total_s': 0.11592411994934082}}\n"
     ]
    }
   ],
   "source": [
    "'''Tune xgb_obj with configs from the hierarchical search space'''\n",
    "from flaml.data import load_openml_dataset\n",
    "from functools import partial\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_openml_dataset(\n",
    "    dataset_id=537, data_dir=\"./\"\n",
    ")\n",
    "analysis = tune.run(\n",
    "    partial(xgb_obj, X_train, X_test, y_train, y_test),\n",
    "    config=full_space,\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    num_samples=5,\n",
    ")\n",
    "print(\"analysis\", analysis.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Tuning Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Constraints on the tuning\n",
    "\n",
    "1. A user can specify constraints on the configurations to be satisfied via the argument `config_constraints`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-08-19 14:40:24,934]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 08-19 14:40:24] {506} INFO - trial 1 config: {'width': 1, 'height': 132, 'length': 647}\n",
      "[flaml.tune.tune: 08-19 14:40:24] {506} INFO - trial 2 config: {'width': 2, 'height': 760, 'length': 169}\n",
      "[flaml.tune.tune: 08-19 14:40:24] {506} INFO - trial 3 config: {'width': 1, 'height': 685, 'length': 953}\n",
      "[flaml.tune.tune: 08-19 14:40:24] {506} INFO - trial 4 config: {'width': 1, 'height': 512, 'length': 812}\n",
      "[flaml.tune.tune: 08-19 14:40:24] {506} INFO - trial 5 config: {'width': 1, 'height': 373, 'length': 674}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'volume': 85404, 'training_iteration': 0, 'config': {'width': 1, 'height': 132, 'length': 647}, 'config/width': 1, 'config/height': 132, 'config/length': 647, 'experiment_tag': 'exp', 'time_total_s': 0.0006337165832519531}\n"
     ]
    }
   ],
   "source": [
    "from flaml import tune\n",
    "def area(config):\n",
    "    return config[\"width\"] * config[\"length\"]\n",
    "\n",
    "cube_search_space = {\n",
    "    \"width\": tune.lograndint(lower=1, upper=1000),\n",
    "    \"height\": tune.randint(lower=1, upper=1000),\n",
    "    \"length\": tune.randint(lower=1, upper=1000),\n",
    "}\n",
    "\n",
    "def cube_volume(config: dict):\n",
    "    \"\"\"evaluate a hyperparameter configuration\"\"\"\n",
    "    score = config[\"width\"] * config[\"height\"] * config[\"length\"]\n",
    "    return {\"volume\": score}\n",
    "\n",
    "analysis = tune.run(evaluation_function=cube_volume,\n",
    "         mode=\"min\",\n",
    "         metric=\"volume\",\n",
    "         config=cube_search_space,\n",
    "         config_constraints=[(area, \"<=\", 1000)],\n",
    "         num_samples=5,\n",
    "        )\n",
    "print(analysis.best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  You can also specify a list of metric constraints to be satisfied via the argument `metric_constraints`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-08-19 14:40:25,044]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 08-19 14:40:25] {506} INFO - trial 1 config: {'x': 3, 'y': 13184}\n",
      "[flaml.tune.tune: 08-19 14:40:25] {506} INFO - trial 2 config: {'x': 6134, 'y': 2076}\n",
      "[flaml.tune.tune: 08-19 14:40:25] {506} INFO - trial 3 config: {'x': 1143, 'y': 74880}\n",
      "[flaml.tune.tune: 08-19 14:40:25] {506} INFO - trial 4 config: {'x': 5539, 'y': 1}\n",
      "[flaml.tune.tune: 08-19 14:40:25] {506} INFO - trial 5 config: {'x': 6793, 'y': 16190}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<flaml.tune.tune.ExperimentAnalysis at 0x7f875bfdf520>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flaml import tune\n",
    "tune.run(evaluation_function=evaluate_config,\n",
    "         mode=\"min\",\n",
    "         metric=\"score\",\n",
    "         config=config_search_space,\n",
    "         metric_constraints=[(\"evaluation_cost\", \"<=\", 0.1)],\n",
    "         num_samples=5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config_constraints vs metric_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-08-19 14:40:25,374]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 08-19 14:40:25] {506} INFO - trial 1 config: {'n_estimators': 39, 'max_leaves': 9, 'learning_rate': 0.08672915197219133}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset from ./openml_ds537.pkl\n",
      "Dataset name: houses\n",
      "X_train.shape: (15480, 8), y_train.shape: (15480,);\n",
      "X_test.shape: (5160, 8), y_test.shape: (5160,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 08-19 14:40:25] {506} INFO - trial 2 config: {'n_estimators': 7, 'max_leaves': 5, 'learning_rate': 0.6111947006764871}\n",
      "Received additional result for trial dccb93ac, but it already finished. Result: {'loss': 0.34163070277175, 'training_cost': 0.07475686073303223, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_leaves': 5, 'learning_rate': 0.6111947006764871}, 'config/n_estimators': 7, 'config/max_leaves': 5, 'config/learning_rate': 0.6111947006764871, 'experiment_tag': 'exp', 'time_total_s': 0.0878458023071289, 'loss_lagrange': 0.34163070277175}\n",
      "Received additional completion for trial dccb93ac, but it already finished. Result: {'loss': 0.34163070277175, 'training_cost': 0.07475686073303223, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_leaves': 5, 'learning_rate': 0.6111947006764871}, 'config/n_estimators': 7, 'config/max_leaves': 5, 'config/learning_rate': 0.6111947006764871, 'experiment_tag': 'exp', 'time_total_s': 0.0878458023071289, 'loss_lagrange': 0.34163070277175}\n",
      "[flaml.tune.tune: 08-19 14:40:26] {506} INFO - trial 3 config: {'n_estimators': 6, 'max_leaves': 5, 'learning_rate': 0.18074443349590638}\n",
      "Received additional result for trial dd5b1e50, but it already finished. Result: {'loss': 0.8232006797301129, 'training_cost': 0.04599189758300781, 'training_iteration': 0, 'config': {'n_estimators': 6, 'max_leaves': 5, 'learning_rate': 0.18074443349590638}, 'config/n_estimators': 6, 'config/max_leaves': 5, 'config/learning_rate': 0.18074443349590638, 'experiment_tag': 'exp', 'time_total_s': 0.05662250518798828, 'loss_lagrange': 0.8232006797301129}\n",
      "Received additional completion for trial dd5b1e50, but it already finished. Result: {'loss': 0.8232006797301129, 'training_cost': 0.04599189758300781, 'training_iteration': 0, 'config': {'n_estimators': 6, 'max_leaves': 5, 'learning_rate': 0.18074443349590638}, 'config/n_estimators': 6, 'config/max_leaves': 5, 'config/learning_rate': 0.18074443349590638, 'experiment_tag': 'exp', 'time_total_s': 0.05662250518798828, 'loss_lagrange': 0.8232006797301129}\n",
      "[flaml.tune.tune: 08-19 14:40:26] {506} INFO - trial 4 config: {'n_estimators': 7, 'max_leaves': 4, 'learning_rate': 0.0050708287994836255}\n",
      "[flaml.tune.tune: 08-19 14:40:27] {506} INFO - trial 5 config: {'n_estimators': 4, 'max_leaves': 8, 'learning_rate': 0.24184523333348865}\n",
      "Received additional result for trial dd9d4faa, but it already finished. Result: {'loss': 0.8387271331451733, 'training_cost': 0.03340911865234375, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 8, 'learning_rate': 0.24184523333348865}, 'config/n_estimators': 4, 'config/max_leaves': 8, 'config/learning_rate': 0.24184523333348865, 'experiment_tag': 'exp', 'time_total_s': 0.042928218841552734, 'loss_lagrange': 0.8387271331451733}\n",
      "Received additional completion for trial dd9d4faa, but it already finished. Result: {'loss': 0.8387271331451733, 'training_cost': 0.03340911865234375, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 8, 'learning_rate': 0.24184523333348865}, 'config/n_estimators': 4, 'config/max_leaves': 8, 'config/learning_rate': 0.24184523333348865, 'experiment_tag': 'exp', 'time_total_s': 0.042928218841552734, 'loss_lagrange': 0.8387271331451733}\n",
      "[flaml.tune.tune: 08-19 14:40:27] {506} INFO - trial 6 config: {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.6006787986201269}\n",
      "[flaml.tune.tune: 08-19 14:40:27] {506} INFO - trial 7 config: {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.5793237833265791}\n",
      "[flaml.tune.tune: 08-19 14:40:27] {506} INFO - trial 8 config: {'n_estimators': 8, 'max_leaves': 5, 'learning_rate': 0.6139350165706452}\n",
      "[flaml.tune.tune: 08-19 14:40:27] {506} INFO - trial 9 config: {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.5823407285827188}\n",
      "[flaml.tune.tune: 08-19 14:40:27] {506} INFO - trial 10 config: {'n_estimators': 7, 'max_leaves': 4, 'learning_rate': 0.6153425666105765}\n",
      "[flaml.tune.tune: 08-19 14:40:27] {506} INFO - trial 11 config: {'n_estimators': 10, 'max_leaves': 4, 'learning_rate': 0.0058671903833274665}\n",
      "[flaml.tune.tune: 08-19 14:40:27] {506} INFO - trial 12 config: {'n_estimators': 10, 'max_leaves': 4, 'learning_rate': 0.005472055643063294}\n",
      "[flaml.tune.tune: 08-19 14:40:28] {506} INFO - trial 13 config: {'n_estimators': 10, 'max_leaves': 4, 'learning_rate': 0.005482932727232923}\n",
      "[flaml.tune.tune: 08-19 14:40:28] {506} INFO - trial 14 config: {'n_estimators': 10, 'max_leaves': 4, 'learning_rate': 0.00451003340688015}\n",
      "[flaml.tune.tune: 08-19 14:40:28] {506} INFO - trial 15 config: {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.004559264656132888}\n",
      "[flaml.tune.tune: 08-19 14:40:28] {506} INFO - trial 16 config: {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.005491692419583242}\n",
      "[flaml.tune.tune: 08-19 14:40:28] {506} INFO - trial 17 config: {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.005400819560603306}\n",
      "[flaml.tune.tune: 08-19 14:40:28] {506} INFO - trial 18 config: {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.0056842152617478025}\n",
      "[flaml.tune.tune: 08-19 14:40:28] {506} INFO - trial 19 config: {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.005370232296413302}\n",
      "[flaml.tune.tune: 08-19 14:40:28] {506} INFO - trial 20 config: {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.005273310814672741}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analysis {'dca21324': {'loss': 0.29118655421442285, 'training_cost': 0.17625713348388672, 'training_iteration': 0, 'config': {'n_estimators': 39, 'max_leaves': 9, 'learning_rate': 0.08672915197219133}, 'config/n_estimators': 39, 'config/max_leaves': 9, 'config/learning_rate': 0.08672915197219133, 'experiment_tag': 'exp', 'time_total_s': 0.1956043243408203, 'loss_lagrange': 0.29118655421442285}, 'dccb93ac': {'loss': 0.34163070277175, 'training_cost': 0.07475686073303223, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_leaves': 5, 'learning_rate': 0.6111947006764871}, 'config/n_estimators': 7, 'config/max_leaves': 5, 'config/learning_rate': 0.6111947006764871, 'experiment_tag': 'exp', 'time_total_s': 0.0878458023071289, 'loss_lagrange': 0.34163070277175}, 'dd5b1e50': {'loss': 0.8232006797301129, 'training_cost': 0.04599189758300781, 'training_iteration': 0, 'config': {'n_estimators': 6, 'max_leaves': 5, 'learning_rate': 0.18074443349590638}, 'config/n_estimators': 6, 'config/max_leaves': 5, 'config/learning_rate': 0.18074443349590638, 'experiment_tag': 'exp', 'time_total_s': 0.05662250518798828, 'loss_lagrange': 0.8232006797301129}, 'dd7231ee': {'loss': 3.9319852698277304, 'training_cost': 0.04110217094421387, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_leaves': 4, 'learning_rate': 0.0050708287994836255}, 'config/n_estimators': 7, 'config/max_leaves': 4, 'config/learning_rate': 0.0050708287994836255, 'experiment_tag': 'exp', 'time_total_s': 0.05344676971435547, 'loss_lagrange': 3.9319852698277304}, 'dd9d4faa': {'loss': 0.8387271331451733, 'training_cost': 0.03340911865234375, 'training_iteration': 0, 'config': {'n_estimators': 4, 'max_leaves': 8, 'learning_rate': 0.24184523333348865}, 'config/n_estimators': 4, 'config/max_leaves': 8, 'config/learning_rate': 0.24184523333348865, 'experiment_tag': 'exp', 'time_total_s': 0.042928218841552734, 'loss_lagrange': 0.8387271331451733}, 'dde7754e': {'loss': 0.354881626172457, 'training_cost': 0.03821682929992676, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.6006787986201269}, 'config/n_estimators': 8, 'config/max_leaves': 4, 'config/learning_rate': 0.6006787986201269, 'experiment_tag': 'exp', 'time_total_s': 0.047669172286987305, 'loss_lagrange': 0.354881626172457}, 'ddf095de': {'loss': 0.3548949411813205, 'training_cost': 0.041512489318847656, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.5793237833265791}, 'config/n_estimators': 8, 'config/max_leaves': 4, 'config/learning_rate': 0.5793237833265791, 'experiment_tag': 'exp', 'time_total_s': 0.05447983741760254, 'loss_lagrange': 0.3548949411813205}, 'ddfdbba6': {'loss': 0.3197094097535268, 'training_cost': 0.04559755325317383, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_leaves': 5, 'learning_rate': 0.6139350165706452}, 'config/n_estimators': 8, 'config/max_leaves': 5, 'config/learning_rate': 0.6139350165706452, 'experiment_tag': 'exp', 'time_total_s': 0.05684208869934082, 'loss_lagrange': 0.3197094097535268}, 'de086420': {'loss': 0.3546971521342588, 'training_cost': 0.059758901596069336, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.5823407285827188}, 'config/n_estimators': 8, 'config/max_leaves': 4, 'config/learning_rate': 0.5823407285827188, 'experiment_tag': 'exp', 'time_total_s': 0.07589840888977051, 'loss_lagrange': 0.3546971521342588}, 'de16643a': {'loss': 0.3769013292935818, 'training_cost': 0.037094831466674805, 'training_iteration': 0, 'config': {'n_estimators': 7, 'max_leaves': 4, 'learning_rate': 0.6153425666105765}, 'config/n_estimators': 7, 'config/max_leaves': 4, 'config/learning_rate': 0.6153425666105765, 'experiment_tag': 'exp', 'time_total_s': 0.05078625679016113, 'loss_lagrange': 0.3769013292935818}, 'de200792': {'loss': 3.7775722488689962, 'training_cost': 0.04292726516723633, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_leaves': 4, 'learning_rate': 0.0058671903833274665}, 'config/n_estimators': 10, 'config/max_leaves': 4, 'config/learning_rate': 0.0058671903833274665, 'experiment_tag': 'exp', 'time_total_s': 0.055135250091552734, 'loss_lagrange': 3.7775722488689962}, 'de2ad05a': {'loss': 3.8034502111024424, 'training_cost': 0.053734540939331055, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_leaves': 4, 'learning_rate': 0.005472055643063294}, 'config/n_estimators': 10, 'config/max_leaves': 4, 'config/learning_rate': 0.005472055643063294, 'experiment_tag': 'exp', 'time_total_s': 0.0644989013671875, 'loss_lagrange': 3.8034502111024424}, 'de369002': {'loss': 3.802735232757214, 'training_cost': 0.04329347610473633, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_leaves': 4, 'learning_rate': 0.005482932727232923}, 'config/n_estimators': 10, 'config/max_leaves': 4, 'config/learning_rate': 0.005482932727232923, 'experiment_tag': 'exp', 'time_total_s': 0.05412411689758301, 'loss_lagrange': 3.802735232757214}, 'de41017c': {'loss': 3.867263945454747, 'training_cost': 0.05841255187988281, 'training_iteration': 0, 'config': {'n_estimators': 10, 'max_leaves': 4, 'learning_rate': 0.00451003340688015}, 'config/n_estimators': 10, 'config/max_leaves': 4, 'config/learning_rate': 0.00451003340688015, 'experiment_tag': 'exp', 'time_total_s': 0.07337450981140137, 'loss_lagrange': 3.867263945454747}, 'de4ecc80': {'loss': 3.9253873188696504, 'training_cost': 0.05304574966430664, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.004559264656132888}, 'config/n_estimators': 8, 'config/max_leaves': 4, 'config/learning_rate': 0.004559264656132888, 'experiment_tag': 'exp', 'time_total_s': 0.06712222099304199, 'loss_lagrange': 3.9253873188696504}, 'de5be4ec': {'loss': 3.874931681987616, 'training_cost': 0.05304098129272461, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.005491692419583242}, 'config/n_estimators': 8, 'config/max_leaves': 4, 'config/learning_rate': 0.005491692419583242, 'experiment_tag': 'exp', 'time_total_s': 0.06700325012207031, 'loss_lagrange': 3.874931681987616}, 'de68ec32': {'loss': 3.879819325377997, 'training_cost': 0.03861379623413086, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.005400819560603306}, 'config/n_estimators': 8, 'config/max_leaves': 4, 'config/learning_rate': 0.005400819560603306, 'experiment_tag': 'exp', 'time_total_s': 0.049741506576538086, 'loss_lagrange': 3.879819325377997}, 'de76db9e': {'loss': 3.864598962789906, 'training_cost': 0.04323768615722656, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.0056842152617478025}, 'config/n_estimators': 8, 'config/max_leaves': 4, 'config/learning_rate': 0.0056842152617478025, 'experiment_tag': 'exp', 'time_total_s': 0.06017899513244629, 'loss_lagrange': 3.864598962789906}, 'de81ce46': {'loss': 3.881465994496562, 'training_cost': 0.04065418243408203, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.005370232296413302}, 'config/n_estimators': 8, 'config/max_leaves': 4, 'config/learning_rate': 0.005370232296413302, 'experiment_tag': 'exp', 'time_total_s': 0.05346322059631348, 'loss_lagrange': 3.881465994496562}, 'de8c54ce': {'loss': 3.886688790212883, 'training_cost': 0.04543447494506836, 'training_iteration': 0, 'config': {'n_estimators': 8, 'max_leaves': 4, 'learning_rate': 0.005273310814672741}, 'config/n_estimators': 8, 'config/max_leaves': 4, 'config/learning_rate': 0.005273310814672741, 'experiment_tag': 'exp', 'time_total_s': 0.0651705265045166, 'loss_lagrange': 3.886688790212883}}\n"
     ]
    }
   ],
   "source": [
    "'''Write a evaluation function'''\n",
    "import xgboost as xgb\n",
    "from flaml import tune\n",
    "import time\n",
    "def xgb_simple_obj(X_train, X_test, y_train, y_test, config):\n",
    "    params = config2params(config)\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    start_time = time.time()\n",
    "    _n_estimators = params.pop(\"n_estimators\")\n",
    "    model = xgb.train(params, dtrain, _n_estimators)\n",
    "    end_time = time.time()\n",
    "    # get validation loss\n",
    "    from sklearn.metrics import r2_score\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    y_test_predict = model.predict(dtest)\n",
    "    test_loss = 1.0 - r2_score(y_test, y_test_predict)\n",
    "    return {\"loss\": test_loss, \"training_cost\": end_time-start_time}\n",
    "\n",
    "def config2params(config: dict) -> dict:\n",
    "    params = config.copy()\n",
    "    max_depth = params[\"max_depth\"] = params.get(\"max_depth\", 0)\n",
    "    if max_depth == 0:\n",
    "        params[\"grow_policy\"] = params.get(\"grow_policy\", \"lossguide\")\n",
    "        params[\"tree_method\"] = params.get(\"tree_method\", \"hist\")\n",
    "    # params[\"booster\"] = params.get(\"booster\", \"gbtree\")\n",
    "    params[\"use_label_encoder\"] = params.get(\"use_label_encoder\", False)\n",
    "    if \"n_jobs\" in config:\n",
    "        params[\"nthread\"] = params.pop(\"n_jobs\")\n",
    "    return params\n",
    "\n",
    "def my_model_size(config):\n",
    "    return config[\"n_estimators\"] * config[\"max_leaves\"]\n",
    "\n",
    "'''Tune xgb_obj with configs from the hierarchical search space'''\n",
    "from flaml.data import load_openml_dataset\n",
    "from functools import partial\n",
    "\n",
    "xgb_space = {\n",
    "     \"n_estimators\": tune.randint(lower=4, upper=64),\n",
    "      \"max_leaves\": tune.randint(lower=4, upper=64),\n",
    "      \"learning_rate\": tune.loguniform(lower=1 / 1024, upper=1.0),\n",
    "}\n",
    "X_train, X_test, y_train, y_test = load_openml_dataset(\n",
    "    dataset_id=537, data_dir=\"./\"\n",
    ")\n",
    "analysis = tune.run(\n",
    "    partial(xgb_simple_obj, X_train, X_test, y_train, y_test),\n",
    "    config=xgb_space,\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    config_constraints = [(my_model_size, \"<=\", 40)],\n",
    "    metric_constraints = [(\"training_cost\", \"<=\", 1)],\n",
    "    num_samples=20,\n",
    ")\n",
    "print(\"analysis\", analysis.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flaml[ray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-08-19 14:40:32,446]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "2022-08-19 14:40:35,386\tINFO services.py:1470 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
      "2022-08-19 14:40:37,389\tWARNING function_runner.py:603 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-08-19 14:40:40 (running for 00:00:01.92)<br>Memory usage on this node: 5.5/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/1.58 GiB heap, 0.0/0.79 GiB objects<br>Result logdir: /home/ec2-user/ray_results/evaluate_config_2022-08-19_14-40-37<br>Number of trials: 1/infinite (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial evaluate_config_e48e9864 reported score=7224490009.00 with parameters={'x': 3, 'y': 13184}.\n",
      "Trial evaluate_config_e48e9864 completed. Last result: score=7224490008.999772,evaluation_cost=3e-05,constraint_metric=39552\n",
      "Trial evaluate_config_e5b3a0ea reported score=6219845953.05 with parameters={'x': 6134, 'y': 2076}.\n",
      "Trial evaluate_config_e5b3a0ea completed. Last result: score=6219845953.0452795,evaluation_cost=0.06134,constraint_metric=12734184\n",
      "Trial evaluate_config_e5b75cc6 reported score=7031996448.98 with parameters={'x': 1143, 'y': 74880}.\n",
      "Trial evaluate_config_e5b75cc6 completed. Last result: score=7031996448.9847355,evaluation_cost=0.01143,constraint_metric=85587840\n",
      "Trial evaluate_config_e5c30b2a reported score=7187648399.99 with parameters={'x': 220, 'y': 22480}.\n",
      "Trial evaluate_config_e5c30b2a completed. Last result: score=7187648399.990213,evaluation_cost=0.0022,constraint_metric=4945600\n",
      "Trial evaluate_config_e5c7883a reported score=6314044982.00 with parameters={'x': 5539, 'y': 1}.\n",
      "Trial evaluate_config_e5c7883a completed. Last result: score=6314044982.0,evaluation_cost=0.05539,constraint_metric=5539\n",
      "Trial evaluate_config_e5ca2428 reported score=7223980036.00 with parameters={'x': 6, 'y': 76053}.\n",
      "Trial evaluate_config_e5ca2428 completed. Last result: score=7223980035.999921,evaluation_cost=6e-05,constraint_metric=456318\n",
      "Trial evaluate_config_e5d542b8 reported score=7224320016.00 with parameters={'x': 4, 'y': 8834}.\n",
      "Trial evaluate_config_e5d542b8 completed. Last result: score=7224320015.999547,evaluation_cost=4e-05,constraint_metric=35336\n",
      "Trial evaluate_config_e5d7fd8c reported score=6116334848.58 with parameters={'x': 6793, 'y': 16190}.\n",
      "Trial evaluate_config_e5d7fd8c completed. Last result: score=6116334848.58042,evaluation_cost=0.06793,constraint_metric=109978670\n",
      "Trial evaluate_config_e5da8304 reported score=6864453903.98 with parameters={'x': 2148, 'y': 95339}.\n",
      "Trial evaluate_config_e5da8304 completed. Last result: score=6864453903.977469,evaluation_cost=0.02148,constraint_metric=204788172\n",
      "Trial evaluate_config_e5e77c12 reported score=7224830001.00 with parameters={'x': 1, 'y': 51219}.\n",
      "Trial evaluate_config_e5e77c12 completed. Last result: score=7224830000.999981,evaluation_cost=1e-05,constraint_metric=51219\n",
      "Trial evaluate_config_e5ed3558 reported score=5601774024.83 with parameters={'x': 10155, 'y': 61252}.\n",
      "Trial evaluate_config_e5ed3558 completed. Last result: score=5601774024.834209,evaluation_cost=0.10155,constraint_metric=622014060\n",
      "Trial evaluate_config_e5efc084 reported score=6666722499.89 with parameters={'x': 3350, 'y': 29188}.\n",
      "Trial evaluate_config_e5efc084 completed. Last result: score=6666722499.885227,evaluation_cost=0.0335,constraint_metric=97779800\n",
      "Trial evaluate_config_e601899a reported score=1110755583.16 with parameters={'x': 51672, 'y': 61799}.\n",
      "Trial evaluate_config_e601899a completed. Last result: score=1110755583.1638699,evaluation_cost=0.51672,constraint_metric=3193277928\n",
      "Trial evaluate_config_e6092d6c reported score=6889664015.97 with parameters={'x': 1996, 'y': 60705}.\n",
      "Trial evaluate_config_e6092d6c completed. Last result: score=6889664015.967119,evaluation_cost=0.01996,constraint_metric=121167180\n",
      "Trial evaluate_config_e65a2492 reported score=4434627648.75 with parameters={'x': 18407, 'y': 72736}.\n",
      "Trial evaluate_config_e65a2492 completed. Last result: score=4434627648.746934,evaluation_cost=0.18407,constraint_metric=1338851552\n",
      "Trial evaluate_config_e65fdec8 reported score=224969999.03 with parameters={'x': 99999, 'y': 50862}.\n",
      "Trial evaluate_config_e65fdec8 completed. Last result: score=224969999.0339153,evaluation_cost=0.99999,constraint_metric=5086149138\n",
      "Trial evaluate_config_e6812e84 reported score=224969999.00 with parameters={'x': 99999, 'y': 50037}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-08-19 14:40:43 (running for 00:00:05.29)<br>Memory usage on this node: 5.5/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/1.58 GiB heap, 0.0/0.79 GiB objects<br>Current best trial: e6812e84 with score=224969999.00149888 and parameters={'x': 99999, 'y': 50037}<br>Result logdir: /home/ec2-user/ray_results/evaluate_config_2022-08-19_14-40-37<br>Number of trials: 18/infinite (1 PENDING, 1 RUNNING, 16 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial evaluate_config_e6812e84 completed. Last result: score=224969999.00149888,evaluation_cost=0.99999,constraint_metric=5003649963\n",
      "Trial evaluate_config_e71b9f82 reported score=1980784035.35 with parameters={'x': 40494, 'y': 62624}.\n",
      "Trial evaluate_config_e71b9f82 completed. Last result: score=1980784035.353379,evaluation_cost=0.40494,constraint_metric=2535896256\n",
      "Trial evaluate_config_e7b84df0 reported score=594628223.34 with parameters={'x': 60615, 'y': 36580}.\n",
      "Trial evaluate_config_e7b84df0 completed. Last result: score=594628223.342947,evaluation_cost=0.60615,constraint_metric=2217296700\n",
      "Trial evaluate_config_e7fa26da reported score=224969999.43 with parameters={'x': 99999, 'y': 63494}.\n",
      "Trial evaluate_config_e7fa26da completed. Last result: score=224969999.4250638,evaluation_cost=0.99999,constraint_metric=6349336506\n",
      "Trial evaluate_config_e859860c reported score=2230483983.38 with parameters={'x': 37772, 'y': 61372}.\n",
      "Trial evaluate_config_e859860c completed. Last result: score=2230483983.38454,evaluation_cost=0.37772,constraint_metric=2318143184\n",
      "Trial evaluate_config_e8f4bdca reported score=224969998.42 with parameters={'x': 99999, 'y': 38702}.\n",
      "Trial evaluate_config_e8f4bdca completed. Last result: score=224969998.41618004,evaluation_cost=0.99999,constraint_metric=3870161298\n",
      "Trial evaluate_config_e931f99c reported score=2337335715.49 with parameters={'x': 36654, 'y': 71457}.\n",
      "Trial evaluate_config_e931f99c completed. Last result: score=2337335715.487048,evaluation_cost=0.36654,constraint_metric=2619184878\n",
      "Trial evaluate_config_e9cde51e reported score=545456023.68 with parameters={'x': 61645, 'y': 46806}.\n",
      "Trial evaluate_config_e9cde51e completed. Last result: score=545456023.682968,evaluation_cost=0.61645,constraint_metric=2885355870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 14:40:49,542\tINFO stopper.py:363 -- Reached timeout of 10 seconds. Stopping all trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial evaluate_config_ea10799c reported score=224969997.73 with parameters={'x': 99999, 'y': 30598}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-08-19 14:40:49 (running for 00:00:10.92)<br>Memory usage on this node: 5.5/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/1.58 GiB heap, 0.0/0.79 GiB objects<br>Current best trial: ea10799c with score=224969997.73184523 and parameters={'x': 99999, 'y': 30598}<br>Result logdir: /home/ec2-user/ray_results/evaluate_config_2022-08-19_14-40-37<br>Number of trials: 26/infinite (26 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-08-19 14:40:49 (running for 00:00:10.93)<br>Memory usage on this node: 5.5/7.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/1.58 GiB heap, 0.0/0.79 GiB objects<br>Current best trial: ea10799c with score=224969997.73184523 and parameters={'x': 99999, 'y': 30598}<br>Result logdir: /home/ec2-user/ray_results/evaluate_config_2022-08-19_14-40-37<br>Number of trials: 26/infinite (26 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">    x</th><th style=\"text-align: right;\">    y</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      score</th><th style=\"text-align: right;\">  evaluation_cost</th><th style=\"text-align: right;\">  constraint_metric</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>evaluate_config_e48e9864</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">    3</td><td style=\"text-align: right;\">13184</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.00169587 </td><td style=\"text-align: right;\">7.22449e+09</td><td style=\"text-align: right;\">          3e-05  </td><td style=\"text-align: right;\">              39552</td></tr>\n",
       "<tr><td>evaluate_config_e5b3a0ea</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\"> 6134</td><td style=\"text-align: right;\"> 2076</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0616207  </td><td style=\"text-align: right;\">6.21985e+09</td><td style=\"text-align: right;\">          0.06134</td><td style=\"text-align: right;\">           12734184</td></tr>\n",
       "<tr><td>evaluate_config_e5b75cc6</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\"> 1143</td><td style=\"text-align: right;\">74880</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0118549  </td><td style=\"text-align: right;\">7.032e+09  </td><td style=\"text-align: right;\">          0.01143</td><td style=\"text-align: right;\">           85587840</td></tr>\n",
       "<tr><td>evaluate_config_e5c30b2a</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">  220</td><td style=\"text-align: right;\">22480</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.00244522 </td><td style=\"text-align: right;\">7.18765e+09</td><td style=\"text-align: right;\">          0.0022 </td><td style=\"text-align: right;\">            4945600</td></tr>\n",
       "<tr><td>evaluate_config_e5c7883a</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\"> 5539</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0556326  </td><td style=\"text-align: right;\">6.31404e+09</td><td style=\"text-align: right;\">          0.05539</td><td style=\"text-align: right;\">               5539</td></tr>\n",
       "<tr><td>evaluate_config_e5ca2428</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">    6</td><td style=\"text-align: right;\">76053</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000466824</td><td style=\"text-align: right;\">7.22398e+09</td><td style=\"text-align: right;\">          6e-05  </td><td style=\"text-align: right;\">             456318</td></tr>\n",
       "<tr><td>evaluate_config_e5d542b8</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\"> 8834</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000468731</td><td style=\"text-align: right;\">7.22432e+09</td><td style=\"text-align: right;\">          4e-05  </td><td style=\"text-align: right;\">              35336</td></tr>\n",
       "<tr><td>evaluate_config_e5d7fd8c</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\"> 6793</td><td style=\"text-align: right;\">16190</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.068198   </td><td style=\"text-align: right;\">6.11633e+09</td><td style=\"text-align: right;\">          0.06793</td><td style=\"text-align: right;\">          109978670</td></tr>\n",
       "<tr><td>evaluate_config_e5da8304</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\"> 2148</td><td style=\"text-align: right;\">95339</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.023006   </td><td style=\"text-align: right;\">6.86445e+09</td><td style=\"text-align: right;\">          0.02148</td><td style=\"text-align: right;\">          204788172</td></tr>\n",
       "<tr><td>evaluate_config_e5e77c12</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">51219</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000255585</td><td style=\"text-align: right;\">7.22483e+09</td><td style=\"text-align: right;\">          1e-05  </td><td style=\"text-align: right;\">              51219</td></tr>\n",
       "<tr><td>evaluate_config_e5ed3558</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">10155</td><td style=\"text-align: right;\">61252</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.101852   </td><td style=\"text-align: right;\">5.60177e+09</td><td style=\"text-align: right;\">          0.10155</td><td style=\"text-align: right;\">          622014060</td></tr>\n",
       "<tr><td>evaluate_config_e5efc084</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\"> 3350</td><td style=\"text-align: right;\">29188</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0338032  </td><td style=\"text-align: right;\">6.66672e+09</td><td style=\"text-align: right;\">          0.0335 </td><td style=\"text-align: right;\">           97779800</td></tr>\n",
       "<tr><td>evaluate_config_e601899a</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">51672</td><td style=\"text-align: right;\">61799</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.517542   </td><td style=\"text-align: right;\">1.11076e+09</td><td style=\"text-align: right;\">          0.51672</td><td style=\"text-align: right;\">         3193277928</td></tr>\n",
       "<tr><td>evaluate_config_e6092d6c</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\"> 1996</td><td style=\"text-align: right;\">60705</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0202024  </td><td style=\"text-align: right;\">6.88966e+09</td><td style=\"text-align: right;\">          0.01996</td><td style=\"text-align: right;\">          121167180</td></tr>\n",
       "<tr><td>evaluate_config_e65a2492</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">18407</td><td style=\"text-align: right;\">72736</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.184415   </td><td style=\"text-align: right;\">4.43463e+09</td><td style=\"text-align: right;\">          0.18407</td><td style=\"text-align: right;\">         1338851552</td></tr>\n",
       "<tr><td>evaluate_config_e65fdec8</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">50862</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.00109    </td><td style=\"text-align: right;\">2.2497e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">         5086149138</td></tr>\n",
       "<tr><td>evaluate_config_e6812e84</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">50037</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.00115    </td><td style=\"text-align: right;\">2.2497e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">         5003649963</td></tr>\n",
       "<tr><td>evaluate_config_e71b9f82</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">40494</td><td style=\"text-align: right;\">62624</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.406367   </td><td style=\"text-align: right;\">1.98078e+09</td><td style=\"text-align: right;\">          0.40494</td><td style=\"text-align: right;\">         2535896256</td></tr>\n",
       "<tr><td>evaluate_config_e7b84df0</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">60615</td><td style=\"text-align: right;\">36580</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.607406   </td><td style=\"text-align: right;\">5.94628e+08</td><td style=\"text-align: right;\">          0.60615</td><td style=\"text-align: right;\">         2217296700</td></tr>\n",
       "<tr><td>evaluate_config_e7fa26da</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">63494</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.00091    </td><td style=\"text-align: right;\">2.2497e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">         6349336506</td></tr>\n",
       "<tr><td>evaluate_config_e859860c</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">37772</td><td style=\"text-align: right;\">61372</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.378147   </td><td style=\"text-align: right;\">2.23048e+09</td><td style=\"text-align: right;\">          0.37772</td><td style=\"text-align: right;\">         2318143184</td></tr>\n",
       "<tr><td>evaluate_config_e8f4bdca</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">38702</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.00127    </td><td style=\"text-align: right;\">2.2497e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">         3870161298</td></tr>\n",
       "<tr><td>evaluate_config_e931f99c</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">36654</td><td style=\"text-align: right;\">71457</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.367723   </td><td style=\"text-align: right;\">2.33734e+09</td><td style=\"text-align: right;\">          0.36654</td><td style=\"text-align: right;\">         2619184878</td></tr>\n",
       "<tr><td>evaluate_config_e9cde51e</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">61645</td><td style=\"text-align: right;\">46806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.623562   </td><td style=\"text-align: right;\">5.45456e+08</td><td style=\"text-align: right;\">          0.61645</td><td style=\"text-align: right;\">         2885355870</td></tr>\n",
       "<tr><td>evaluate_config_ea10799c</td><td>TERMINATED</td><td>172.31.46.142:23793</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">30598</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.0006     </td><td style=\"text-align: right;\">2.2497e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">         3059769402</td></tr>\n",
       "<tr><td>evaluate_config_ea70b168</td><td>TERMINATED</td><td>                   </td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">40382</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 14:40:49,812\tINFO tune.py:747 -- Total run time: 12.43 seconds (10.92 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 224969997.73184523, 'evaluation_cost': 0.99999, 'constraint_metric': 3059769402, 'time_this_iter_s': 1.0006046295166016, 'done': False, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 1, 'trial_id': 'ea10799c', 'experiment_id': 'd9a4d0a5639d4a3b9be0b28f6226480e', 'date': '2022-08-19_14-40-49', 'timestamp': 1660920049, 'time_total_s': 1.0006046295166016, 'pid': 23793, 'hostname': 'ip-172-31-46-142.us-east-2.compute.internal', 'node_ip': '172.31.46.142', 'config': {'x': 99999, 'y': 30598}, 'time_since_restore': 1.0006046295166016, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'warmup_time': 0.006740570068359375, 'experiment_tag': '25_x=99999,y=30598'}\n",
      "{'x': 99999, 'y': 30598}\n"
     ]
    }
   ],
   "source": [
    "# require: pip install flaml[ray]\n",
    "analysis = tune.run(\n",
    "    evaluate_config,  # the function to evaluate a config\n",
    "    config=config_search_space,  # the search space defined\n",
    "    metric=\"score\",\n",
    "    mode=\"min\",  # the optimization mode, \"min\" or \"max\"\n",
    "    num_samples=-1,  # the maximal number of configs to try, -1 means infinite\n",
    "    time_budget_s=10,  # the time budget in seconds\n",
    "    use_ray=True,\n",
    "    resources_per_trial={\"cpu\": 2}  # limit resources allocated per trial\n",
    ")\n",
    "print(analysis.best_trial.last_result)  # the best trial's result\n",
    "print(analysis.best_config)  # the best config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 14:40:50,070\tWARNING optuna.py:297 -- You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-08-19 14:40:50,073]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "/home/ec2-user/miniconda3/envs/myflaml/lib/python3.8/site-packages/ray/tune/suggest/optuna.py:561: ExperimentalWarning: create_trial is experimental (supported from v2.0.0). The interface can change in the future.\n",
      "  trial = ot.trial.create_trial(\n",
      "2022-08-19 14:40:50,075\tWARNING optuna.py:297 -- You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-08-19 14:40:50,078]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 08-19 14:40:50] {506} INFO - trial 1 config: {'b': 0.8, 'a': 3.0}\n",
      "[flaml.tune.tune: 08-19 14:40:50] {506} INFO - trial 2 config: {'b': 0.8, 'a': 2.0}\n",
      "[flaml.tune.tune: 08-19 14:40:50] {506} INFO - trial 3 config: {'a': 0.7636074368340785, 'b': 0.0622558480782045}\n",
      "[flaml.tune.tune: 08-19 14:40:50] {506} INFO - trial 4 config: {'a': 0.6273117525770127, 'b': 2.246411647615836}\n",
      "[flaml.tune.tune: 08-19 14:40:50] {506} INFO - trial 5 config: {'a': 0.4935219421795645, 'b': 0.674389936592543}\n",
      "[flaml.tune.tune: 08-19 14:40:50] {506} INFO - trial 6 config: {'a': 0.19608223611202774, 'b': 2.2815921365968763}\n",
      "[flaml.tune.tune: 08-19 14:40:50] {506} INFO - trial 7 config: {'a': 0.1674197281969101, 'b': 0.2650194425220308}\n",
      "[flaml.tune.tune: 08-19 14:40:50] {506} INFO - trial 8 config: {'a': 0.6785062201841192, 'b': 2.8601800385848097}\n",
      "[flaml.tune.tune: 08-19 14:40:50] {506} INFO - trial 9 config: {'a': 0.003908783664635307, 'b': 1.53657679015733}\n",
      "[flaml.tune.tune: 08-19 14:40:50] {506} INFO - trial 10 config: {'a': 0.8044947520355924, 'b': 1.8375782004881644}\n"
     ]
    }
   ],
   "source": [
    "from flaml import tune\n",
    "\n",
    "config_search_space = {\n",
    "    \"a\": tune.uniform(lower=0, upper=0.99),\n",
    "    \"b\": tune.uniform(lower=0, upper=3),\n",
    "}\n",
    "\n",
    "def simple_obj(config):\n",
    "    return config[\"a\"] + config[\"b\"]\n",
    "\n",
    "points_to_evaluate = [\n",
    "    {\"b\": .99, \"a\": 3},\n",
    "    {\"b\": .99, \"a\": 2},\n",
    "    {\"b\": .80, \"a\": 3},\n",
    "    {\"b\": .80, \"a\": 2},\n",
    "]\n",
    "evaluated_rewards = [3.99, 2.99]\n",
    "\n",
    "analysis = tune.run(\n",
    "    simple_obj,\n",
    "    config=config_search_space,\n",
    "    mode=\"max\",\n",
    "    points_to_evaluate=points_to_evaluate,\n",
    "    evaluated_rewards=evaluated_rewards,\n",
    "    num_samples=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial scheduling\n",
    "\n",
    "###  An authentic scheduler implemented in FLAML (`scheduler='flaml'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "        \"n_estimators\": tune.lograndint(lower=4, upper=32768),\n",
    "        \"max_leaves\": tune.lograndint(lower=4, upper=32768),\n",
    "        \"learning_rate\": tune.loguniform(lower=1 / 1024, upper=1.0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set a evaluation function with resource dimension'''\n",
    "def obj_from_resource_attr(resource_attr, X_train, X_test, y_train, y_test, config):\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # in this example sample size is our resource dimension\n",
    "    resource = int(config[resource_attr])\n",
    "    sampled_X_train = X_train.iloc[:resource]\n",
    "    sampled_y_train = y_train[:resource]\n",
    "\n",
    "    # construct a LGBM model from the config\n",
    "    # note that you need to first remove the resource_attr field\n",
    "    # from the config as it is not part of the original search space\n",
    "    model_config = config.copy()\n",
    "    del model_config[resource_attr]\n",
    "    model = LGBMClassifier(**model_config)\n",
    "\n",
    "    model.fit(sampled_X_train, sampled_y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    test_loss = 1.0 - accuracy_score(y_test, y_test_predict)\n",
    "    return {\"loss\": test_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 14:44:26,028\tWARNING optuna.py:297 -- You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-08-19 14:44:26,030]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 08-19 14:44:26] {506} INFO - trial 1 config: {'n_estimators': 9, 'max_leaves': 1364, 'learning_rate': 0.012074374674294664, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:26] {506} INFO - trial 2 config: {'n_estimators': 4048, 'max_leaves': 4, 'learning_rate': 0.07891713267442702, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset from openml_task7592.pkl\n",
      "X_train.shape: (43957, 14), y_train.shape: (43957,),\n",
      "X_test.shape: (4885, 14), y_test.shape: (4885,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 08-19 14:44:26] {506} INFO - trial 3 config: {'n_estimators': 3295, 'max_leaves': 334, 'learning_rate': 0.004638797085780012, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:26] {506} INFO - trial 4 config: {'n_estimators': 21, 'max_leaves': 3668, 'learning_rate': 0.003153366048206083, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:26] {506} INFO - trial 5 config: {'n_estimators': 8, 'max_leaves': 1845, 'learning_rate': 0.7239356970260848, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:26] {506} INFO - trial 6 config: {'n_estimators': 4, 'max_leaves': 379, 'learning_rate': 0.2728556109672425, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:26] {506} INFO - trial 7 config: {'n_estimators': 948, 'max_leaves': 2573, 'learning_rate': 0.0073847289359894605, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:26] {506} INFO - trial 8 config: {'n_estimators': 15449, 'max_leaves': 2409, 'learning_rate': 0.04196829547317673, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:26] {506} INFO - trial 9 config: {'n_estimators': 13, 'max_leaves': 106, 'learning_rate': 0.10448271169801053, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:26] {506} INFO - trial 10 config: {'n_estimators': 199, 'max_leaves': 185, 'learning_rate': 0.07069097177435173, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:26] {506} INFO - trial 11 config: {'n_estimators': 382, 'max_leaves': 1340, 'learning_rate': 0.06295171682621144, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:26] {506} INFO - trial 12 config: {'n_estimators': 5520, 'max_leaves': 413, 'learning_rate': 0.5308914484951052, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:27] {506} INFO - trial 13 config: {'n_estimators': 3503, 'max_leaves': 7, 'learning_rate': 0.0010918443163764437, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:27] {506} INFO - trial 14 config: {'n_estimators': 54, 'max_leaves': 30204, 'learning_rate': 0.004360679238440181, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:27] {506} INFO - trial 15 config: {'n_estimators': 49, 'max_leaves': 23677, 'learning_rate': 0.0010641529214071718, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:27] {506} INFO - trial 16 config: {'n_estimators': 1534, 'max_leaves': 37, 'learning_rate': 0.006371183957388993, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:27] {506} INFO - trial 17 config: {'n_estimators': 29723, 'max_leaves': 9340, 'learning_rate': 0.0027991149620651954, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:27] {506} INFO - trial 18 config: {'n_estimators': 70, 'max_leaves': 34, 'learning_rate': 0.011193803613244459, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:27] {506} INFO - trial 19 config: {'n_estimators': 7696, 'max_leaves': 6735, 'learning_rate': 0.0171883008494944, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:27] {506} INFO - trial 20 config: {'n_estimators': 24847, 'max_leaves': 13127, 'learning_rate': 0.0022947034584149804, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:28] {506} INFO - trial 21 config: {'n_estimators': 167, 'max_leaves': 15, 'learning_rate': 0.01693528096911362, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:28] {506} INFO - trial 22 config: {'n_estimators': 10494, 'max_leaves': 746, 'learning_rate': 0.02385060065057464, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:28] {506} INFO - trial 23 config: {'n_estimators': 1934, 'max_leaves': 92, 'learning_rate': 0.0019836952742413195, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:28] {506} INFO - trial 24 config: {'n_estimators': 26875, 'max_leaves': 4, 'learning_rate': 0.0017068232742646725, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:28] {506} INFO - trial 25 config: {'n_estimators': 281, 'max_leaves': 688, 'learning_rate': 0.016552541070398875, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:28] {506} INFO - trial 26 config: {'n_estimators': 1778, 'max_leaves': 81, 'learning_rate': 0.03175152998663522, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:28] {506} INFO - trial 27 config: {'n_estimators': 688, 'max_leaves': 7, 'learning_rate': 0.001542522148885942, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:28] {506} INFO - trial 28 config: {'n_estimators': 3797, 'max_leaves': 791, 'learning_rate': 0.007264101943760989, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:28] {506} INFO - trial 29 config: {'n_estimators': 630, 'max_leaves': 177, 'learning_rate': 0.14424489344601685, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:28] {506} INFO - trial 30 config: {'n_estimators': 1174, 'max_leaves': 34, 'learning_rate': 0.03769197598985876, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:28] {506} INFO - trial 31 config: {'n_estimators': 3554, 'max_leaves': 12, 'learning_rate': 0.005723824290933867, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:29] {506} INFO - trial 32 config: {'n_estimators': 540, 'max_leaves': 970, 'learning_rate': 0.2234297355835903, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:29] {506} INFO - trial 33 config: {'n_estimators': 988, 'max_leaves': 207, 'learning_rate': 0.16430394221281475, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:29] {506} INFO - trial 34 config: {'n_estimators': 2835, 'max_leaves': 23, 'learning_rate': 0.004113773682186522, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:29] {506} INFO - trial 35 config: {'n_estimators': 480, 'max_leaves': 13, 'learning_rate': 0.3286382866833518, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:29] {506} INFO - trial 36 config: {'n_estimators': 5897, 'max_leaves': 254, 'learning_rate': 0.9259903592746499, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:29] {506} INFO - trial 37 config: {'n_estimators': 2526, 'max_leaves': 1332, 'learning_rate': 0.19284215718355668, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:29] {506} INFO - trial 38 config: {'n_estimators': 12671, 'max_leaves': 4, 'learning_rate': 0.0018253161972409146, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:29] {506} INFO - trial 39 config: {'n_estimators': 199, 'max_leaves': 439, 'learning_rate': 0.011304611020148745, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:29] {506} INFO - trial 40 config: {'n_estimators': 103, 'max_leaves': 88, 'learning_rate': 0.003539923584406662, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:29] {506} INFO - trial 41 config: {'n_estimators': 18778, 'max_leaves': 3702, 'learning_rate': 0.027602122008566297, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:30] {506} INFO - trial 42 config: {'n_estimators': 270, 'max_leaves': 62, 'learning_rate': 0.05507878569900855, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:30] {506} INFO - trial 43 config: {'n_estimators': 918, 'max_leaves': 564, 'learning_rate': 0.011450265080289271, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:30] {506} INFO - trial 44 config: {'n_estimators': 1817, 'max_leaves': 313, 'learning_rate': 0.008383218707494321, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:30] {506} INFO - trial 45 config: {'n_estimators': 663, 'max_leaves': 178, 'learning_rate': 0.10140492706094423, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:30] {506} INFO - trial 46 config: {'n_estimators': 4785, 'max_leaves': 137, 'learning_rate': 0.0013296286140323664, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:30] {506} INFO - trial 47 config: {'n_estimators': 1109, 'max_leaves': 6, 'learning_rate': 0.09122606727247846, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:30] {506} INFO - trial 48 config: {'n_estimators': 778, 'max_leaves': 54, 'learning_rate': 0.04335186975552169, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:30] {506} INFO - trial 49 config: {'n_estimators': 3992, 'max_leaves': 14, 'learning_rate': 0.005902481455333757, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:30] {506} INFO - trial 50 config: {'n_estimators': 1332, 'max_leaves': 2032, 'learning_rate': 0.005114224731719409, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:30] {506} INFO - trial 51 config: {'n_estimators': 584, 'max_leaves': 39, 'learning_rate': 0.4763308566342319, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:30] {506} INFO - trial 52 config: {'n_estimators': 394, 'max_leaves': 1349, 'learning_rate': 0.15573324989369033, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:30] {506} INFO - trial 53 config: {'n_estimators': 1137, 'max_leaves': 22, 'learning_rate': 0.30657057312024644, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:31] {506} INFO - trial 54 config: {'n_estimators': 2881, 'max_leaves': 19, 'learning_rate': 0.003592649684962099, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:31] {506} INFO - trial 55 config: {'n_estimators': 424, 'max_leaves': 11, 'learning_rate': 0.2826008095299387, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:31] {506} INFO - trial 56 config: {'n_estimators': 7415, 'max_leaves': 9, 'learning_rate': 0.41144344654042997, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:31] {506} INFO - trial 57 config: {'n_estimators': 5525, 'max_leaves': 278, 'learning_rate': 0.9784854203265464, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:31] {506} INFO - trial 58 config: {'n_estimators': 2407, 'max_leaves': 257, 'learning_rate': 0.7924698570749448, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:31] {506} INFO - trial 59 config: {'n_estimators': 2586, 'max_leaves': 1133, 'learning_rate': 0.668218029499765, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:31] {506} INFO - trial 60 config: {'n_estimators': 5525, 'max_leaves': 443, 'learning_rate': 0.16378510208856667, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:31] {506} INFO - trial 61 config: {'n_estimators': 9220, 'max_leaves': 4, 'learning_rate': 0.36062762370731777, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:31] {506} INFO - trial 62 config: {'n_estimators': 13127, 'max_leaves': 2778, 'learning_rate': 0.00222017541525974, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:31] {506} INFO - trial 63 config: {'n_estimators': 30, 'max_leaves': 1436, 'learning_rate': 0.0026028422881987055, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:31] {506} INFO - trial 64 config: {'n_estimators': 201, 'max_leaves': 475, 'learning_rate': 0.011324773041374265, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:31] {506} INFO - trial 65 config: {'n_estimators': 18941, 'max_leaves': 4223, 'learning_rate': 0.025865362181268114, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 66 config: {'n_estimators': 146, 'max_leaves': 4821, 'learning_rate': 0.0034154784329390535, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 67 config: {'n_estimators': 101, 'max_leaves': 7778, 'learning_rate': 0.052572695809586165, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 68 config: {'n_estimators': 275, 'max_leaves': 2819, 'learning_rate': 0.07081648034307593, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 69 config: {'n_estimators': 110, 'max_leaves': 65, 'learning_rate': 0.012107530127793, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 70 config: {'n_estimators': 73, 'max_leaves': 587, 'learning_rate': 0.008061889806716868, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 71 config: {'n_estimators': 12, 'max_leaves': 134, 'learning_rate': 0.009322413215086983, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 72 config: {'n_estimators': 216, 'max_leaves': 122, 'learning_rate': 0.020857393898663115, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 73 config: {'n_estimators': 312, 'max_leaves': 186, 'learning_rate': 0.014177007227519758, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 74 config: {'n_estimators': 1473, 'max_leaves': 20, 'learning_rate': 0.5282804782911118, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 75 config: {'n_estimators': 364, 'max_leaves': 23, 'learning_rate': 0.005958043358657801, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 76 config: {'n_estimators': 446, 'max_leaves': 43, 'learning_rate': 0.004775130134948399, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 77 config: {'n_estimators': 1219, 'max_leaves': 10, 'learning_rate': 0.3779589262687463, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:32] {506} INFO - trial 78 config: {'n_estimators': 1401, 'max_leaves': 10, 'learning_rate': 0.28038134184632646, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:33] {506} INFO - trial 79 config: {'n_estimators': 6628, 'max_leaves': 6, 'learning_rate': 0.47891449595724667, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:33] {506} INFO - trial 80 config: {'n_estimators': 8308, 'max_leaves': 30, 'learning_rate': 0.447042664449934, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:33] {506} INFO - trial 81 config: {'n_estimators': 2232, 'max_leaves': 302, 'learning_rate': 0.9413848630987627, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:33] {506} INFO - trial 82 config: {'n_estimators': 3008, 'max_leaves': 19, 'learning_rate': 0.6617776883804151, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:33] {506} INFO - trial 83 config: {'n_estimators': 4676, 'max_leaves': 831, 'learning_rate': 0.729098750582734, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:33] {506} INFO - trial 84 config: {'n_estimators': 9073, 'max_leaves': 7, 'learning_rate': 0.6999001097029152, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:33] {506} INFO - trial 85 config: {'n_estimators': 12097, 'max_leaves': 365, 'learning_rate': 0.23076401336141383, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:33] {506} INFO - trial 86 config: {'n_estimators': 6076, 'max_leaves': 15976, 'learning_rate': 0.3771793556881001, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:33] {506} INFO - trial 87 config: {'n_estimators': 4, 'max_leaves': 1072, 'learning_rate': 0.8133197504691136, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:33] {506} INFO - trial 88 config: {'n_estimators': 15851, 'max_leaves': 1532, 'learning_rate': 0.0026562675065994125, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:34] {506} INFO - trial 89 config: {'n_estimators': 10539, 'max_leaves': 469, 'learning_rate': 0.0020422601196322786, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:34] {506} INFO - trial 90 config: {'n_estimators': 35, 'max_leaves': 2692, 'learning_rate': 0.0025090165260535893, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:34] {506} INFO - trial 91 config: {'n_estimators': 31, 'max_leaves': 3981, 'learning_rate': 0.0030253535104938114, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:34] {506} INFO - trial 92 config: {'n_estimators': 18188, 'max_leaves': 4341, 'learning_rate': 0.0013359200355607022, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:34] {506} INFO - trial 93 config: {'n_estimators': 115, 'max_leaves': 6603, 'learning_rate': 0.021098867037444867, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:34] {506} INFO - trial 94 config: {'n_estimators': 153, 'max_leaves': 5730, 'learning_rate': 0.12902679796448774, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:34] {506} INFO - trial 95 config: {'n_estimators': 109, 'max_leaves': 2582, 'learning_rate': 0.07080984320878844, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:34] {506} INFO - trial 96 config: {'n_estimators': 86, 'max_leaves': 8478, 'learning_rate': 0.038435592425912324, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:34] {506} INFO - trial 97 config: {'n_estimators': 59, 'max_leaves': 5035, 'learning_rate': 0.007798167307370056, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:34] {506} INFO - trial 98 config: {'n_estimators': 16, 'max_leaves': 10730, 'learning_rate': 0.009894614910177672, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:34] {506} INFO - trial 99 config: {'n_estimators': 131, 'max_leaves': 127, 'learning_rate': 0.015268661873095089, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:34] {506} INFO - trial 100 config: {'n_estimators': 211, 'max_leaves': 57, 'learning_rate': 0.019426510247163038, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 101 config: {'n_estimators': 282, 'max_leaves': 127, 'learning_rate': 0.013917381016486404, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 102 config: {'n_estimators': 82, 'max_leaves': 213, 'learning_rate': 0.03215891352653318, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 103 config: {'n_estimators': 298, 'max_leaves': 73, 'learning_rate': 0.008842202108353148, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 104 config: {'n_estimators': 232, 'max_leaves': 102, 'learning_rate': 0.0066980336616668445, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 105 config: {'n_estimators': 392, 'max_leaves': 45, 'learning_rate': 0.004550516087330994, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 106 config: {'n_estimators': 8, 'max_leaves': 28, 'learning_rate': 0.013639473182140692, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 107 config: {'n_estimators': 1308, 'max_leaves': 71, 'learning_rate': 0.0050708287994836255, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 108 config: {'n_estimators': 879, 'max_leaves': 41, 'learning_rate': 0.006461510915459239, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 109 config: {'n_estimators': 1642, 'max_leaves': 5, 'learning_rate': 0.009620046518012432, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 110 config: {'n_estimators': 759, 'max_leaves': 10, 'learning_rate': 0.5582224182204506, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 111 config: {'n_estimators': 528, 'max_leaves': 16, 'learning_rate': 0.47482418104411844, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 112 config: {'n_estimators': 2055, 'max_leaves': 28, 'learning_rate': 0.5549732420567667, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:35] {506} INFO - trial 113 config: {'n_estimators': 2169, 'max_leaves': 19, 'learning_rate': 0.5973102809665856, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 08-19 14:44:36] {506} INFO - trial 114 config: {'n_estimators': 4191, 'max_leaves': 29, 'learning_rate': 0.45841248810094576, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best result w/ flaml scheduler (in 10s):  {'loss': 0.2393039918116684, 'training_iteration': 0, 'config': {'n_estimators': 9, 'max_leaves': 1364, 'learning_rate': 0.012074374674294664, 'sample_size': 1000}, 'config/n_estimators': 9, 'config/max_leaves': 1364, 'config/learning_rate': 0.012074374674294664, 'config/sample_size': 1000, 'experiment_tag': 'exp', 'time_total_s': 0.07670164108276367}\n"
     ]
    }
   ],
   "source": [
    "from flaml import tune\n",
    "from functools import partial\n",
    "from flaml.data import load_openml_task\n",
    "    \n",
    "X_train, X_test, y_train, y_test = load_openml_task(task_id=7592, data_dir=\"\")\n",
    "max_resource = len(y_train)\n",
    "resource_attr = \"sample_size\"\n",
    "min_resource = 1000\n",
    "analysis = tune.run(\n",
    "    partial(\n",
    "        obj_from_resource_attr, resource_attr, X_train, X_test, y_train, y_test\n",
    "    ),\n",
    "    config=search_space,\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    resource_attr=resource_attr,\n",
    "    scheduler=\"flaml\",\n",
    "    max_resource=max_resource,\n",
    "    min_resource=min_resource,\n",
    "    reduction_factor=2,\n",
    "    time_budget_s=10,\n",
    "    num_samples=-1,\n",
    ")\n",
    "print(\"best result w/ flaml scheduler (in 10s): \", analysis.best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ASHA scheduler (`scheduler='asha'`) or a custom scheduler of the  [`TrialScheduler`](https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#tune-schedulers) class from `ray.tune`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_w_intermediate_report(\n",
    "        resource_attr,\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        min_resource,\n",
    "        max_resource,\n",
    "        config,\n",
    "    ):\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # a customized schedule to perform the evaluation\n",
    "    eval_schedule = [res for res in range(min_resource, max_resource, 5000)] + [\n",
    "        max_resource\n",
    "    ]\n",
    "    for resource in eval_schedule:\n",
    "        sampled_X_train = X_train.iloc[:resource]\n",
    "        sampled_y_train = y_train[:resource]\n",
    "\n",
    "        # construct a LGBM model from the config\n",
    "        model = LGBMClassifier(**config)\n",
    "\n",
    "        model.fit(sampled_X_train, sampled_y_train)\n",
    "        y_test_predict = model.predict(X_test)\n",
    "        test_loss = 1.0 - accuracy_score(y_test, y_test_predict)\n",
    "        # need to report the resource attribute used and the corresponding intermediate results\n",
    "        try:\n",
    "            tune.report(sample_size=resource, loss=test_loss)\n",
    "        except StopIteration:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 14:44:36,536\tWARNING optuna.py:297 -- You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-08-19 14:44:36,538]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 08-19 14:44:36] {506} INFO - trial 1 config: {'n_estimators': 9, 'max_leaves': 1364, 'learning_rate': 0.012074374674294664}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset from openml_task7592.pkl\n",
      "X_train.shape: (43957, 14), y_train.shape: (43957,),\n",
      "X_test.shape: (4885, 14), y_test.shape: (4885,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 08-19 14:44:37] {506} INFO - trial 2 config: {'n_estimators': 4048, 'max_leaves': 4, 'learning_rate': 0.07891713267442702}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_openml_task(task_id=7592, data_dir=\"\")\n",
    "resource_attr = \"sample_size\"\n",
    "min_resource = 1000\n",
    "max_resource = len(y_train)\n",
    "analysis = tune.run(\n",
    "    partial(\n",
    "        obj_w_intermediate_report,\n",
    "        resource_attr,\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        min_resource,\n",
    "        max_resource,\n",
    "    ),\n",
    "    config=search_space,\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    resource_attr=resource_attr,\n",
    "    scheduler=\"asha\",\n",
    "    max_resource=max_resource,\n",
    "    min_resource=min_resource,\n",
    "    reduction_factor=2,\n",
    "    time_budget_s=10,\n",
    "    num_samples=-1,\n",
    ")\n",
    "print(\"best result w/ asha scheduler (in 10s): \", analysis.best_result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61dacc07bdd67a6bd133ad154042152699ffea5858044733f84b495e7a4b9e6a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('myflaml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
