{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook includes toy examples to demonstrate how to tune User Defined Functions with `flaml.tune`.\n",
    "\n",
    "FLAML requires `Python>=3.7`. To run this notebook example, please install flaml with the `notebook` option:\n",
    "```bash\n",
    "pip install flaml[notebook]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flaml[notebook]\n",
    "# from v0.6.6, catboost is made an optional dependency to build conda package.\n",
    "# to install catboost without installing the notebook option, you can run:\n",
    "# %pip install flaml[catboost]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic tuning procedure\n",
    "## 1. A basic tuning example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set a search space'''\n",
    "from flaml import tune\n",
    "config_search_space = {\n",
    "    \"x\": tune.lograndint(lower=1, upper=100000),\n",
    "    \"y\": tune.randint(lower=1, upper=100000)\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Write a evaluation function'''\n",
    "import time\n",
    "def evaluate_config(config: dict):\n",
    "    \"\"\"evaluate a hyperparameter configuration\"\"\"\n",
    "    score = (config[\"x\"] - 85000) ** 2 - config[\"x\"] / config[\"y\"]\n",
    "    # usually the evaluation takes an non-neglible cost\n",
    "    # and the cost could be related to certain hyperparameters\n",
    "    # here we simulate this cost by calling the time.sleep() function\n",
    "    # here we assume the cost is proportional to x\n",
    "    faked_evaluation_cost = config[\"x\"] / 100000\n",
    "    time.sleep(faked_evaluation_cost)\n",
    "    # we can return a single float as a score on the input config:\n",
    "    # return score\n",
    "    # or, we can return a dictionary that maps metric name to metric value:\n",
    "    return {\"score\": score, \"evaluation_cost\": faked_evaluation_cost, \"constraint_metric\": config[\"x\"] * config[\"y\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-07-07 04:02:16,168]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 07-07 04:02:16] {506} INFO - trial 1 config: {'x': 3, 'y': 13184}\n",
      "[flaml.tune.tune: 07-07 04:02:16] {506} INFO - trial 2 config: {'x': 6134, 'y': 2076}\n",
      "[flaml.tune.tune: 07-07 04:02:16] {506} INFO - trial 3 config: {'x': 1143, 'y': 74880}\n",
      "[flaml.tune.tune: 07-07 04:02:16] {506} INFO - trial 4 config: {'x': 5539, 'y': 1}\n",
      "[flaml.tune.tune: 07-07 04:02:16] {506} INFO - trial 5 config: {'x': 6793, 'y': 16190}\n",
      "[flaml.tune.tune: 07-07 04:02:16] {506} INFO - trial 6 config: {'x': 220, 'y': 22480}\n",
      "[flaml.tune.tune: 07-07 04:02:16] {506} INFO - trial 7 config: {'x': 6, 'y': 76053}\n",
      "[flaml.tune.tune: 07-07 04:02:16] {506} INFO - trial 8 config: {'x': 4, 'y': 8834}\n",
      "[flaml.tune.tune: 07-07 04:02:16] {506} INFO - trial 9 config: {'x': 2148, 'y': 95339}\n",
      "[flaml.tune.tune: 07-07 04:02:16] {506} INFO - trial 10 config: {'x': 1, 'y': 51219}\n",
      "[flaml.tune.tune: 07-07 04:02:16] {506} INFO - trial 11 config: {'x': 10155, 'y': 61252}\n",
      "[flaml.tune.tune: 07-07 04:02:16] {506} INFO - trial 12 config: {'x': 51672, 'y': 61799}\n",
      "[flaml.tune.tune: 07-07 04:02:17] {506} INFO - trial 13 config: {'x': 18407, 'y': 72736}\n",
      "[flaml.tune.tune: 07-07 04:02:17] {506} INFO - trial 14 config: {'x': 99999, 'y': 50862}\n",
      "[flaml.tune.tune: 07-07 04:02:18] {506} INFO - trial 15 config: {'x': 2, 'y': 372}\n",
      "[flaml.tune.tune: 07-07 04:02:18] {506} INFO - trial 16 config: {'x': 99999, 'y': 39100}\n",
      "[flaml.tune.tune: 07-07 04:02:19] {506} INFO - trial 17 config: {'x': 40494, 'y': 50862}\n",
      "[flaml.tune.tune: 07-07 04:02:19] {506} INFO - trial 18 config: {'x': 60615, 'y': 25643}\n",
      "[flaml.tune.tune: 07-07 04:02:20] {506} INFO - trial 19 config: {'x': 99999, 'y': 52557}\n",
      "[flaml.tune.tune: 07-07 04:02:21] {506} INFO - trial 20 config: {'x': 3350, 'y': 29188}\n",
      "[flaml.tune.tune: 07-07 04:02:21] {506} INFO - trial 21 config: {'x': 36654, 'y': 71457}\n",
      "[flaml.tune.tune: 07-07 04:02:21] {506} INFO - trial 22 config: {'x': 376, 'y': 14217}\n",
      "[flaml.tune.tune: 07-07 04:02:21] {506} INFO - trial 23 config: {'x': 99999, 'y': 64368}\n",
      "[flaml.tune.tune: 07-07 04:02:22] {506} INFO - trial 24 config: {'x': 51439, 'y': 97709}\n",
      "[flaml.tune.tune: 07-07 04:02:23] {506} INFO - trial 25 config: {'x': 73238, 'y': 99999}\n",
      "[flaml.tune.tune: 07-07 04:02:23] {506} INFO - trial 26 config: {'x': 24442, 'y': 71457}\n",
      "[flaml.tune.tune: 07-07 04:02:24] {506} INFO - trial 27 config: {'x': 60949, 'y': 50896}\n",
      "[flaml.tune.tune: 07-07 04:02:24] {506} INFO - trial 28 config: {'x': 51439, 'y': 86194}\n",
      "[flaml.tune.tune: 07-07 04:02:25] {506} INFO - trial 29 config: {'x': 99999, 'y': 77840}\n"
     ]
    }
   ],
   "source": [
    "''''Performs tuning'''\n",
    "# require: pip install flaml[blendsearch]\n",
    "analysis = tune.run(\n",
    "    evaluate_config,  # the function to evaluate a config\n",
    "    config=config_search_space,  # the search space defined\n",
    "    metric=\"score\",\n",
    "    mode=\"min\",  # the optimization mode, \"min\" or \"max\"\n",
    "    num_samples=-1,  # the maximal number of configs to try, -1 means infinite\n",
    "    time_budget_s=10,  # the time budget in seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 138344643.26761267, 'evaluation_cost': 0.73238, 'constraint_metric': 7323726762, 'training_iteration': 0, 'config': {'x': 73238, 'y': 99999}, 'config/x': 73238, 'config/y': 99999, 'experiment_tag': 'exp', 'time_total_s': 0.7350201606750488}\n"
     ]
    }
   ],
   "source": [
    "'''Investigate results'''\n",
    "print(analysis.best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical search space \n",
    "Hierarchical search space is supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set a hierarchical search space'''\n",
    "from flaml import tune\n",
    "gbtree_hp_space = {\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"n_estimators\": tune.lograndint(lower=4, upper=64),\n",
    "        \"max_leaves\": tune.lograndint(lower=4, upper=64),\n",
    "        \"learning_rate\": tune.loguniform(lower=1 / 1024, upper=1.0),\n",
    "    }\n",
    "gblinear_hp_space = {\n",
    "    \"booster\": \"gblinear\",\n",
    "    \"lambda\": tune.uniform(0, 1),\n",
    "    \"alpha\": tune.loguniform(0.0001, 1),\n",
    "}\n",
    "\n",
    "full_space = {\n",
    "    \"xgb_config\": tune.choice([gbtree_hp_space, gblinear_hp_space]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Write a evaluation function'''\n",
    "import xgboost as xgb\n",
    "def xgb_obj(X_train, X_test, y_train, y_test, config):\n",
    "    config = config[\"xgb_config\"]\n",
    "    params = config2params(config)\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    booster_type = config.get(\"booster\")\n",
    "\n",
    "    if booster_type == \"gblinear\":\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "        )\n",
    "    else:\n",
    "        _n_estimators = params.pop(\"n_estimators\")\n",
    "        model = xgb.train(params, dtrain, _n_estimators)\n",
    "\n",
    "    # get validation loss\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    y_test_predict = model.predict(dtest)\n",
    "    test_loss = 1.0 - r2_score(y_test, y_test_predict)\n",
    "    return {\"loss\": test_loss}\n",
    "\n",
    "def config2params(config: dict) -> dict:\n",
    "    params = config.copy()\n",
    "    max_depth = params[\"max_depth\"] = params.get(\"max_depth\", 0)\n",
    "    if max_depth == 0:\n",
    "        params[\"grow_policy\"] = params.get(\"grow_policy\", \"lossguide\")\n",
    "        params[\"tree_method\"] = params.get(\"tree_method\", \"hist\")\n",
    "    # params[\"booster\"] = params.get(\"booster\", \"gbtree\")\n",
    "    params[\"use_label_encoder\"] = params.get(\"use_label_encoder\", False)\n",
    "    if \"n_jobs\" in config:\n",
    "        params[\"nthread\"] = params.pop(\"n_jobs\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-07 04:02:27,568]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 07-07 04:02:27] {506} INFO - trial 1 config: {'xgb_config': {'booster': 'gblinear', 'lambda': 0.6472660813321921, 'alpha': 0.0028264214081400014}}\n",
      "/home/qxw5138/miniconda3/envs/myflaml/lib/python3.8/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "[flaml.tune.tune: 07-07 04:02:27] {506} INFO - trial 2 config: {'xgb_config': {'n_estimators': 22, 'max_leaves': 31, 'learning_rate': 0.0309282737630552, 'booster': 'gbtree'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset from ./openml_ds537.pkl\n",
      "Dataset name: houses\n",
      "X_train.shape: (15480, 8), y_train.shape: (15480,);\n",
      "X_test.shape: (5160, 8), y_test.shape: (5160,)\n",
      "[04:02:27] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { grow_policy, max_depth, tree_method, use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:02:27] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qxw5138/miniconda3/envs/myflaml/lib/python3.8/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "[flaml.tune.tune: 07-07 04:02:27] {506} INFO - trial 3 config: {'xgb_config': {'n_estimators': 32, 'max_leaves': 6, 'learning_rate': 0.0018014797394283806, 'booster': 'gbtree'}}\n",
      "/home/qxw5138/miniconda3/envs/myflaml/lib/python3.8/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "[flaml.tune.tune: 07-07 04:02:27] {506} INFO - trial 4 config: {'xgb_config': {'n_estimators': 21, 'max_leaves': 21, 'learning_rate': 0.06308266770250766, 'booster': 'gbtree'}}\n",
      "/home/qxw5138/miniconda3/envs/myflaml/lib/python3.8/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "[flaml.tune.tune: 07-07 04:02:27] {506} INFO - trial 5 config: {'xgb_config': {'n_estimators': 44, 'max_leaves': 6, 'learning_rate': 0.0009765625, 'booster': 'gbtree'}}\n",
      "/home/qxw5138/miniconda3/envs/myflaml/lib/python3.8/site-packages/xgboost/data.py:192: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:02:27] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:02:27] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:02:27] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "analysis {'49e42716': {'loss': 422.4636187077617, 'training_iteration': 0, 'config': {'xgb_config': {'booster': 'gblinear', 'lambda': 0.6472660813321921, 'alpha': 0.0028264214081400014}}, 'config/xgb_config': {'booster': 'gblinear', 'lambda': 0.6472660813321921, 'alpha': 0.0028264214081400014}, 'experiment_tag': 'exp', 'time_total_s': 0.08394932746887207}, '49e42717': {'loss': 1.291006987963745, 'training_iteration': 0, 'config': {'xgb_config': {'n_estimators': 22, 'max_leaves': 31, 'learning_rate': 0.0309282737630552, 'booster': 'gbtree'}}, 'config/xgb_config': {'n_estimators': 22, 'max_leaves': 31, 'learning_rate': 0.0309282737630552, 'booster': 'gbtree'}, 'experiment_tag': 'exp', 'time_total_s': 0.13451027870178223}, '49e42718': {'loss': 3.781676744261694, 'training_iteration': 0, 'config': {'xgb_config': {'n_estimators': 32, 'max_leaves': 6, 'learning_rate': 0.0018014797394283806, 'booster': 'gbtree'}}, 'config/xgb_config': {'n_estimators': 32, 'max_leaves': 6, 'learning_rate': 0.0018014797394283806, 'booster': 'gbtree'}, 'experiment_tag': 'exp', 'time_total_s': 0.06412291526794434}, '49e42719': {'loss': 0.5705721607799167, 'training_iteration': 0, 'config': {'xgb_config': {'n_estimators': 21, 'max_leaves': 21, 'learning_rate': 0.06308266770250766, 'booster': 'gbtree'}}, 'config/xgb_config': {'n_estimators': 21, 'max_leaves': 21, 'learning_rate': 0.06308266770250766, 'booster': 'gbtree'}, 'experiment_tag': 'exp', 'time_total_s': 0.09098315238952637}, '49e4271a': {'loss': 3.879518423538136, 'training_iteration': 0, 'config': {'xgb_config': {'n_estimators': 44, 'max_leaves': 6, 'learning_rate': 0.0009765625, 'booster': 'gbtree'}}, 'config/xgb_config': {'n_estimators': 44, 'max_leaves': 6, 'learning_rate': 0.0009765625, 'booster': 'gbtree'}, 'experiment_tag': 'exp', 'time_total_s': 0.13361477851867676}}\n"
     ]
    }
   ],
   "source": [
    "'''Tune xgb_obj with configs from the hierarchical search space'''\n",
    "from flaml.data import load_openml_dataset\n",
    "from functools import partial\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_openml_dataset(\n",
    "    dataset_id=537, data_dir=\"./\"\n",
    ")\n",
    "analysis = tune.run(\n",
    "    partial(xgb_obj, X_train, X_test, y_train, y_test),\n",
    "    config=full_space,\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    num_samples=5,\n",
    ")\n",
    "print(\"analysis\", analysis.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Tuning Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Constraints on the tuning\n",
    "\n",
    "1. A user can specify constraints on the configurations to be satisfied via the argument `config_constraints`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-07-07 04:02:28,659]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 07-07 04:02:28] {506} INFO - trial 1 config: {'width': 1, 'height': 132, 'length': 647}\n",
      "[flaml.tune.tune: 07-07 04:02:28] {506} INFO - trial 2 config: {'width': 2, 'height': 760, 'length': 169}\n",
      "[flaml.tune.tune: 07-07 04:02:28] {506} INFO - trial 3 config: {'width': 1, 'height': 685, 'length': 953}\n",
      "[flaml.tune.tune: 07-07 04:02:28] {506} INFO - trial 4 config: {'width': 1, 'height': 512, 'length': 812}\n",
      "[flaml.tune.tune: 07-07 04:02:28] {506} INFO - trial 5 config: {'width': 1, 'height': 373, 'length': 674}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'volume': 85404, 'training_iteration': 0, 'config': {'width': 1, 'height': 132, 'length': 647}, 'config/width': 1, 'config/height': 132, 'config/length': 647, 'experiment_tag': 'exp', 'time_total_s': 0.0014650821685791016}\n"
     ]
    }
   ],
   "source": [
    "from flaml import tune\n",
    "def area(config):\n",
    "    return config[\"width\"] * config[\"length\"]\n",
    "\n",
    "cube_search_space = {\n",
    "    \"width\": tune.lograndint(lower=1, upper=1000),\n",
    "    \"height\": tune.randint(lower=1, upper=1000),\n",
    "    \"length\": tune.randint(lower=1, upper=1000),\n",
    "}\n",
    "\n",
    "def cube_volume(config: dict):\n",
    "    \"\"\"evaluate a hyperparameter configuration\"\"\"\n",
    "    score = config[\"width\"] * config[\"height\"] * config[\"length\"]\n",
    "    return {\"volume\": score}\n",
    "\n",
    "analysis = tune.run(evaluation_function=cube_volume,\n",
    "         mode=\"min\",\n",
    "         metric=\"volume\",\n",
    "         config=cube_search_space,\n",
    "         config_constraints=[(area, \"<=\", 1000)],\n",
    "         num_samples=5,\n",
    "        )\n",
    "print(analysis.best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  You can also specify a list of metric constraints to be satisfied via the argument `metric_constraints`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-07-07 04:03:36,539]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 07-07 04:03:36] {506} INFO - trial 1 config: {'x': 3, 'y': 13184}\n",
      "[flaml.tune.tune: 07-07 04:03:36] {506} INFO - trial 2 config: {'x': 6134, 'y': 2076}\n",
      "[flaml.tune.tune: 07-07 04:03:36] {506} INFO - trial 3 config: {'x': 1143, 'y': 74880}\n",
      "[flaml.tune.tune: 07-07 04:03:36] {506} INFO - trial 4 config: {'x': 5539, 'y': 1}\n",
      "[flaml.tune.tune: 07-07 04:03:36] {506} INFO - trial 5 config: {'x': 6793, 'y': 16190}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<flaml.tune.tune.ExperimentAnalysis at 0x7fab68115fd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flaml import tune\n",
    "tune.run(evaluation_function=evaluate_config,\n",
    "         mode=\"min\",\n",
    "         metric=\"score\",\n",
    "         config=config_search_space,\n",
    "         metric_constraints=[(\"evaluation_cost\", \"<=\", 0.1)],\n",
    "         num_samples=5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install flaml[ray]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-07-07 04:04:55,820]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "2022-07-07 04:04:59,245\tWARNING function_runner.py:603 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "2022-07-07 04:04:59,774\tWARNING tune.py:668 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-07 04:05:01 (running for 00:00:01.74)<br>Memory usage on this node: 35.9/503.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/48 CPUs, 0/4 GPUs, 0.0/320.52 GiB heap, 0.0/141.36 GiB objects<br>Result logdir: /home/qxw5138/ray_results/evaluate_config_2022-07-07_04-04-59<br>Number of trials: 1/infinite (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial evaluate_config_a49d1df2 reported score=7224490009.00 with parameters={'x': 3, 'y': 13184}.\n",
      "Trial evaluate_config_a49d1df2 completed. Last result: score=7224490008.999772,evaluation_cost=3e-05,constraint_metric=39552\n",
      "Trial evaluate_config_a5a79c2d reported score=7031996448.98 with parameters={'x': 1143, 'y': 74880}.\n",
      "Trial evaluate_config_a5a79c2d completed. Last result: score=7031996448.9847355,evaluation_cost=0.01143,constraint_metric=85587840\n",
      "Trial evaluate_config_a5a79c2f reported score=7223980036.00 with parameters={'x': 6, 'y': 76053}.\n",
      "Trial evaluate_config_a5a79c2f completed. Last result: score=7223980035.999921,evaluation_cost=6e-05,constraint_metric=456318\n",
      "Trial evaluate_config_a5a79c31 reported score=6864453903.98 with parameters={'x': 2148, 'y': 95339}.\n",
      "Trial evaluate_config_a5a79c31 completed. Last result: score=6864453903.977469,evaluation_cost=0.02148,constraint_metric=204788172\n",
      "Trial evaluate_config_a5a79c34 reported score=6303883608.92 with parameters={'x': 5603, 'y': 71825}.\n",
      "Trial evaluate_config_a5a79c34 completed. Last result: score=6303883608.921991,evaluation_cost=0.05603,constraint_metric=402435475\n",
      "Trial evaluate_config_a5a79c38 reported score=6236260899.93 with parameters={'x': 6030, 'y': 84402}.\n",
      "Trial evaluate_config_a5a79c38 completed. Last result: score=6236260899.928556,evaluation_cost=0.0603,constraint_metric=508944060\n",
      "Trial evaluate_config_a5a79c3a reported score=6767201168.95 with parameters={'x': 2737, 'y': 59126}.\n",
      "Trial evaluate_config_a5a79c3a completed. Last result: score=6767201168.953709,evaluation_cost=0.02737,constraint_metric=161827862\n",
      "Trial evaluate_config_a5a79c3d reported score=6413607224.94 with parameters={'x': 4915, 'y': 78908}.\n",
      "Trial evaluate_config_a5a79c3d completed. Last result: score=6413607224.937713,evaluation_cost=0.04915,constraint_metric=387832820\n",
      "Trial evaluate_config_a5a79c41 reported score=7224830001.00 with parameters={'x': 1, 'y': 51219}.\n",
      "Trial evaluate_config_a5a79c41 completed. Last result: score=7224830000.999981,evaluation_cost=1e-05,constraint_metric=51219\n",
      "Trial evaluate_config_a5a79c43 reported score=6666722499.89 with parameters={'x': 3350, 'y': 29188}.\n",
      "Trial evaluate_config_a5a79c43 completed. Last result: score=6666722499.885227,evaluation_cost=0.0335,constraint_metric=97779800\n",
      "Trial evaluate_config_a5a79c46 reported score=7216842304.00 with parameters={'x': 48, 'y': 67413}.\n",
      "Trial evaluate_config_a5a79c46 completed. Last result: score=7216842303.999288,evaluation_cost=0.00048,constraint_metric=3235824\n",
      "Trial evaluate_config_a5a79c48 reported score=7065915480.98 with parameters={'x': 941, 'y': 51314}.\n",
      "Trial evaluate_config_a5a79c48 completed. Last result: score=7065915480.981662,evaluation_cost=0.00941,constraint_metric=48286474\n",
      "Trial evaluate_config_a5a79c4b reported score=2725884098.97 with parameters={'x': 32790, 'y': 31924}.\n",
      "Trial evaluate_config_a5a79c4b completed. Last result: score=2725884098.972873,evaluation_cost=0.3279,constraint_metric=1046787960\n",
      "Trial evaluate_config_a5a79c50 reported score=7223980036.00 with parameters={'x': 6, 'y': 85685}.\n",
      "Trial evaluate_config_a5a79c50 completed. Last result: score=7223980035.99993,evaluation_cost=6e-05,constraint_metric=514110\n",
      "Trial evaluate_config_a5a79c2c reported score=6219845953.05 with parameters={'x': 6134, 'y': 2076}.\n",
      "Trial evaluate_config_a5a79c2c completed. Last result: score=6219845953.0452795,evaluation_cost=0.06134,constraint_metric=12734184\n",
      "Trial evaluate_config_a5a79c30 reported score=7224320016.00 with parameters={'x': 4, 'y': 8834}.\n",
      "Trial evaluate_config_a5a79c30 completed. Last result: score=7224320015.999547,evaluation_cost=4e-05,constraint_metric=35336\n",
      "Trial evaluate_config_a5a79c2e reported score=7187648399.99 with parameters={'x': 220, 'y': 22480}.\n",
      "Trial evaluate_config_a5a79c2e completed. Last result: score=7187648399.990213,evaluation_cost=0.0022,constraint_metric=4945600\n",
      "Trial evaluate_config_a694ab49 reported score=5926690224.79 with parameters={'x': 8015, 'y': 39013}.\n",
      "Trial evaluate_config_a694ab49 completed. Last result: score=5926690224.794556,evaluation_cost=0.08015,constraint_metric=312689195\n",
      "Trial evaluate_config_a694ab4a reported score=4226950223.92 with parameters={'x': 19985, 'y': 18452}.\n",
      "Trial evaluate_config_a694ab4a completed. Last result: score=4226950223.9169197,evaluation_cost=0.19985,constraint_metric=368763220\n",
      "Trial evaluate_config_a5a79c32 reported score=7050625023.98 with parameters={'x': 1032, 'y': 60766}.\n",
      "Trial evaluate_config_a5a79c32 completed. Last result: score=7050625023.983017,evaluation_cost=0.01032,constraint_metric=62710512\n",
      "Trial evaluate_config_a5a79c36 reported score=7153438084.00 with parameters={'x': 422, 'y': 94792}.\n",
      "Trial evaluate_config_a5a79c33 reported score=7011382755.99 with parameters={'x': 1266, 'y': 88994}.\n",
      "Trial evaluate_config_a5a79c36 completed. Last result: score=7153438083.995548,evaluation_cost=0.00422,constraint_metric=40002224\n",
      "Trial evaluate_config_a5a79c35 reported score=5486364899.89 with parameters={'x': 10930, 'y': 95886}.\n",
      "Trial evaluate_config_a5a79c33 completed. Last result: score=7011382755.985774,evaluation_cost=0.01266,constraint_metric=112666404\n",
      "Trial evaluate_config_a5a79c35 completed. Last result: score=5486364899.88601,evaluation_cost=0.1093,constraint_metric=1048033980\n",
      "Trial evaluate_config_a694ab4b reported score=973564802.81 with parameters={'x': 53798, 'y': 45396}.\n",
      "Trial evaluate_config_a694ab4b completed. Last result: score=973564802.8149176,evaluation_cost=0.53798,constraint_metric=2442214008\n",
      "Trial evaluate_config_a5a79c37 reported score=7095535224.99 with parameters={'x': 765, 'y': 99999}.\n",
      "Trial evaluate_config_a5a79c3c reported score=6533650560.95 with parameters={'x': 4169, 'y': 89204}.\n",
      "Trial evaluate_config_a5a79c37 completed. Last result: score=7095535224.99235,evaluation_cost=0.00765,constraint_metric=76499235\n",
      "Trial evaluate_config_a5a79c3c completed. Last result: score=6533650560.953264,evaluation_cost=0.04169,constraint_metric=371891476\n",
      "Trial evaluate_config_a694ab4d reported score=1563727928.93 with parameters={'x': 45456, 'y': 6432}.\n",
      "Trial evaluate_config_a694ab4d completed. Last result: score=1563727928.9328358,evaluation_cost=0.45456,constraint_metric=292372992\n",
      "Trial evaluate_config_a5a79c3f reported score=5406660899.86 with parameters={'x': 11470, 'y': 84524}.\n",
      "Trial evaluate_config_a5a79c3f completed. Last result: score=5406660899.864299,evaluation_cost=0.1147,constraint_metric=969490280\n",
      "Trial evaluate_config_a5a79c3e reported score=6022225608.92 with parameters={'x': 7397, 'y': 89896}.\n",
      "Trial evaluate_config_a5a79c3e completed. Last result: score=6022225608.917716,evaluation_cost=0.07397,constraint_metric=664960712\n",
      "Trial evaluate_config_a5a79c40 reported score=4777574399.74 with parameters={'x': 15880, 'y': 60957}.\n",
      "Trial evaluate_config_a694ab48 reported score=224969996.97 with parameters={'x': 99999, 'y': 24835}.\n",
      "Trial evaluate_config_a5a79c40 completed. Last result: score=4777574399.739489,evaluation_cost=0.1588,constraint_metric=967997160\n",
      "Trial evaluate_config_a694ab48 completed. Last result: score=224969996.97346488,evaluation_cost=0.99999,constraint_metric=2483475165\n",
      "Trial evaluate_config_a5a79c3b reported score=5818333283.89 with parameters={'x': 8722, 'y': 79600}.\n",
      "Trial evaluate_config_a5a79c3b completed. Last result: score=5818333283.890428,evaluation_cost=0.08722,constraint_metric=694271200\n",
      "Trial evaluate_config_a694ab4c reported score=16908521.09 with parameters={'x': 89112, 'y': 3890}.\n",
      "Trial evaluate_config_a5a79c42 reported score=5601774024.83 with parameters={'x': 10155, 'y': 61252}.\n",
      "Trial evaluate_config_a694ab4c completed. Last result: score=16908521.09203085,evaluation_cost=0.89112,constraint_metric=346645680\n",
      "Trial evaluate_config_a5a79c45 reported score=7161221375.97 with parameters={'x': 376, 'y': 14217}.\n",
      "Trial evaluate_config_a5a79c42 completed. Last result: score=5601774024.834209,evaluation_cost=0.10155,constraint_metric=622014060\n",
      "Trial evaluate_config_a694ab53 reported score=2383880624.11 with parameters={'x': 36175, 'y': 40765}.\n",
      "Trial evaluate_config_a5a79c45 completed. Last result: score=7161221375.973553,evaluation_cost=0.00376,constraint_metric=5345592\n",
      "Trial evaluate_config_a694ab56 reported score=3040640163.30 with parameters={'x': 29858, 'y': 42717}.\n",
      "Trial evaluate_config_a5a79c47 reported score=7206312100.00 with parameters={'x': 110, 'y': 43401}.\n",
      "Trial evaluate_config_a694ab50 reported score=865065696.65 with parameters={'x': 55588, 'y': 1174}.\n",
      "Trial evaluate_config_a694ab53 completed. Last result: score=2383880624.1125965,evaluation_cost=0.36175,constraint_metric=1474673875\n",
      "Trial evaluate_config_a5a79c47 completed. Last result: score=7206312099.997465,evaluation_cost=0.0011,constraint_metric=4774110\n",
      "Trial evaluate_config_a694ab50 completed. Last result: score=865065696.6507666,evaluation_cost=0.55588,constraint_metric=65260312\n",
      "Trial evaluate_config_a5a79c49 reported score=6988625603.98 with parameters={'x': 1402, 'y': 60104}.\n",
      "Trial evaluate_config_a694ab5b reported score=5072559506.00 with parameters={'x': 13778, 'y': 1}.\n",
      "Trial evaluate_config_a5a79c49 completed. Last result: score=6988625603.976674,evaluation_cost=0.01402,constraint_metric=84265808\n",
      "Trial evaluate_config_a694ab56 completed. Last result: score=3040640163.301028,evaluation_cost=0.29858,constraint_metric=1275444186\n",
      "Trial evaluate_config_a694ab5b completed. Last result: score=5072559506.0,evaluation_cost=0.13778,constraint_metric=13778\n",
      "Trial evaluate_config_a694ab4f reported score=37970069.58 with parameters={'x': 78838, 'y': 452}.\n",
      "Trial evaluate_config_a5a79c4a reported score=5733669840.82 with parameters={'x': 9279, 'y': 52165}.\n",
      "Trial evaluate_config_a694ab4f completed. Last result: score=37970069.57964602,evaluation_cost=0.78838,constraint_metric=35634776\n",
      "Trial evaluate_config_a694ab4e reported score=8743789.37 with parameters={'x': 87957, 'y': 1475}.\n",
      "Trial evaluate_config_a5a79c4d reported score=7224660004.00 with parameters={'x': 2, 'y': 82868}.\n",
      "Trial evaluate_config_a694ab58 reported score=2153145602.12 with parameters={'x': 38598, 'y': 20502}.\n",
      "Trial evaluate_config_a694ab4e completed. Last result: score=8743789.368135594,evaluation_cost=0.87957,constraint_metric=129736575\n",
      "Trial evaluate_config_a5a79c4c reported score=7224660004.00 with parameters={'x': 2, 'y': 30070}.\n",
      "Trial evaluate_config_a5a79c4e reported score=7224830001.00 with parameters={'x': 1, 'y': 62629}.\n",
      "Trial evaluate_config_a694ab5f reported score=3892739056.00 with parameters={'x': 22608, 'y': 1}.\n",
      "Trial evaluate_config_a5a79c4a completed. Last result: score=5733669840.822123,evaluation_cost=0.09279,constraint_metric=484039035\n",
      "Trial evaluate_config_a5a79c4d completed. Last result: score=7224660003.999976,evaluation_cost=2e-05,constraint_metric=165736\n",
      "Trial evaluate_config_a694ab52 reported score=25229.14 with parameters={'x': 84841, 'y': 1636}.\n",
      "Trial evaluate_config_a694ab59 reported score=623301153.64 with parameters={'x': 60034, 'y': 25433}.\n",
      "Trial evaluate_config_a694ab52 completed. Last result: score=25229.14119804401,evaluation_cost=0.84841,constraint_metric=138799876\n",
      "Trial evaluate_config_a694ab57 reported score=990118556.00 with parameters={'x': 53533, 'y': 1}.\n",
      "Trial evaluate_config_a5a79c4f reported score=7157160000.00 with parameters={'x': 400, 'y': 81928}.\n",
      "Trial evaluate_config_a694ab5f completed. Last result: score=3892739056.0,evaluation_cost=0.22608,constraint_metric=22608\n",
      "Trial evaluate_config_a5a79c4c completed. Last result: score=7224660003.999933,evaluation_cost=2e-05,constraint_metric=60140\n",
      "Trial evaluate_config_a694ab58 completed. Last result: score=2153145602.1173544,evaluation_cost=0.38598,constraint_metric=791336196\n",
      "Trial evaluate_config_a694ab57 completed. Last result: score=990118556.0,evaluation_cost=0.53533,constraint_metric=53533\n",
      "Trial evaluate_config_a694ab54 reported score=24940034.40 with parameters={'x': 80006, 'y': 50027}.\n",
      "Trial evaluate_config_a5a79c44 reported score=2337335715.49 with parameters={'x': 36654, 'y': 71457}.\n",
      "Trial evaluate_config_a694ab5d reported score=4452759438.44 with parameters={'x': 18271, 'y': 7140}.\n",
      "Trial evaluate_config_a5a79c4f completed. Last result: score=7157159999.995117,evaluation_cost=0.004,constraint_metric=32771200\n",
      "Trial evaluate_config_a694ab55 reported score=142396486.98 with parameters={'x': 96933, 'y': 48075}.\n",
      "Trial evaluate_config_a694ab5d completed. Last result: score=4452759438.441036,evaluation_cost=0.18271,constraint_metric=130454940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-07 04:05:05 (running for 00:00:05.27)<br>Memory usage on this node: 37.0/503.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 46.0/48 CPUs, 0/4 GPUs, 0.0/320.52 GiB heap, 0.0/141.36 GiB objects<br>Current best trial: a694ab52 with score=25229.14119804401 and parameters={'x': 84841, 'y': 1636}<br>Result logdir: /home/qxw5138/ray_results/evaluate_config_2022-07-07_04-04-59<br>Number of trials: 76/infinite (1 PENDING, 23 RUNNING, 52 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial evaluate_config_a694ab54 completed. Last result: score=24940034.4007436,evaluation_cost=0.80006,constraint_metric=4002460162\n",
      "Trial evaluate_config_a694ab59 completed. Last result: score=623301153.6395235,evaluation_cost=0.60034,constraint_metric=1526844722\n",
      "Trial evaluate_config_a5a79c4e completed. Last result: score=7224830000.999984,evaluation_cost=1e-05,constraint_metric=62629\n",
      "Trial evaluate_config_a694ab65 reported score=4785734040.09 with parameters={'x': 15821, 'y': 17465}.\n",
      "Trial evaluate_config_a694ab51 reported score=195859938.84 with parameters={'x': 98995, 'y': 1149}.\n",
      "Trial evaluate_config_a694ab65 completed. Last result: score=4785734040.094131,evaluation_cost=0.15821,constraint_metric=276313765\n",
      "Trial evaluate_config_a694ab66 reported score=2899284022.48 with parameters={'x': 31155, 'y': 12371}.\n",
      "Trial evaluate_config_a694ab63 reported score=1847022494.33 with parameters={'x': 42023, 'y': 1212}.\n",
      "Trial evaluate_config_a694ab51 completed. Last result: score=195859938.84247172,evaluation_cost=0.98995,constraint_metric=113745255\n",
      "Trial evaluate_config_a7c33336 reported score=4582342247.98 with parameters={'x': 17307, 'y': 17026}.\n",
      "Trial evaluate_config_a694ab6f reported score=4336222498.44 with parameters={'x': 19150, 'y': 12268}.\n",
      "Trial evaluate_config_a694ab69 reported score=3739420952.00 with parameters={'x': 23849, 'y': 1}.\n",
      "Trial evaluate_config_a694ab6f completed. Last result: score=4336222498.439029,evaluation_cost=0.1915,constraint_metric=234932200\n",
      "Trial evaluate_config_a694ab60 reported score=14730052.58 with parameters={'x': 81162, 'y': 424}.\n",
      "Trial evaluate_config_a694ab63 completed. Last result: score=1847022494.3275578,evaluation_cost=0.42023,constraint_metric=50931876\n",
      "Trial evaluate_config_a694ab62 reported score=9665811.13 with parameters={'x': 88109, 'y': 1261}.\n",
      "Trial evaluate_config_a694ab55 completed. Last result: score=142396486.98371294,evaluation_cost=0.96933,constraint_metric=4660053975\n",
      "Trial evaluate_config_a694ab60 completed. Last result: score=14730052.580188679,evaluation_cost=0.81162,constraint_metric=34412688\n",
      "Trial evaluate_config_a694ab64 reported score=9828220.40 with parameters={'x': 88135, 'y': 19172}.\n",
      "Trial evaluate_config_a694ab62 completed. Last result: score=9665811.127676448,evaluation_cost=0.88109,constraint_metric=111105449\n",
      "Trial evaluate_config_a7c3333a reported score=4012208962.20 with parameters={'x': 21658, 'y': 12050}.\n",
      "Trial evaluate_config_a7c3333a completed. Last result: score=4012208962.202656,evaluation_cost=0.21658,constraint_metric=260978900\n",
      "Trial evaluate_config_a7c33338 reported score=4358112254.89 with parameters={'x': 18984, 'y': 17094}.\n",
      "Trial evaluate_config_a694ab69 completed. Last result: score=3739420952.0,evaluation_cost=0.23849,constraint_metric=23849\n",
      "Trial evaluate_config_a694ab5a reported score=224969994.77 with parameters={'x': 99999, 'y': 16050}.\n",
      "Trial evaluate_config_a7c33339 reported score=4580582398.98 with parameters={'x': 17320, 'y': 16902}.\n",
      "Trial evaluate_config_a7c33336 completed. Last result: score=4582342247.983496,evaluation_cost=0.17307,constraint_metric=294668982\n",
      "Trial evaluate_config_a694ab6c reported score=172633316.42 with parameters={'x': 71861, 'y': 15704}.\n",
      "Trial evaluate_config_a5a79c44 completed. Last result: score=2337335715.487048,evaluation_cost=0.36654,constraint_metric=2619184878\n",
      "Trial evaluate_config_a694ab61 reported score=94050993.09 with parameters={'x': 94698, 'y': 449}.\n",
      "Trial evaluate_config_a694ab64 completed. Last result: score=9828220.402931359,evaluation_cost=0.88135,constraint_metric=1689724220\n",
      "Trial evaluate_config_a694ab6e reported score=4048649639.68 with parameters={'x': 21371, 'y': 16204}.\n",
      "Trial evaluate_config_a7c33343 reported score=6274224099.76 with parameters={'x': 5790, 'y': 24403}.\n",
      "Trial evaluate_config_a694ab5a completed. Last result: score=224969994.7695327,evaluation_cost=0.99999,constraint_metric=1604983950\n",
      "Trial evaluate_config_a7c3333b reported score=4256388079.03 with parameters={'x': 19759, 'y': 10037}.\n",
      "Trial evaluate_config_a694ab67 reported score=224870002.00 with parameters={'x': 99999, 'y': 1}.\n",
      "Trial evaluate_config_a7c33341 reported score=6228208560.70 with parameters={'x': 6081, 'y': 20300}.\n",
      "Trial evaluate_config_a694ab5c reported score=224969844.75 with parameters={'x': 99999, 'y': 640}.\n",
      "Trial evaluate_config_a7c3333b completed. Last result: score=4256388079.031384,evaluation_cost=0.19759,constraint_metric=198321083\n",
      "Trial evaluate_config_a7c33341 completed. Last result: score=6228208560.700443,evaluation_cost=0.06081,constraint_metric=123444300\n",
      "Trial evaluate_config_a694ab5e reported score=224969992.31 with parameters={'x': 99999, 'y': 11510}.\n",
      "Trial evaluate_config_a694ab61 completed. Last result: score=94050993.09131403,evaluation_cost=0.94698,constraint_metric=42519402\n",
      "Trial evaluate_config_a694ab6d reported score=4197225794.72 with parameters={'x': 20214, 'y': 15850}.\n",
      "Trial evaluate_config_a694ab6a reported score=224969991.47 with parameters={'x': 99999, 'y': 10496}.\n",
      "Trial evaluate_config_a694ab6e completed. Last result: score=4048649639.681128,evaluation_cost=0.21371,constraint_metric=346295684\n",
      "Trial evaluate_config_a694ab5e completed. Last result: score=224969992.31198958,evaluation_cost=0.99999,constraint_metric=1150988490\n",
      "Trial evaluate_config_a7c3333f reported score=6268680624.72 with parameters={'x': 5825, 'y': 20572}.\n",
      "Trial evaluate_config_a7c33345 reported score=4315307480.20 with parameters={'x': 19309, 'y': 24280}.\n",
      "Trial evaluate_config_a7c33347 reported score=6431238024.80 with parameters={'x': 4805, 'y': 23943}.\n",
      "Trial evaluate_config_a694ab6a completed. Last result: score=224969991.47265625,evaluation_cost=0.99999,constraint_metric=1049589504\n",
      "Trial evaluate_config_a694ab5c completed. Last result: score=224969844.7515625,evaluation_cost=0.99999,constraint_metric=63999360\n",
      "Trial evaluate_config_a7c33337 reported score=224969998.98 with parameters={'x': 99999, 'y': 49429}.\n",
      "Trial evaluate_config_a7c33349 reported score=6256335408.84 with parameters={'x': 5903, 'y': 36036}.\n",
      "Trial evaluate_config_a7c33347 completed. Last result: score=6431238024.799315,evaluation_cost=0.04805,constraint_metric=115046115\n",
      "Trial evaluate_config_a7c33337 completed. Last result: score=224969998.97691637,evaluation_cost=0.99999,constraint_metric=4942850571\n",
      "Trial evaluate_config_a694ab6c completed. Last result: score=172633316.4240321,evaluation_cost=0.71861,constraint_metric=1128505144\n",
      "Trial evaluate_config_a7c3333c reported score=6368838024.72 with parameters={'x': 5195, 'y': 18798}.\n",
      "Trial evaluate_config_a7c33348 reported score=6468502328.81 with parameters={'x': 4573, 'y': 23891}.\n",
      "Trial evaluate_config_a7c3334a reported score=6503777315.88 with parameters={'x': 4354, 'y': 37317}.\n",
      "Trial evaluate_config_a7c33340 reported score=6318183168.70 with parameters={'x': 5513, 'y': 18686}.\n",
      "Trial evaluate_config_a694ab68 reported score=4183114326.34 with parameters={'x': 20323, 'y': 7644}.\n",
      "Trial evaluate_config_a7c3333e reported score=6497972099.81 with parameters={'x': 4390, 'y': 22752}.\n",
      "Trial evaluate_config_a7c33348 completed. Last result: score=6468502328.808589,evaluation_cost=0.04573,constraint_metric=109253543\n",
      "Trial evaluate_config_a694ab68 completed. Last result: score=4183114326.3413134,evaluation_cost=0.20323,constraint_metric=155349012\n",
      "Trial evaluate_config_a694ab66 completed. Last result: score=2899284022.4816103,evaluation_cost=0.31155,constraint_metric=385418505\n",
      "Trial evaluate_config_a7c3333d reported score=6288648600.74 with parameters={'x': 5699, 'y': 21591}.\n",
      "Trial evaluate_config_a7c33339 completed. Last result: score=4580582398.975269,evaluation_cost=0.1732,constraint_metric=292742640\n",
      "Trial evaluate_config_a7c33349 completed. Last result: score=6256335408.836191,evaluation_cost=0.05903,constraint_metric=212720508\n",
      "Trial evaluate_config_a7c3334d reported score=5732609795.62 with parameters={'x': 9286, 'y': 24741}.\n",
      "Trial evaluate_config_a7c3333c completed. Last result: score=6368838024.72364,evaluation_cost=0.05195,constraint_metric=97655610\n",
      "Trial evaluate_config_a7c3334a completed. Last result: score=6503777315.883324,evaluation_cost=0.04354,constraint_metric=162478218\n",
      "Trial evaluate_config_a7c33338 completed. Last result: score=4358112254.889435,evaluation_cost=0.18984,constraint_metric=324512496\n",
      "Trial evaluate_config_a7c3333d completed. Last result: score=6288648600.736048,evaluation_cost=0.05699,constraint_metric=123047109\n",
      "Trial evaluate_config_a7c33345 completed. Last result: score=4315307480.204737,evaluation_cost=0.19309,constraint_metric=468822520\n",
      "Trial evaluate_config_a7c3334b reported score=6543192099.83 with parameters={'x': 4110, 'y': 23662}.\n",
      "Trial evaluate_config_a694ab67 completed. Last result: score=224870002.0,evaluation_cost=0.99999,constraint_metric=99999\n",
      "Trial evaluate_config_a7c3333f completed. Last result: score=6268680624.716848,evaluation_cost=0.05825,constraint_metric=119831900\n",
      "Trial evaluate_config_a7c3333e completed. Last result: score=6497972099.80705,evaluation_cost=0.0439,constraint_metric=99881280\n",
      "Trial evaluate_config_a694ab6d completed. Last result: score=4197225794.724669,evaluation_cost=0.20214,constraint_metric=320391900\n",
      "Trial evaluate_config_a7c3334b completed. Last result: score=6543192099.8263035,evaluation_cost=0.0411,constraint_metric=97250820\n",
      "Trial evaluate_config_a7c33342 reported score=176757020.81 with parameters={'x': 98295, 'y': 23455}.\n",
      "Trial evaluate_config_a7c3334d completed. Last result: score=5732609795.624672,evaluation_cost=0.09286,constraint_metric=229744926\n",
      "Trial evaluate_config_a7c33342 completed. Last result: score=176757020.80920914,evaluation_cost=0.98295,constraint_metric=2305509225\n",
      "Trial evaluate_config_a7c33340 completed. Last result: score=6318183168.704967,evaluation_cost=0.05513,constraint_metric=103015918\n",
      "Trial evaluate_config_a7c33346 reported score=224969993.89 with parameters={'x': 99999, 'y': 14064}.\n",
      "Trial evaluate_config_a7c33343 completed. Last result: score=6274224099.762734,evaluation_cost=0.0579,constraint_metric=141293370\n",
      "Trial evaluate_config_a7c3334c reported score=6244634528.75 with parameters={'x': 5977, 'y': 23882}.\n",
      "Trial evaluate_config_a7c33346 completed. Last result: score=224969993.88971844,evaluation_cost=0.99999,constraint_metric=1406385936\n",
      "Trial evaluate_config_a7c3334c completed. Last result: score=6244634528.749728,evaluation_cost=0.05977,constraint_metric=142742714\n",
      "Trial evaluate_config_a7c33353 reported score=449016091.12 with parameters={'x': 63810, 'y': 7185}.\n",
      "Trial evaluate_config_a7c3334f reported score=4322228.99 with parameters={'x': 87079, 'y': 7253}.\n",
      "Trial evaluate_config_a7c33344 reported score=70980621.24 with parameters={'x': 93425, 'y': 24855}.\n",
      "Trial evaluate_config_a7c33353 completed. Last result: score=449016091.11899793,evaluation_cost=0.6381,constraint_metric=458474850\n",
      "Trial evaluate_config_a7c3334e reported score=178035637.91 with parameters={'x': 98343, 'y': 8870}.\n",
      "Trial evaluate_config_a7c33350 reported score=287811214.80 with parameters={'x': 68035, 'y': 6668}.\n",
      "Trial evaluate_config_a7c3334e completed. Last result: score=178035637.91285232,evaluation_cost=0.98343,constraint_metric=872302410\n",
      "Trial evaluate_config_a8ed9124 reported score=7219221155.99 with parameters={'x': 34, 'y': 4766}.\n",
      "Trial evaluate_config_a7c33356 reported score=506025016.28 with parameters={'x': 62505, 'y': 7172}.\n",
      "Trial evaluate_config_a7c33350 completed. Last result: score=287811214.79679066,evaluation_cost=0.68035,constraint_metric=453657380\n",
      "Trial evaluate_config_a7c33357 reported score=238177479.96 with parameters={'x': 69567, 'y': 7693}.\n",
      "Trial evaluate_config_a7c33358 reported score=329821910.95 with parameters={'x': 66839, 'y': 6652}.\n",
      "Trial evaluate_config_a7c33344 completed. Last result: score=70980621.24119896,evaluation_cost=0.93425,constraint_metric=2322078375\n",
      "Trial evaluate_config_a7c3335b reported score=817559641.84 with parameters={'x': 56407, 'y': 7873}.\n",
      "Trial evaluate_config_a8ed9124 completed. Last result: score=7219221155.9928665,evaluation_cost=0.00034,constraint_metric=162044\n",
      "Trial evaluate_config_a7c3335c reported score=651985147.41 with parameters={'x': 59466, 'y': 6921}.\n",
      "Trial evaluate_config_a7c3335c completed. Last result: score=651985147.407889,evaluation_cost=0.59466,constraint_metric=411564186\n",
      "Trial evaluate_config_a7c33358 completed. Last result: score=329821910.9520445,evaluation_cost=0.66839,constraint_metric=444613028\n",
      "Trial evaluate_config_a7c33357 completed. Last result: score=238177479.95710385,evaluation_cost=0.69567,constraint_metric=535178931\n",
      "Trial evaluate_config_a7c3335e reported score=450882745.69 with parameters={'x': 63766, 'y': 6183}.\n",
      "Trial evaluate_config_a7c3335f reported score=625550112.21 with parameters={'x': 59989, 'y': 6825}.\n",
      "Trial evaluate_config_a7c33352 reported score=42667011.85 with parameters={'x': 91532, 'y': 7534}.\n",
      "Trial evaluate_config_a7c3335f completed. Last result: score=625550112.210403,evaluation_cost=0.59989,constraint_metric=409424925\n",
      "Trial evaluate_config_a7c33355 reported score=519520840.28 with parameters={'x': 62207, 'y': 7133}.\n",
      "Trial evaluate_config_a7c33361 reported score=414733212.92 with parameters={'x': 64635, 'y': 5352}.\n",
      "Trial evaluate_config_a7c3334f completed. Last result: score=4322228.994071418,evaluation_cost=0.87079,constraint_metric=631583987\n",
      "Trial evaluate_config_a7c33361 completed. Last result: score=414733212.92320627,evaluation_cost=0.64635,constraint_metric=345926520\n",
      "Trial evaluate_config_a8ed9120 reported score=560742388.36 with parameters={'x': 61320, 'y': 5270}.\n",
      "Trial evaluate_config_a7c33352 completed. Last result: score=42667011.85080966,evaluation_cost=0.91532,constraint_metric=689602088\n",
      "Trial evaluate_config_a8ed9120 completed. Last result: score=560742388.3643264,evaluation_cost=0.6132,constraint_metric=323156400\n",
      "Trial evaluate_config_a8ed9126 reported score=2686970887.75 with parameters={'x': 33164, 'y': 4020}.\n",
      "Trial evaluate_config_a7c33360 reported score=410062490.36 with parameters={'x': 64750, 'y': 6714}.\n",
      "Trial evaluate_config_a8ed9127 reported score=2244201119.61 with parameters={'x': 37627, 'y': 4009}.\n",
      "Trial evaluate_config_a8ed9128 reported score=2569171960.64 with parameters={'x': 34313, 'y': 4104}.\n",
      "Trial evaluate_config_a8ed9122 reported score=590441389.87 with parameters={'x': 60701, 'y': 5456}.\n",
      "Trial evaluate_config_a8ed912a reported score=2949684711.64 with parameters={'x': 30689, 'y': 3279}.\n",
      "Trial evaluate_config_a8ed9126 completed. Last result: score=2686970887.750249,evaluation_cost=0.33164,constraint_metric=133319280\n",
      "Trial evaluate_config_a7c33354 reported score=66814260.52 with parameters={'x': 93174, 'y': 6020}.\n",
      "Trial evaluate_config_a8ed9127 completed. Last result: score=2244201119.6143675,evaluation_cost=0.37627,constraint_metric=150846643\n",
      "Trial evaluate_config_a8ed912a completed. Last result: score=2949684711.640744,evaluation_cost=0.30689,constraint_metric=100629231\n",
      "Trial evaluate_config_a7c33356 completed. Last result: score=506025016.2848578,evaluation_cost=0.62505,constraint_metric=448285860\n",
      "Trial evaluate_config_a7c33360 completed. Last result: score=410062490.3559726,evaluation_cost=0.6475,constraint_metric=434731500\n",
      "Trial evaluate_config_a8ed9128 completed. Last result: score=2569171960.6391325,evaluation_cost=0.34313,constraint_metric=140820552\n",
      "Trial evaluate_config_a8ed9123 reported score=442934109.21 with parameters={'x': 63954, 'y': 9421}.\n",
      "Trial evaluate_config_a7c3335b completed. Last result: score=817559641.8353868,evaluation_cost=0.56407,constraint_metric=444092311\n",
      "Trial evaluate_config_a7c3335a reported score=509179216.84 with parameters={'x': 62435, 'y': 7656}.\n",
      "Trial evaluate_config_a8ed912b reported score=2809424005.24 with parameters={'x': 31996, 'y': 2973}.\n",
      "Trial evaluate_config_a8ed912d reported score=2524760999.47 with parameters={'x': 34753, 'y': 3647}.\n",
      "Trial evaluate_config_a8ed9129 reported score=2649572668.36 with parameters={'x': 33526, 'y': 4387}.\n",
      "Trial evaluate_config_a8ed9122 completed. Last result: score=590441389.8744501,evaluation_cost=0.60701,constraint_metric=331184656\n",
      "Trial evaluate_config_a7c33354 completed. Last result: score=66814260.52259136,evaluation_cost=0.93174,constraint_metric=560907480\n",
      "Trial evaluate_config_a8ed912e reported score=3236358312.87 with parameters={'x': 28111, 'y': 3456}.\n",
      "Trial evaluate_config_a8ed9125 reported score=2868994962.73 with parameters={'x': 31437, 'y': 5012}.\n",
      "Trial evaluate_config_a8ed9129 completed. Last result: score=2649572668.3578753,evaluation_cost=0.33526,constraint_metric=147078562\n",
      "Trial evaluate_config_a7c3335a completed. Last result: score=509179216.8449582,evaluation_cost=0.62435,constraint_metric=478002360\n",
      "Trial evaluate_config_a8ed912c reported score=2873281599.77 with parameters={'x': 31397, 'y': 3402}.\n",
      "Trial evaluate_config_a8ed9131 reported score=2662869577.90 with parameters={'x': 33397, 'y': 1074}.\n",
      "Trial evaluate_config_a8ed9135 reported score=3368409402.77 with parameters={'x': 26962, 'y': 654}.\n",
      "Trial evaluate_config_a8ed9121 reported score=607869015.72 with parameters={'x': 60345, 'y': 6500}.\n",
      "Trial evaluate_config_a7c3335e completed. Last result: score=450882745.6868834,evaluation_cost=0.63766,constraint_metric=394265178\n",
      "Trial evaluate_config_a8ed912e completed. Last result: score=3236358312.86603,evaluation_cost=0.28111,constraint_metric=97151616\n",
      "Trial evaluate_config_a7c33355 completed. Last result: score=519520840.278985,evaluation_cost=0.62207,constraint_metric=443722531\n",
      "Trial evaluate_config_a8ed9123 completed. Last result: score=442934109.2115487,evaluation_cost=0.63954,constraint_metric=602510634\n",
      "Trial evaluate_config_a8ed9133 reported score=2987715480.55 with parameters={'x': 30340, 'y': 254}.\n",
      "Trial evaluate_config_a8ed912f reported score=2845902399.10 with parameters={'x': 31653, 'y': 3198}.\n",
      "Trial evaluate_config_a8ed9139 reported score=5265243675.92 with parameters={'x': 12438, 'y': 74}.\n",
      "Trial evaluate_config_a7c3335d reported score=429152645.93 with parameters={'x': 64284, 'y': 6381}.\n",
      "Trial evaluate_config_a7c33351 reported score=126584986.56 with parameters={'x': 96251, 'y': 6667}.\n",
      "Trial evaluate_config_a8ed913a reported score=5269017742.93 with parameters={'x': 12412, 'y': 11595}.\n",
      "Trial evaluate_config_a7c3335d completed. Last result: score=429152645.925717,evaluation_cost=0.64284,constraint_metric=410196204\n",
      "Trial evaluate_config_a8ed9139 completed. Last result: score=5265243675.918919,evaluation_cost=0.12438,constraint_metric=920412\n",
      "Trial evaluate_config_a8ed9133 completed. Last result: score=2987715480.5511813,evaluation_cost=0.3034,constraint_metric=7706360\n",
      "Trial evaluate_config_a7c33351 completed. Last result: score=126584986.56307185,evaluation_cost=0.96251,constraint_metric=641705417\n",
      "Trial evaluate_config_a8ed9131 completed. Last result: score=2662869577.9040966,evaluation_cost=0.33397,constraint_metric=35868378\n",
      "Trial evaluate_config_a7c33359 reported score=626300666.10 with parameters={'x': 59974, 'y': 6061}.\n",
      "Trial evaluate_config_a8ed912b completed. Last result: score=2809424005.237807,evaluation_cost=0.31996,constraint_metric=95124108\n",
      "Trial evaluate_config_a8ed9138 reported score=3359013757.64 with parameters={'x': 27043, 'y': 296}.\n",
      "Trial evaluate_config_a8ed9121 completed. Last result: score=607869015.7161539,evaluation_cost=0.60345,constraint_metric=392242500\n",
      "Trial evaluate_config_a8ed9125 completed. Last result: score=2868994962.7276535,evaluation_cost=0.31437,constraint_metric=157562244\n",
      "Trial evaluate_config_a8ed9135 completed. Last result: score=3368409402.7737,evaluation_cost=0.26962,constraint_metric=17633148\n",
      "Trial evaluate_config_a8ed912d completed. Last result: score=2524760999.470798,evaluation_cost=0.34753,constraint_metric=126744191\n",
      "Trial evaluate_config_a8ed9134 reported score=5174355400.08 with parameters={'x': 13067, 'y': 12}.\n",
      "Trial evaluate_config_a8ed9140 reported score=5462244648.19 with parameters={'x': 11093, 'y': 13761}.\n",
      "Trial evaluate_config_a8ed913c reported score=3333676641.63 with parameters={'x': 27262, 'y': 11527}.\n",
      "Trial evaluate_config_a8ed9137 reported score=5179393012.58 with parameters={'x': 13032, 'y': 1141}.\n",
      "Trial evaluate_config_a7c33359 completed. Last result: score=626300666.1049331,evaluation_cost=0.59974,constraint_metric=363502414\n",
      "Trial evaluate_config_a8ed913e reported score=5405337421.74 with parameters={'x': 11479, 'y': 596}.\n",
      "Trial evaluate_config_a8ed9132 reported score=2743872871.81 with parameters={'x': 32618, 'y': 31}.\n",
      "Trial evaluate_config_a8ed913c completed. Last result: score=3333676641.634944,evaluation_cost=0.27262,constraint_metric=314249074\n",
      "Trial evaluate_config_a8ed9138 completed. Last result: score=3359013757.6385136,evaluation_cost=0.27043,constraint_metric=8004728\n",
      "Trial evaluate_config_a8ed912f completed. Last result: score=2845902399.1022515,evaluation_cost=0.31653,constraint_metric=101226294\n",
      "Trial evaluate_config_a8ed9140 completed. Last result: score=5462244648.193881,evaluation_cost=0.11093,constraint_metric=152650773\n",
      "Trial evaluate_config_a8ed9143 reported score=1849430021.58 with parameters={'x': 41995, 'y': 12266}.\n",
      "Trial evaluate_config_a8ed913a completed. Last result: score=5269017742.929539,evaluation_cost=0.12412,constraint_metric=143917140\n",
      "Trial evaluate_config_a8ed912c completed. Last result: score=2873281599.771017,evaluation_cost=0.31397,constraint_metric=106812594\n",
      "Trial evaluate_config_a8ed9136 reported score=3540249997.97 with parameters={'x': 25500, 'y': 12578}.\n",
      "Trial evaluate_config_a8ed913e completed. Last result: score=5405337421.739933,evaluation_cost=0.11479,constraint_metric=6841484\n",
      "Trial evaluate_config_a8ed9134 completed. Last result: score=5174355400.083333,evaluation_cost=0.13067,constraint_metric=156804\n",
      "Trial evaluate_config_a8ed9136 completed. Last result: score=3540249997.9726505,evaluation_cost=0.255,constraint_metric=320739000\n",
      "Trial evaluate_config_a8ed9137 completed. Last result: score=5179393012.57844,evaluation_cost=0.13032,constraint_metric=14869512\n",
      "Trial evaluate_config_a8ed9144 reported score=1662274436.67 with parameters={'x': 44229, 'y': 10221}.\n",
      "Trial evaluate_config_a8ed9132 completed. Last result: score=2743872871.806452,evaluation_cost=0.32618,constraint_metric=1011158\n",
      "Trial evaluate_config_a8ed913d reported score=28429947.76 with parameters={'x': 90332, 'y': 327}.\n",
      "Trial evaluate_config_a8ed9141 reported score=1652991645.34 with parameters={'x': 44343, 'y': 12129}.\n",
      "Trial evaluate_config_a8ed9130 reported score=2880361550.67 with parameters={'x': 31331, 'y': 3033}.\n",
      "Trial evaluate_config_a8ed9143 completed. Last result: score=1849430021.5763085,evaluation_cost=0.41995,constraint_metric=515110670\n",
      "Trial evaluate_config_a8ed9141 completed. Last result: score=1652991645.3440514,evaluation_cost=0.44343,constraint_metric=537836247\n",
      "Trial evaluate_config_a8ed9144 completed. Last result: score=1662274436.6727326,evaluation_cost=0.44229,constraint_metric=452064609\n",
      "Trial evaluate_config_a8ed913b reported score=145804682.52 with parameters={'x': 97075, 'y': 103}.\n",
      "Trial evaluate_config_a8ed913d completed. Last result: score=28429947.75535168,evaluation_cost=0.90332,constraint_metric=29538564\n",
      "Trial evaluate_config_a8ed9130 completed. Last result: score=2880361550.669964,evaluation_cost=0.31331,constraint_metric=95026923\n",
      "Trial evaluate_config_a8ed913f reported score=220788840.80 with parameters={'x': 99859, 'y': 96}.\n",
      "Trial evaluate_config_a8ed913b completed. Last result: score=145804682.52427185,evaluation_cost=0.97075,constraint_metric=9998725\n",
      "Trial evaluate_config_a8ed9142 reported score=167780200.97 with parameters={'x': 97953, 'y': 12194}.\n",
      "Trial evaluate_config_a8ed913f completed. Last result: score=220788840.80208334,evaluation_cost=0.99859,constraint_metric=9586464\n",
      "Trial evaluate_config_a8ed9142 completed. Last result: score=167780200.96711498,evaluation_cost=0.97953,constraint_metric=1194438882\n",
      "Trial evaluate_config_aa2213ad reported score=1505983245.72 with parameters={'x': 46193, 'y': 14087}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 04:05:10,036\tINFO stopper.py:363 -- Reached timeout of 10 seconds. Stopping all trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial evaluate_config_a8ed9145 reported score=118222121.74 with parameters={'x': 95873, 'y': 13212}.\n",
      "Trial evaluate_config_aa2213ad completed. Last result: score=1505983245.7208774,evaluation_cost=0.46193,constraint_metric=650720791\n",
      "Trial evaluate_config_aa2213a4 reported score=39375618.55 with parameters={'x': 91275, 'y': 14152}.\n",
      "Trial evaluate_config_a8ed9145 completed. Last result: score=118222121.74349077,evaluation_cost=0.95873,constraint_metric=1266674076\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-07 04:05:10 (running for 00:00:10.54)<br>Memory usage on this node: 36.2/503.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/48 CPUs, 0/4 GPUs, 0.0/320.52 GiB heap, 0.0/141.36 GiB objects<br>Current best trial: a694ab52 with score=25229.14119804401 and parameters={'x': 84841, 'y': 1636}<br>Result logdir: /home/qxw5138/ray_results/evaluate_config_2022-07-07_04-04-59<br>Number of trials: 183/infinite (183 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-07 04:05:10 (running for 00:00:10.55)<br>Memory usage on this node: 36.2/503.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/48 CPUs, 0/4 GPUs, 0.0/320.52 GiB heap, 0.0/141.36 GiB objects<br>Current best trial: a694ab52 with score=25229.14119804401 and parameters={'x': 84841, 'y': 1636}<br>Result logdir: /home/qxw5138/ray_results/evaluate_config_2022-07-07_04-04-59<br>Number of trials: 183/infinite (183 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc                    </th><th style=\"text-align: right;\">    x</th><th style=\"text-align: right;\">    y</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">          score</th><th style=\"text-align: right;\">  evaluation_cost</th><th style=\"text-align: right;\">  constraint_metric</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>evaluate_config_a49d1df2</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">    3</td><td style=\"text-align: right;\">13184</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000576019</td><td style=\"text-align: right;\">    7.22449e+09</td><td style=\"text-align: right;\">          3e-05  </td><td style=\"text-align: right;\">              39552</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c2c</td><td>TERMINATED</td><td>130.203.136.143:4004235</td><td style=\"text-align: right;\"> 6134</td><td style=\"text-align: right;\"> 2076</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0619102  </td><td style=\"text-align: right;\">    6.21985e+09</td><td style=\"text-align: right;\">          0.06134</td><td style=\"text-align: right;\">           12734184</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c2d</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\"> 1143</td><td style=\"text-align: right;\">74880</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0118678  </td><td style=\"text-align: right;\">    7.032e+09  </td><td style=\"text-align: right;\">          0.01143</td><td style=\"text-align: right;\">           85587840</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c2e</td><td>TERMINATED</td><td>130.203.136.143:4004241</td><td style=\"text-align: right;\">  220</td><td style=\"text-align: right;\">22480</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.00351667 </td><td style=\"text-align: right;\">    7.18765e+09</td><td style=\"text-align: right;\">          0.0022 </td><td style=\"text-align: right;\">            4945600</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c2f</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">    6</td><td style=\"text-align: right;\">76053</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000468969</td><td style=\"text-align: right;\">    7.22398e+09</td><td style=\"text-align: right;\">          6e-05  </td><td style=\"text-align: right;\">             456318</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c30</td><td>TERMINATED</td><td>130.203.136.143:4004246</td><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\"> 8834</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000578165</td><td style=\"text-align: right;\">    7.22432e+09</td><td style=\"text-align: right;\">          4e-05  </td><td style=\"text-align: right;\">              35336</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c31</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\"> 2148</td><td style=\"text-align: right;\">95339</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0219069  </td><td style=\"text-align: right;\">    6.86445e+09</td><td style=\"text-align: right;\">          0.02148</td><td style=\"text-align: right;\">          204788172</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c32</td><td>TERMINATED</td><td>130.203.136.143:4004253</td><td style=\"text-align: right;\"> 1032</td><td style=\"text-align: right;\">60766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0107296  </td><td style=\"text-align: right;\">    7.05063e+09</td><td style=\"text-align: right;\">          0.01032</td><td style=\"text-align: right;\">           62710512</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c33</td><td>TERMINATED</td><td>130.203.136.143:4004257</td><td style=\"text-align: right;\"> 1266</td><td style=\"text-align: right;\">88994</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0130882  </td><td style=\"text-align: right;\">    7.01138e+09</td><td style=\"text-align: right;\">          0.01266</td><td style=\"text-align: right;\">          112666404</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c34</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\"> 5603</td><td style=\"text-align: right;\">71825</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0565019  </td><td style=\"text-align: right;\">    6.30388e+09</td><td style=\"text-align: right;\">          0.05603</td><td style=\"text-align: right;\">          402435475</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c35</td><td>TERMINATED</td><td>130.203.136.143:4004263</td><td style=\"text-align: right;\">10930</td><td style=\"text-align: right;\">95886</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.10989    </td><td style=\"text-align: right;\">    5.48636e+09</td><td style=\"text-align: right;\">          0.1093 </td><td style=\"text-align: right;\">         1048033980</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c36</td><td>TERMINATED</td><td>130.203.136.143:4004267</td><td style=\"text-align: right;\">  422</td><td style=\"text-align: right;\">94792</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.00460029 </td><td style=\"text-align: right;\">    7.15344e+09</td><td style=\"text-align: right;\">          0.00422</td><td style=\"text-align: right;\">           40002224</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c37</td><td>TERMINATED</td><td>130.203.136.143:4004272</td><td style=\"text-align: right;\">  765</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.00813866 </td><td style=\"text-align: right;\">    7.09554e+09</td><td style=\"text-align: right;\">          0.00765</td><td style=\"text-align: right;\">           76499235</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c38</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\"> 6030</td><td style=\"text-align: right;\">84402</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0608087  </td><td style=\"text-align: right;\">    6.23626e+09</td><td style=\"text-align: right;\">          0.0603 </td><td style=\"text-align: right;\">          508944060</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c3a</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\"> 2737</td><td style=\"text-align: right;\">59126</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0278707  </td><td style=\"text-align: right;\">    6.7672e+09 </td><td style=\"text-align: right;\">          0.02737</td><td style=\"text-align: right;\">          161827862</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c3b</td><td>TERMINATED</td><td>130.203.136.143:4004282</td><td style=\"text-align: right;\"> 8722</td><td style=\"text-align: right;\">79600</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0876565  </td><td style=\"text-align: right;\">    5.81833e+09</td><td style=\"text-align: right;\">          0.08722</td><td style=\"text-align: right;\">          694271200</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c3c</td><td>TERMINATED</td><td>130.203.136.143:4004285</td><td style=\"text-align: right;\"> 4169</td><td style=\"text-align: right;\">89204</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0420125  </td><td style=\"text-align: right;\">    6.53365e+09</td><td style=\"text-align: right;\">          0.04169</td><td style=\"text-align: right;\">          371891476</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c3d</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\"> 4915</td><td style=\"text-align: right;\">78908</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.049665   </td><td style=\"text-align: right;\">    6.41361e+09</td><td style=\"text-align: right;\">          0.04915</td><td style=\"text-align: right;\">          387832820</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c3e</td><td>TERMINATED</td><td>130.203.136.143:4004292</td><td style=\"text-align: right;\"> 7397</td><td style=\"text-align: right;\">89896</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0745385  </td><td style=\"text-align: right;\">    6.02223e+09</td><td style=\"text-align: right;\">          0.07397</td><td style=\"text-align: right;\">          664960712</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c3f</td><td>TERMINATED</td><td>130.203.136.143:4004307</td><td style=\"text-align: right;\">11470</td><td style=\"text-align: right;\">84524</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.115197   </td><td style=\"text-align: right;\">    5.40666e+09</td><td style=\"text-align: right;\">          0.1147 </td><td style=\"text-align: right;\">          969490280</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c40</td><td>TERMINATED</td><td>130.203.136.143:4004315</td><td style=\"text-align: right;\">15880</td><td style=\"text-align: right;\">60957</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.159379   </td><td style=\"text-align: right;\">    4.77757e+09</td><td style=\"text-align: right;\">          0.1588 </td><td style=\"text-align: right;\">          967997160</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c41</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">51219</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000491858</td><td style=\"text-align: right;\">    7.22483e+09</td><td style=\"text-align: right;\">          1e-05  </td><td style=\"text-align: right;\">              51219</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c42</td><td>TERMINATED</td><td>130.203.136.143:4004334</td><td style=\"text-align: right;\">10155</td><td style=\"text-align: right;\">61252</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.102179   </td><td style=\"text-align: right;\">    5.60177e+09</td><td style=\"text-align: right;\">          0.10155</td><td style=\"text-align: right;\">          622014060</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c43</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\"> 3350</td><td style=\"text-align: right;\">29188</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0340137  </td><td style=\"text-align: right;\">    6.66672e+09</td><td style=\"text-align: right;\">          0.0335 </td><td style=\"text-align: right;\">           97779800</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c44</td><td>TERMINATED</td><td>130.203.136.143:4004358</td><td style=\"text-align: right;\">36654</td><td style=\"text-align: right;\">71457</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.367312   </td><td style=\"text-align: right;\">    2.33734e+09</td><td style=\"text-align: right;\">          0.36654</td><td style=\"text-align: right;\">         2619184878</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c45</td><td>TERMINATED</td><td>130.203.136.143:4004379</td><td style=\"text-align: right;\">  376</td><td style=\"text-align: right;\">14217</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.00430536 </td><td style=\"text-align: right;\">    7.16122e+09</td><td style=\"text-align: right;\">          0.00376</td><td style=\"text-align: right;\">            5345592</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c46</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">   48</td><td style=\"text-align: right;\">67413</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000968456</td><td style=\"text-align: right;\">    7.21684e+09</td><td style=\"text-align: right;\">          0.00048</td><td style=\"text-align: right;\">            3235824</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c47</td><td>TERMINATED</td><td>130.203.136.143:4004391</td><td style=\"text-align: right;\">  110</td><td style=\"text-align: right;\">43401</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.00168061 </td><td style=\"text-align: right;\">    7.20631e+09</td><td style=\"text-align: right;\">          0.0011 </td><td style=\"text-align: right;\">            4774110</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c48</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">  941</td><td style=\"text-align: right;\">51314</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.00980473 </td><td style=\"text-align: right;\">    7.06592e+09</td><td style=\"text-align: right;\">          0.00941</td><td style=\"text-align: right;\">           48286474</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c49</td><td>TERMINATED</td><td>130.203.136.143:4004412</td><td style=\"text-align: right;\"> 1402</td><td style=\"text-align: right;\">60104</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0144379  </td><td style=\"text-align: right;\">    6.98863e+09</td><td style=\"text-align: right;\">          0.01402</td><td style=\"text-align: right;\">           84265808</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c4a</td><td>TERMINATED</td><td>130.203.136.143:4004415</td><td style=\"text-align: right;\"> 9279</td><td style=\"text-align: right;\">52165</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0933821  </td><td style=\"text-align: right;\">    5.73367e+09</td><td style=\"text-align: right;\">          0.09279</td><td style=\"text-align: right;\">          484039035</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c4b</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">32790</td><td style=\"text-align: right;\">31924</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.328568   </td><td style=\"text-align: right;\">    2.72588e+09</td><td style=\"text-align: right;\">          0.3279 </td><td style=\"text-align: right;\">         1046787960</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c4c</td><td>TERMINATED</td><td>130.203.136.143:4004422</td><td style=\"text-align: right;\">    2</td><td style=\"text-align: right;\">30070</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000621796</td><td style=\"text-align: right;\">    7.22466e+09</td><td style=\"text-align: right;\">          2e-05  </td><td style=\"text-align: right;\">              60140</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c4d</td><td>TERMINATED</td><td>130.203.136.143:4004426</td><td style=\"text-align: right;\">    2</td><td style=\"text-align: right;\">82868</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000623941</td><td style=\"text-align: right;\">    7.22466e+09</td><td style=\"text-align: right;\">          2e-05  </td><td style=\"text-align: right;\">             165736</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c4e</td><td>TERMINATED</td><td>130.203.136.143:4004431</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">62629</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000534534</td><td style=\"text-align: right;\">    7.22483e+09</td><td style=\"text-align: right;\">          1e-05  </td><td style=\"text-align: right;\">              62629</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c4f</td><td>TERMINATED</td><td>130.203.136.143:4004434</td><td style=\"text-align: right;\">  400</td><td style=\"text-align: right;\">81928</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.00447702 </td><td style=\"text-align: right;\">    7.15716e+09</td><td style=\"text-align: right;\">          0.004  </td><td style=\"text-align: right;\">           32771200</td></tr>\n",
       "<tr><td>evaluate_config_a5a79c50</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">    6</td><td style=\"text-align: right;\">85685</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.000469446</td><td style=\"text-align: right;\">    7.22398e+09</td><td style=\"text-align: right;\">          6e-05  </td><td style=\"text-align: right;\">             514110</td></tr>\n",
       "<tr><td>evaluate_config_a694ab48</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">24835</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.00151    </td><td style=\"text-align: right;\">    2.2497e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">         2483475165</td></tr>\n",
       "<tr><td>evaluate_config_a694ab49</td><td>TERMINATED</td><td>130.203.136.143:4004235</td><td style=\"text-align: right;\"> 8015</td><td style=\"text-align: right;\">39013</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0805938  </td><td style=\"text-align: right;\">    5.92669e+09</td><td style=\"text-align: right;\">          0.08015</td><td style=\"text-align: right;\">          312689195</td></tr>\n",
       "<tr><td>evaluate_config_a694ab4a</td><td>TERMINATED</td><td>130.203.136.143:4004246</td><td style=\"text-align: right;\">19985</td><td style=\"text-align: right;\">18452</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.200443   </td><td style=\"text-align: right;\">    4.22695e+09</td><td style=\"text-align: right;\">          0.19985</td><td style=\"text-align: right;\">          368763220</td></tr>\n",
       "<tr><td>evaluate_config_a694ab4b</td><td>TERMINATED</td><td>130.203.136.143:4004241</td><td style=\"text-align: right;\">53798</td><td style=\"text-align: right;\">45396</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.538812   </td><td style=\"text-align: right;\">    9.73565e+08</td><td style=\"text-align: right;\">          0.53798</td><td style=\"text-align: right;\">         2442214008</td></tr>\n",
       "<tr><td>evaluate_config_a694ab4c</td><td>TERMINATED</td><td>130.203.136.143:4004235</td><td style=\"text-align: right;\">89112</td><td style=\"text-align: right;\"> 3890</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.892407   </td><td style=\"text-align: right;\">    1.69085e+07</td><td style=\"text-align: right;\">          0.89112</td><td style=\"text-align: right;\">          346645680</td></tr>\n",
       "<tr><td>evaluate_config_a694ab4d</td><td>TERMINATED</td><td>130.203.136.143:4004246</td><td style=\"text-align: right;\">45456</td><td style=\"text-align: right;\"> 6432</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.454936   </td><td style=\"text-align: right;\">    1.56373e+09</td><td style=\"text-align: right;\">          0.45456</td><td style=\"text-align: right;\">          292372992</td></tr>\n",
       "<tr><td>evaluate_config_a694ab4e</td><td>TERMINATED</td><td>130.203.136.143:4004253</td><td style=\"text-align: right;\">87957</td><td style=\"text-align: right;\"> 1475</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.880757   </td><td style=\"text-align: right;\">    8.74379e+06</td><td style=\"text-align: right;\">          0.87957</td><td style=\"text-align: right;\">          129736575</td></tr>\n",
       "<tr><td>evaluate_config_a694ab4f</td><td>TERMINATED</td><td>130.203.136.143:4004267</td><td style=\"text-align: right;\">78838</td><td style=\"text-align: right;\">  452</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.789517   </td><td style=\"text-align: right;\">    3.79701e+07</td><td style=\"text-align: right;\">          0.78838</td><td style=\"text-align: right;\">           35634776</td></tr>\n",
       "<tr><td>evaluate_config_a694ab50</td><td>TERMINATED</td><td>130.203.136.143:4004257</td><td style=\"text-align: right;\">55588</td><td style=\"text-align: right;\"> 1174</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.556754   </td><td style=\"text-align: right;\">    8.65066e+08</td><td style=\"text-align: right;\">          0.55588</td><td style=\"text-align: right;\">           65260312</td></tr>\n",
       "<tr><td>evaluate_config_a694ab51</td><td>TERMINATED</td><td>130.203.136.143:4004263</td><td style=\"text-align: right;\">98995</td><td style=\"text-align: right;\"> 1149</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.991405   </td><td style=\"text-align: right;\">    1.9586e+08 </td><td style=\"text-align: right;\">          0.98995</td><td style=\"text-align: right;\">          113745255</td></tr>\n",
       "<tr><td>evaluate_config_a694ab52</td><td>TERMINATED</td><td>130.203.136.143:4004241</td><td style=\"text-align: right;\">84841</td><td style=\"text-align: right;\"> 1636</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.848893   </td><td style=\"text-align: right;\">25229.1        </td><td style=\"text-align: right;\">          0.84841</td><td style=\"text-align: right;\">          138799876</td></tr>\n",
       "<tr><td>evaluate_config_a694ab53</td><td>TERMINATED</td><td>130.203.136.143:4004272</td><td style=\"text-align: right;\">36175</td><td style=\"text-align: right;\">40765</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.362524   </td><td style=\"text-align: right;\">    2.38388e+09</td><td style=\"text-align: right;\">          0.36175</td><td style=\"text-align: right;\">         1474673875</td></tr>\n",
       "<tr><td>evaluate_config_a694ab54</td><td>TERMINATED</td><td>130.203.136.143:4004285</td><td style=\"text-align: right;\">80006</td><td style=\"text-align: right;\">50027</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.801177   </td><td style=\"text-align: right;\">    2.494e+07  </td><td style=\"text-align: right;\">          0.80006</td><td style=\"text-align: right;\">         4002460162</td></tr>\n",
       "<tr><td>evaluate_config_a694ab55</td><td>TERMINATED</td><td>130.203.136.143:4004246</td><td style=\"text-align: right;\">96933</td><td style=\"text-align: right;\">48075</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.970743   </td><td style=\"text-align: right;\">    1.42396e+08</td><td style=\"text-align: right;\">          0.96933</td><td style=\"text-align: right;\">         4660053975</td></tr>\n",
       "<tr><td>evaluate_config_a694ab56</td><td>TERMINATED</td><td>130.203.136.143:4004307</td><td style=\"text-align: right;\">29858</td><td style=\"text-align: right;\">42717</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.299246   </td><td style=\"text-align: right;\">    3.04064e+09</td><td style=\"text-align: right;\">          0.29858</td><td style=\"text-align: right;\">         1275444186</td></tr>\n",
       "<tr><td>evaluate_config_a694ab57</td><td>TERMINATED</td><td>130.203.136.143:4004292</td><td style=\"text-align: right;\">53533</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.53629    </td><td style=\"text-align: right;\">    9.90119e+08</td><td style=\"text-align: right;\">          0.53533</td><td style=\"text-align: right;\">              53533</td></tr>\n",
       "<tr><td>evaluate_config_a694ab58</td><td>TERMINATED</td><td>130.203.136.143:4004315</td><td style=\"text-align: right;\">38598</td><td style=\"text-align: right;\">20502</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.386778   </td><td style=\"text-align: right;\">    2.15315e+09</td><td style=\"text-align: right;\">          0.38598</td><td style=\"text-align: right;\">          791336196</td></tr>\n",
       "<tr><td>evaluate_config_a694ab59</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">60034</td><td style=\"text-align: right;\">25433</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.601071   </td><td style=\"text-align: right;\">    6.23301e+08</td><td style=\"text-align: right;\">          0.60034</td><td style=\"text-align: right;\">         1526844722</td></tr>\n",
       "<tr><td>evaluate_config_a694ab5a</td><td>TERMINATED</td><td>130.203.136.143:4004282</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">16050</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.00141    </td><td style=\"text-align: right;\">    2.2497e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">         1604983950</td></tr>\n",
       "<tr><td>evaluate_config_a694ab5b</td><td>TERMINATED</td><td>130.203.136.143:4004235</td><td style=\"text-align: right;\">13778</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.138384   </td><td style=\"text-align: right;\">    5.07256e+09</td><td style=\"text-align: right;\">          0.13778</td><td style=\"text-align: right;\">              13778</td></tr>\n",
       "<tr><td>evaluate_config_a694ab5c</td><td>TERMINATED</td><td>130.203.136.143:4004334</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">  640</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.00144    </td><td style=\"text-align: right;\">    2.2497e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">           63999360</td></tr>\n",
       "<tr><td>evaluate_config_a694ab5d</td><td>TERMINATED</td><td>130.203.136.143:4004379</td><td style=\"text-align: right;\">18271</td><td style=\"text-align: right;\"> 7140</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.183349   </td><td style=\"text-align: right;\">    4.45276e+09</td><td style=\"text-align: right;\">          0.18271</td><td style=\"text-align: right;\">          130454940</td></tr>\n",
       "<tr><td>evaluate_config_a694ab5e</td><td>TERMINATED</td><td>130.203.136.143:4004272</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">11510</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.0012     </td><td style=\"text-align: right;\">    2.2497e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">         1150988490</td></tr>\n",
       "<tr><td>evaluate_config_a694ab5f</td><td>TERMINATED</td><td>130.203.136.143:4004391</td><td style=\"text-align: right;\">22608</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.226458   </td><td style=\"text-align: right;\">    3.89274e+09</td><td style=\"text-align: right;\">          0.22608</td><td style=\"text-align: right;\">              22608</td></tr>\n",
       "<tr><td>evaluate_config_a694ab60</td><td>TERMINATED</td><td>130.203.136.143:4004257</td><td style=\"text-align: right;\">81162</td><td style=\"text-align: right;\">  424</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.812809   </td><td style=\"text-align: right;\">    1.47301e+07</td><td style=\"text-align: right;\">          0.81162</td><td style=\"text-align: right;\">           34412688</td></tr>\n",
       "<tr><td>evaluate_config_a694ab61</td><td>TERMINATED</td><td>130.203.136.143:4004412</td><td style=\"text-align: right;\">94698</td><td style=\"text-align: right;\">  449</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.948169   </td><td style=\"text-align: right;\">    9.4051e+07 </td><td style=\"text-align: right;\">          0.94698</td><td style=\"text-align: right;\">           42519402</td></tr>\n",
       "<tr><td>evaluate_config_a694ab62</td><td>TERMINATED</td><td>130.203.136.143:4004307</td><td style=\"text-align: right;\">88109</td><td style=\"text-align: right;\"> 1261</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.881719   </td><td style=\"text-align: right;\">    9.66581e+06</td><td style=\"text-align: right;\">          0.88109</td><td style=\"text-align: right;\">          111105449</td></tr>\n",
       "<tr><td>evaluate_config_a694ab63</td><td>TERMINATED</td><td>130.203.136.143:4004235</td><td style=\"text-align: right;\">42023</td><td style=\"text-align: right;\"> 1212</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.421077   </td><td style=\"text-align: right;\">    1.84702e+09</td><td style=\"text-align: right;\">          0.42023</td><td style=\"text-align: right;\">           50931876</td></tr>\n",
       "<tr><td>evaluate_config_a694ab64</td><td>TERMINATED</td><td>130.203.136.143:4004267</td><td style=\"text-align: right;\">88135</td><td style=\"text-align: right;\">19172</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.882624   </td><td style=\"text-align: right;\">    9.82822e+06</td><td style=\"text-align: right;\">          0.88135</td><td style=\"text-align: right;\">         1689724220</td></tr>\n",
       "<tr><td>evaluate_config_a694ab65</td><td>TERMINATED</td><td>130.203.136.143:4004253</td><td style=\"text-align: right;\">15821</td><td style=\"text-align: right;\">17465</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.158812   </td><td style=\"text-align: right;\">    4.78573e+09</td><td style=\"text-align: right;\">          0.15821</td><td style=\"text-align: right;\">          276313765</td></tr>\n",
       "<tr><td>evaluate_config_a694ab66</td><td>TERMINATED</td><td>130.203.136.143:4004415</td><td style=\"text-align: right;\">31155</td><td style=\"text-align: right;\">12371</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.31217    </td><td style=\"text-align: right;\">    2.89928e+09</td><td style=\"text-align: right;\">          0.31155</td><td style=\"text-align: right;\">          385418505</td></tr>\n",
       "<tr><td>evaluate_config_a694ab67</td><td>TERMINATED</td><td>130.203.136.143:4004426</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.00142    </td><td style=\"text-align: right;\">    2.2487e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">              99999</td></tr>\n",
       "<tr><td>evaluate_config_a694ab68</td><td>TERMINATED</td><td>130.203.136.143:4004241</td><td style=\"text-align: right;\">20323</td><td style=\"text-align: right;\"> 7644</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.203825   </td><td style=\"text-align: right;\">    4.18311e+09</td><td style=\"text-align: right;\">          0.20323</td><td style=\"text-align: right;\">          155349012</td></tr>\n",
       "<tr><td>evaluate_config_a694ab69</td><td>TERMINATED</td><td>130.203.136.143:4004391</td><td style=\"text-align: right;\">23849</td><td style=\"text-align: right;\">    1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.239094   </td><td style=\"text-align: right;\">    3.73942e+09</td><td style=\"text-align: right;\">          0.23849</td><td style=\"text-align: right;\">              23849</td></tr>\n",
       "<tr><td>evaluate_config_a694ab6a</td><td>TERMINATED</td><td>130.203.136.143:4004422</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">10496</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.00153    </td><td style=\"text-align: right;\">    2.2497e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">         1049589504</td></tr>\n",
       "<tr><td>evaluate_config_a694ab6c</td><td>TERMINATED</td><td>130.203.136.143:4004315</td><td style=\"text-align: right;\">71861</td><td style=\"text-align: right;\">15704</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.719769   </td><td style=\"text-align: right;\">    1.72633e+08</td><td style=\"text-align: right;\">          0.71861</td><td style=\"text-align: right;\">         1128505144</td></tr>\n",
       "<tr><td>evaluate_config_a694ab6d</td><td>TERMINATED</td><td>130.203.136.143:4004292</td><td style=\"text-align: right;\">20214</td><td style=\"text-align: right;\">15850</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.202689   </td><td style=\"text-align: right;\">    4.19723e+09</td><td style=\"text-align: right;\">          0.20214</td><td style=\"text-align: right;\">          320391900</td></tr>\n",
       "<tr><td>evaluate_config_a694ab6e</td><td>TERMINATED</td><td>130.203.136.143:4004434</td><td style=\"text-align: right;\">21371</td><td style=\"text-align: right;\">16204</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.214309   </td><td style=\"text-align: right;\">    4.04865e+09</td><td style=\"text-align: right;\">          0.21371</td><td style=\"text-align: right;\">          346295684</td></tr>\n",
       "<tr><td>evaluate_config_a694ab6f</td><td>TERMINATED</td><td>130.203.136.143:4004379</td><td style=\"text-align: right;\">19150</td><td style=\"text-align: right;\">12268</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.192081   </td><td style=\"text-align: right;\">    4.33622e+09</td><td style=\"text-align: right;\">          0.1915 </td><td style=\"text-align: right;\">          234932200</td></tr>\n",
       "<tr><td>evaluate_config_a7c33336</td><td>TERMINATED</td><td>130.203.136.143:4004285</td><td style=\"text-align: right;\">17307</td><td style=\"text-align: right;\">17026</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.17366    </td><td style=\"text-align: right;\">    4.58234e+09</td><td style=\"text-align: right;\">          0.17307</td><td style=\"text-align: right;\">          294668982</td></tr>\n",
       "<tr><td>evaluate_config_a7c33337</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">49429</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.00117    </td><td style=\"text-align: right;\">    2.2497e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">         4942850571</td></tr>\n",
       "<tr><td>evaluate_config_a7c33338</td><td>TERMINATED</td><td>130.203.136.143:4004431</td><td style=\"text-align: right;\">18984</td><td style=\"text-align: right;\">17094</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.190417   </td><td style=\"text-align: right;\">    4.35811e+09</td><td style=\"text-align: right;\">          0.18984</td><td style=\"text-align: right;\">          324512496</td></tr>\n",
       "<tr><td>evaluate_config_a7c33339</td><td>TERMINATED</td><td>130.203.136.143:4004253</td><td style=\"text-align: right;\">17320</td><td style=\"text-align: right;\">16902</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.173733   </td><td style=\"text-align: right;\">    4.58058e+09</td><td style=\"text-align: right;\">          0.1732 </td><td style=\"text-align: right;\">          292742640</td></tr>\n",
       "<tr><td>evaluate_config_a7c3333a</td><td>TERMINATED</td><td>130.203.136.143:4004263</td><td style=\"text-align: right;\">21658</td><td style=\"text-align: right;\">12050</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.217214   </td><td style=\"text-align: right;\">    4.01221e+09</td><td style=\"text-align: right;\">          0.21658</td><td style=\"text-align: right;\">          260978900</td></tr>\n",
       "<tr><td>evaluate_config_a7c3333b</td><td>TERMINATED</td><td>130.203.136.143:4004379</td><td style=\"text-align: right;\">19759</td><td style=\"text-align: right;\">10037</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.198181   </td><td style=\"text-align: right;\">    4.25639e+09</td><td style=\"text-align: right;\">          0.19759</td><td style=\"text-align: right;\">          198321083</td></tr>\n",
       "<tr><td>evaluate_config_a7c3333c</td><td>TERMINATED</td><td>130.203.136.143:4004235</td><td style=\"text-align: right;\"> 5195</td><td style=\"text-align: right;\">18798</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.052407   </td><td style=\"text-align: right;\">    6.36884e+09</td><td style=\"text-align: right;\">          0.05195</td><td style=\"text-align: right;\">           97655610</td></tr>\n",
       "<tr><td>evaluate_config_a7c3333d</td><td>TERMINATED</td><td>130.203.136.143:4004246</td><td style=\"text-align: right;\"> 5699</td><td style=\"text-align: right;\">21591</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0574064  </td><td style=\"text-align: right;\">    6.28865e+09</td><td style=\"text-align: right;\">          0.05699</td><td style=\"text-align: right;\">          123047109</td></tr>\n",
       "<tr><td>evaluate_config_a7c3333e</td><td>TERMINATED</td><td>130.203.136.143:4004257</td><td style=\"text-align: right;\"> 4390</td><td style=\"text-align: right;\">22752</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0443089  </td><td style=\"text-align: right;\">    6.49797e+09</td><td style=\"text-align: right;\">          0.0439 </td><td style=\"text-align: right;\">           99881280</td></tr>\n",
       "<tr><td>evaluate_config_a7c3333f</td><td>TERMINATED</td><td>130.203.136.143:4004307</td><td style=\"text-align: right;\"> 5825</td><td style=\"text-align: right;\">20572</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0587173  </td><td style=\"text-align: right;\">    6.26868e+09</td><td style=\"text-align: right;\">          0.05825</td><td style=\"text-align: right;\">          119831900</td></tr>\n",
       "<tr><td>evaluate_config_a7c33340</td><td>TERMINATED</td><td>130.203.136.143:4004263</td><td style=\"text-align: right;\"> 5513</td><td style=\"text-align: right;\">18686</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0555587  </td><td style=\"text-align: right;\">    6.31818e+09</td><td style=\"text-align: right;\">          0.05513</td><td style=\"text-align: right;\">          103015918</td></tr>\n",
       "<tr><td>evaluate_config_a7c33341</td><td>TERMINATED</td><td>130.203.136.143:4004391</td><td style=\"text-align: right;\"> 6081</td><td style=\"text-align: right;\">20300</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0612419  </td><td style=\"text-align: right;\">    6.22821e+09</td><td style=\"text-align: right;\">          0.06081</td><td style=\"text-align: right;\">          123444300</td></tr>\n",
       "<tr><td>evaluate_config_a7c33342</td><td>TERMINATED</td><td>130.203.136.143:4004285</td><td style=\"text-align: right;\">98295</td><td style=\"text-align: right;\">23455</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.984332   </td><td style=\"text-align: right;\">    1.76757e+08</td><td style=\"text-align: right;\">          0.98295</td><td style=\"text-align: right;\">         2305509225</td></tr>\n",
       "<tr><td>evaluate_config_a7c33343</td><td>TERMINATED</td><td>130.203.136.143:4004358</td><td style=\"text-align: right;\"> 5790</td><td style=\"text-align: right;\">24403</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.058352   </td><td style=\"text-align: right;\">    6.27422e+09</td><td style=\"text-align: right;\">          0.0579 </td><td style=\"text-align: right;\">          141293370</td></tr>\n",
       "<tr><td>evaluate_config_a7c33344</td><td>TERMINATED</td><td>130.203.136.143:4004267</td><td style=\"text-align: right;\">93425</td><td style=\"text-align: right;\">24855</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.935255   </td><td style=\"text-align: right;\">    7.09806e+07</td><td style=\"text-align: right;\">          0.93425</td><td style=\"text-align: right;\">         2322078375</td></tr>\n",
       "<tr><td>evaluate_config_a7c33345</td><td>TERMINATED</td><td>130.203.136.143:4004282</td><td style=\"text-align: right;\">19309</td><td style=\"text-align: right;\">24280</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.193651   </td><td style=\"text-align: right;\">    4.31531e+09</td><td style=\"text-align: right;\">          0.19309</td><td style=\"text-align: right;\">          468822520</td></tr>\n",
       "<tr><td>evaluate_config_a7c33346</td><td>TERMINATED</td><td>130.203.136.143:4004379</td><td style=\"text-align: right;\">99999</td><td style=\"text-align: right;\">14064</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     1.00138    </td><td style=\"text-align: right;\">    2.2497e+08 </td><td style=\"text-align: right;\">          0.99999</td><td style=\"text-align: right;\">         1406385936</td></tr>\n",
       "<tr><td>evaluate_config_a7c33347</td><td>TERMINATED</td><td>130.203.136.143:4004391</td><td style=\"text-align: right;\"> 4805</td><td style=\"text-align: right;\">23943</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.048454   </td><td style=\"text-align: right;\">    6.43124e+09</td><td style=\"text-align: right;\">          0.04805</td><td style=\"text-align: right;\">          115046115</td></tr>\n",
       "<tr><td>evaluate_config_a7c33348</td><td>TERMINATED</td><td>130.203.136.143:4004412</td><td style=\"text-align: right;\"> 4573</td><td style=\"text-align: right;\">23891</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0461342  </td><td style=\"text-align: right;\">    6.4685e+09 </td><td style=\"text-align: right;\">          0.04573</td><td style=\"text-align: right;\">          109253543</td></tr>\n",
       "<tr><td>evaluate_config_a7c33349</td><td>TERMINATED</td><td>130.203.136.143:4004434</td><td style=\"text-align: right;\"> 5903</td><td style=\"text-align: right;\">36036</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0594935  </td><td style=\"text-align: right;\">    6.25634e+09</td><td style=\"text-align: right;\">          0.05903</td><td style=\"text-align: right;\">          212720508</td></tr>\n",
       "<tr><td>evaluate_config_a7c3334a</td><td>TERMINATED</td><td>130.203.136.143:4004272</td><td style=\"text-align: right;\"> 4354</td><td style=\"text-align: right;\">37317</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0439513  </td><td style=\"text-align: right;\">    6.50378e+09</td><td style=\"text-align: right;\">          0.04354</td><td style=\"text-align: right;\">          162478218</td></tr>\n",
       "<tr><td>evaluate_config_a7c3334b</td><td>TERMINATED</td><td>130.203.136.143:4004422</td><td style=\"text-align: right;\"> 4110</td><td style=\"text-align: right;\">23662</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0415468  </td><td style=\"text-align: right;\">    6.54319e+09</td><td style=\"text-align: right;\">          0.0411 </td><td style=\"text-align: right;\">           97250820</td></tr>\n",
       "<tr><td>evaluate_config_a7c3334c</td><td>TERMINATED</td><td>130.203.136.143:4004334</td><td style=\"text-align: right;\"> 5977</td><td style=\"text-align: right;\">23882</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0602028  </td><td style=\"text-align: right;\">    6.24463e+09</td><td style=\"text-align: right;\">          0.05977</td><td style=\"text-align: right;\">          142742714</td></tr>\n",
       "<tr><td>evaluate_config_a7c3334d</td><td>TERMINATED</td><td>130.203.136.143:4004391</td><td style=\"text-align: right;\"> 9286</td><td style=\"text-align: right;\">24741</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.0932963  </td><td style=\"text-align: right;\">    5.73261e+09</td><td style=\"text-align: right;\">          0.09286</td><td style=\"text-align: right;\">          229744926</td></tr>\n",
       "<tr><td>evaluate_config_a7c3334e</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">98343</td><td style=\"text-align: right;\"> 8870</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.984797   </td><td style=\"text-align: right;\">    1.78036e+08</td><td style=\"text-align: right;\">          0.98343</td><td style=\"text-align: right;\">          872302410</td></tr>\n",
       "<tr><td>evaluate_config_a7c3334f</td><td>TERMINATED</td><td>130.203.136.143:4004315</td><td style=\"text-align: right;\">87079</td><td style=\"text-align: right;\"> 7253</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.872013   </td><td style=\"text-align: right;\">    4.32223e+06</td><td style=\"text-align: right;\">          0.87079</td><td style=\"text-align: right;\">          631583987</td></tr>\n",
       "<tr><td>evaluate_config_a7c33350</td><td>TERMINATED</td><td>130.203.136.143:4004412</td><td style=\"text-align: right;\">68035</td><td style=\"text-align: right;\"> 6668</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.681476   </td><td style=\"text-align: right;\">    2.87811e+08</td><td style=\"text-align: right;\">          0.68035</td><td style=\"text-align: right;\">          453657380</td></tr>\n",
       "<tr><td>evaluate_config_a7c33351</td><td>TERMINATED</td><td>130.203.136.143:4004241</td><td style=\"text-align: right;\">96251</td><td style=\"text-align: right;\"> 6667</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.963843   </td><td style=\"text-align: right;\">    1.26585e+08</td><td style=\"text-align: right;\">          0.96251</td><td style=\"text-align: right;\">          641705417</td></tr>\n",
       "<tr><td>evaluate_config_a7c33352</td><td>TERMINATED</td><td>130.203.136.143:4004415</td><td style=\"text-align: right;\">91532</td><td style=\"text-align: right;\"> 7534</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.915907   </td><td style=\"text-align: right;\">    4.2667e+07 </td><td style=\"text-align: right;\">          0.91532</td><td style=\"text-align: right;\">          689602088</td></tr>\n",
       "<tr><td>evaluate_config_a7c33353</td><td>TERMINATED</td><td>130.203.136.143:4004253</td><td style=\"text-align: right;\">63810</td><td style=\"text-align: right;\"> 7185</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.638678   </td><td style=\"text-align: right;\">    4.49016e+08</td><td style=\"text-align: right;\">          0.6381 </td><td style=\"text-align: right;\">          458474850</td></tr>\n",
       "<tr><td>evaluate_config_a7c33354</td><td>TERMINATED</td><td>130.203.136.143:4004434</td><td style=\"text-align: right;\">93174</td><td style=\"text-align: right;\"> 6020</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.933062   </td><td style=\"text-align: right;\">    6.68143e+07</td><td style=\"text-align: right;\">          0.93174</td><td style=\"text-align: right;\">          560907480</td></tr>\n",
       "<tr><td>evaluate_config_a7c33355</td><td>TERMINATED</td><td>130.203.136.143:4004235</td><td style=\"text-align: right;\">62207</td><td style=\"text-align: right;\"> 7133</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.623069   </td><td style=\"text-align: right;\">    5.19521e+08</td><td style=\"text-align: right;\">          0.62207</td><td style=\"text-align: right;\">          443722531</td></tr>\n",
       "<tr><td>evaluate_config_a7c33356</td><td>TERMINATED</td><td>130.203.136.143:4004272</td><td style=\"text-align: right;\">62505</td><td style=\"text-align: right;\"> 7172</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.62606    </td><td style=\"text-align: right;\">    5.06025e+08</td><td style=\"text-align: right;\">          0.62505</td><td style=\"text-align: right;\">          448285860</td></tr>\n",
       "<tr><td>evaluate_config_a7c33357</td><td>TERMINATED</td><td>130.203.136.143:4004431</td><td style=\"text-align: right;\">69567</td><td style=\"text-align: right;\"> 7693</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.696734   </td><td style=\"text-align: right;\">    2.38177e+08</td><td style=\"text-align: right;\">          0.69567</td><td style=\"text-align: right;\">          535178931</td></tr>\n",
       "<tr><td>evaluate_config_a7c33358</td><td>TERMINATED</td><td>130.203.136.143:4004246</td><td style=\"text-align: right;\">66839</td><td style=\"text-align: right;\"> 6652</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.669426   </td><td style=\"text-align: right;\">    3.29822e+08</td><td style=\"text-align: right;\">          0.66839</td><td style=\"text-align: right;\">          444613028</td></tr>\n",
       "<tr><td>evaluate_config_a7c33359</td><td>TERMINATED</td><td>130.203.136.143:4004282</td><td style=\"text-align: right;\">59974</td><td style=\"text-align: right;\"> 6061</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.60068    </td><td style=\"text-align: right;\">    6.26301e+08</td><td style=\"text-align: right;\">          0.59974</td><td style=\"text-align: right;\">          363502414</td></tr>\n",
       "<tr><td>evaluate_config_a7c3335a</td><td>TERMINATED</td><td>130.203.136.143:4004426</td><td style=\"text-align: right;\">62435</td><td style=\"text-align: right;\"> 7656</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.62535    </td><td style=\"text-align: right;\">    5.09179e+08</td><td style=\"text-align: right;\">          0.62435</td><td style=\"text-align: right;\">          478002360</td></tr>\n",
       "<tr><td>evaluate_config_a7c3335b</td><td>TERMINATED</td><td>130.203.136.143:4004307</td><td style=\"text-align: right;\">56407</td><td style=\"text-align: right;\"> 7873</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.565059   </td><td style=\"text-align: right;\">    8.1756e+08 </td><td style=\"text-align: right;\">          0.56407</td><td style=\"text-align: right;\">          444092311</td></tr>\n",
       "<tr><td>evaluate_config_a7c3335c</td><td>TERMINATED</td><td>130.203.136.143:4004257</td><td style=\"text-align: right;\">59466</td><td style=\"text-align: right;\"> 6921</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.595446   </td><td style=\"text-align: right;\">    6.51985e+08</td><td style=\"text-align: right;\">          0.59466</td><td style=\"text-align: right;\">          411564186</td></tr>\n",
       "<tr><td>evaluate_config_a7c3335d</td><td>TERMINATED</td><td>130.203.136.143:4004292</td><td style=\"text-align: right;\">64284</td><td style=\"text-align: right;\"> 6381</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.643857   </td><td style=\"text-align: right;\">    4.29153e+08</td><td style=\"text-align: right;\">          0.64284</td><td style=\"text-align: right;\">          410196204</td></tr>\n",
       "<tr><td>evaluate_config_a7c3335e</td><td>TERMINATED</td><td>130.203.136.143:4004422</td><td style=\"text-align: right;\">63766</td><td style=\"text-align: right;\"> 6183</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.638707   </td><td style=\"text-align: right;\">    4.50883e+08</td><td style=\"text-align: right;\">          0.63766</td><td style=\"text-align: right;\">          394265178</td></tr>\n",
       "<tr><td>evaluate_config_a7c3335f</td><td>TERMINATED</td><td>130.203.136.143:4004391</td><td style=\"text-align: right;\">59989</td><td style=\"text-align: right;\"> 6825</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.60087    </td><td style=\"text-align: right;\">    6.2555e+08 </td><td style=\"text-align: right;\">          0.59989</td><td style=\"text-align: right;\">          409424925</td></tr>\n",
       "<tr><td>evaluate_config_a7c33360</td><td>TERMINATED</td><td>130.203.136.143:4004285</td><td style=\"text-align: right;\">64750</td><td style=\"text-align: right;\"> 6714</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.648497   </td><td style=\"text-align: right;\">    4.10062e+08</td><td style=\"text-align: right;\">          0.6475 </td><td style=\"text-align: right;\">          434731500</td></tr>\n",
       "<tr><td>evaluate_config_a7c33361</td><td>TERMINATED</td><td>130.203.136.143:4004263</td><td style=\"text-align: right;\">64635</td><td style=\"text-align: right;\"> 5352</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.647385   </td><td style=\"text-align: right;\">    4.14733e+08</td><td style=\"text-align: right;\">          0.64635</td><td style=\"text-align: right;\">          345926520</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9120</td><td>TERMINATED</td><td>130.203.136.143:4004358</td><td style=\"text-align: right;\">61320</td><td style=\"text-align: right;\"> 5270</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.613754   </td><td style=\"text-align: right;\">    5.60742e+08</td><td style=\"text-align: right;\">          0.6132 </td><td style=\"text-align: right;\">          323156400</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9121</td><td>TERMINATED</td><td>130.203.136.143:4004379</td><td style=\"text-align: right;\">60345</td><td style=\"text-align: right;\"> 6500</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.60443    </td><td style=\"text-align: right;\">    6.07869e+08</td><td style=\"text-align: right;\">          0.60345</td><td style=\"text-align: right;\">          392242500</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9122</td><td>TERMINATED</td><td>130.203.136.143:4004334</td><td style=\"text-align: right;\">60701</td><td style=\"text-align: right;\"> 5456</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.608014   </td><td style=\"text-align: right;\">    5.90441e+08</td><td style=\"text-align: right;\">          0.60701</td><td style=\"text-align: right;\">          331184656</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9123</td><td>TERMINATED</td><td>130.203.136.143:4004253</td><td style=\"text-align: right;\">63954</td><td style=\"text-align: right;\"> 9421</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.640559   </td><td style=\"text-align: right;\">    4.42934e+08</td><td style=\"text-align: right;\">          0.63954</td><td style=\"text-align: right;\">          602510634</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9124</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">   34</td><td style=\"text-align: right;\"> 4766</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.00077486 </td><td style=\"text-align: right;\">    7.21922e+09</td><td style=\"text-align: right;\">          0.00034</td><td style=\"text-align: right;\">             162044</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9125</td><td>TERMINATED</td><td>130.203.136.143:4004412</td><td style=\"text-align: right;\">31437</td><td style=\"text-align: right;\"> 5012</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.314837   </td><td style=\"text-align: right;\">    2.86899e+09</td><td style=\"text-align: right;\">          0.31437</td><td style=\"text-align: right;\">          157562244</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9126</td><td>TERMINATED</td><td>130.203.136.143:4004267</td><td style=\"text-align: right;\">33164</td><td style=\"text-align: right;\"> 4020</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.33238    </td><td style=\"text-align: right;\">    2.68697e+09</td><td style=\"text-align: right;\">          0.33164</td><td style=\"text-align: right;\">          133319280</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9127</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">37627</td><td style=\"text-align: right;\"> 4009</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.377053   </td><td style=\"text-align: right;\">    2.2442e+09 </td><td style=\"text-align: right;\">          0.37627</td><td style=\"text-align: right;\">          150846643</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9128</td><td>TERMINATED</td><td>130.203.136.143:4004257</td><td style=\"text-align: right;\">34313</td><td style=\"text-align: right;\"> 4104</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.34384    </td><td style=\"text-align: right;\">    2.56917e+09</td><td style=\"text-align: right;\">          0.34313</td><td style=\"text-align: right;\">          140820552</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9129</td><td>TERMINATED</td><td>130.203.136.143:4004246</td><td style=\"text-align: right;\">33526</td><td style=\"text-align: right;\"> 4387</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.336      </td><td style=\"text-align: right;\">    2.64957e+09</td><td style=\"text-align: right;\">          0.33526</td><td style=\"text-align: right;\">          147078562</td></tr>\n",
       "<tr><td>evaluate_config_a8ed912a</td><td>TERMINATED</td><td>130.203.136.143:4004431</td><td style=\"text-align: right;\">30689</td><td style=\"text-align: right;\"> 3279</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.307564   </td><td style=\"text-align: right;\">    2.94968e+09</td><td style=\"text-align: right;\">          0.30689</td><td style=\"text-align: right;\">          100629231</td></tr>\n",
       "<tr><td>evaluate_config_a8ed912b</td><td>TERMINATED</td><td>130.203.136.143:4004391</td><td style=\"text-align: right;\">31996</td><td style=\"text-align: right;\"> 2973</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.320668   </td><td style=\"text-align: right;\">    2.80942e+09</td><td style=\"text-align: right;\">          0.31996</td><td style=\"text-align: right;\">           95124108</td></tr>\n",
       "<tr><td>evaluate_config_a8ed912c</td><td>TERMINATED</td><td>130.203.136.143:4004315</td><td style=\"text-align: right;\">31397</td><td style=\"text-align: right;\"> 3402</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.314687   </td><td style=\"text-align: right;\">    2.87328e+09</td><td style=\"text-align: right;\">          0.31397</td><td style=\"text-align: right;\">          106812594</td></tr>\n",
       "<tr><td>evaluate_config_a8ed912d</td><td>TERMINATED</td><td>130.203.136.143:4004263</td><td style=\"text-align: right;\">34753</td><td style=\"text-align: right;\"> 3647</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.348273   </td><td style=\"text-align: right;\">    2.52476e+09</td><td style=\"text-align: right;\">          0.34753</td><td style=\"text-align: right;\">          126744191</td></tr>\n",
       "<tr><td>evaluate_config_a8ed912e</td><td>TERMINATED</td><td>130.203.136.143:4004415</td><td style=\"text-align: right;\">28111</td><td style=\"text-align: right;\"> 3456</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.281793   </td><td style=\"text-align: right;\">    3.23636e+09</td><td style=\"text-align: right;\">          0.28111</td><td style=\"text-align: right;\">           97151616</td></tr>\n",
       "<tr><td>evaluate_config_a8ed912f</td><td>TERMINATED</td><td>130.203.136.143:4004358</td><td style=\"text-align: right;\">31653</td><td style=\"text-align: right;\"> 3198</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.317244   </td><td style=\"text-align: right;\">    2.8459e+09 </td><td style=\"text-align: right;\">          0.31653</td><td style=\"text-align: right;\">          101226294</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9130</td><td>TERMINATED</td><td>130.203.136.143:4004267</td><td style=\"text-align: right;\">31331</td><td style=\"text-align: right;\"> 3033</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.313993   </td><td style=\"text-align: right;\">    2.88036e+09</td><td style=\"text-align: right;\">          0.31331</td><td style=\"text-align: right;\">           95026923</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9131</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">33397</td><td style=\"text-align: right;\"> 1074</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.334658   </td><td style=\"text-align: right;\">    2.66287e+09</td><td style=\"text-align: right;\">          0.33397</td><td style=\"text-align: right;\">           35868378</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9132</td><td>TERMINATED</td><td>130.203.136.143:4004431</td><td style=\"text-align: right;\">32618</td><td style=\"text-align: right;\">   31</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.32688    </td><td style=\"text-align: right;\">    2.74387e+09</td><td style=\"text-align: right;\">          0.32618</td><td style=\"text-align: right;\">            1011158</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9133</td><td>TERMINATED</td><td>130.203.136.143:4004272</td><td style=\"text-align: right;\">30340</td><td style=\"text-align: right;\">  254</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.304073   </td><td style=\"text-align: right;\">    2.98772e+09</td><td style=\"text-align: right;\">          0.3034 </td><td style=\"text-align: right;\">            7706360</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9134</td><td>TERMINATED</td><td>130.203.136.143:4004285</td><td style=\"text-align: right;\">13067</td><td style=\"text-align: right;\">   12</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.13122    </td><td style=\"text-align: right;\">    5.17436e+09</td><td style=\"text-align: right;\">          0.13067</td><td style=\"text-align: right;\">             156804</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9135</td><td>TERMINATED</td><td>130.203.136.143:4004257</td><td style=\"text-align: right;\">26962</td><td style=\"text-align: right;\">  654</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.27029    </td><td style=\"text-align: right;\">    3.36841e+09</td><td style=\"text-align: right;\">          0.26962</td><td style=\"text-align: right;\">           17633148</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9136</td><td>TERMINATED</td><td>130.203.136.143:4004307</td><td style=\"text-align: right;\">25500</td><td style=\"text-align: right;\">12578</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.25569    </td><td style=\"text-align: right;\">    3.54025e+09</td><td style=\"text-align: right;\">          0.255  </td><td style=\"text-align: right;\">          320739000</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9137</td><td>TERMINATED</td><td>130.203.136.143:4004334</td><td style=\"text-align: right;\">13032</td><td style=\"text-align: right;\"> 1141</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.130828   </td><td style=\"text-align: right;\">    5.17939e+09</td><td style=\"text-align: right;\">          0.13032</td><td style=\"text-align: right;\">           14869512</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9138</td><td>TERMINATED</td><td>130.203.136.143:4004434</td><td style=\"text-align: right;\">27043</td><td style=\"text-align: right;\">  296</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.271077   </td><td style=\"text-align: right;\">    3.35901e+09</td><td style=\"text-align: right;\">          0.27043</td><td style=\"text-align: right;\">            8004728</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9139</td><td>TERMINATED</td><td>130.203.136.143:4004246</td><td style=\"text-align: right;\">12438</td><td style=\"text-align: right;\">   74</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.124879   </td><td style=\"text-align: right;\">    5.26524e+09</td><td style=\"text-align: right;\">          0.12438</td><td style=\"text-align: right;\">             920412</td></tr>\n",
       "<tr><td>evaluate_config_a8ed913a</td><td>TERMINATED</td><td>130.203.136.143:4004426</td><td style=\"text-align: right;\">12412</td><td style=\"text-align: right;\">11595</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.124681   </td><td style=\"text-align: right;\">    5.26902e+09</td><td style=\"text-align: right;\">          0.12412</td><td style=\"text-align: right;\">          143917140</td></tr>\n",
       "<tr><td>evaluate_config_a8ed913b</td><td>TERMINATED</td><td>130.203.136.143:4004422</td><td style=\"text-align: right;\">97075</td><td style=\"text-align: right;\">  103</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.971707   </td><td style=\"text-align: right;\">    1.45805e+08</td><td style=\"text-align: right;\">          0.97075</td><td style=\"text-align: right;\">            9998725</td></tr>\n",
       "<tr><td>evaluate_config_a8ed913c</td><td>TERMINATED</td><td>130.203.136.143:4004415</td><td style=\"text-align: right;\">27262</td><td style=\"text-align: right;\">11527</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.273275   </td><td style=\"text-align: right;\">    3.33368e+09</td><td style=\"text-align: right;\">          0.27262</td><td style=\"text-align: right;\">          314249074</td></tr>\n",
       "<tr><td>evaluate_config_a8ed913d</td><td>TERMINATED</td><td>130.203.136.143:4004235</td><td style=\"text-align: right;\">90332</td><td style=\"text-align: right;\">  327</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.904618   </td><td style=\"text-align: right;\">    2.84299e+07</td><td style=\"text-align: right;\">          0.90332</td><td style=\"text-align: right;\">           29538564</td></tr>\n",
       "<tr><td>evaluate_config_a8ed913e</td><td>TERMINATED</td><td>130.203.136.143:4004253</td><td style=\"text-align: right;\">11479</td><td style=\"text-align: right;\">  596</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.115334   </td><td style=\"text-align: right;\">    5.40534e+09</td><td style=\"text-align: right;\">          0.11479</td><td style=\"text-align: right;\">            6841484</td></tr>\n",
       "<tr><td>evaluate_config_a8ed913f</td><td>TERMINATED</td><td>130.203.136.143:4004292</td><td style=\"text-align: right;\">99859</td><td style=\"text-align: right;\">   96</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.999941   </td><td style=\"text-align: right;\">    2.20789e+08</td><td style=\"text-align: right;\">          0.99859</td><td style=\"text-align: right;\">            9586464</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9140</td><td>TERMINATED</td><td>130.203.136.143:4004246</td><td style=\"text-align: right;\">11093</td><td style=\"text-align: right;\">13761</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.111424   </td><td style=\"text-align: right;\">    5.46224e+09</td><td style=\"text-align: right;\">          0.11093</td><td style=\"text-align: right;\">          152650773</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9141</td><td>TERMINATED</td><td>130.203.136.143:4004272</td><td style=\"text-align: right;\">44343</td><td style=\"text-align: right;\">12129</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.444189   </td><td style=\"text-align: right;\">    1.65299e+09</td><td style=\"text-align: right;\">          0.44343</td><td style=\"text-align: right;\">          537836247</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9142</td><td>TERMINATED</td><td>130.203.136.143:4004241</td><td style=\"text-align: right;\">97953</td><td style=\"text-align: right;\">12194</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.980887   </td><td style=\"text-align: right;\">    1.6778e+08 </td><td style=\"text-align: right;\">          0.97953</td><td style=\"text-align: right;\">         1194438882</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9143</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">41995</td><td style=\"text-align: right;\">12266</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.420761   </td><td style=\"text-align: right;\">    1.84943e+09</td><td style=\"text-align: right;\">          0.41995</td><td style=\"text-align: right;\">          515110670</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9144</td><td>TERMINATED</td><td>130.203.136.143:4004391</td><td style=\"text-align: right;\">44229</td><td style=\"text-align: right;\">10221</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.443065   </td><td style=\"text-align: right;\">    1.66227e+09</td><td style=\"text-align: right;\">          0.44229</td><td style=\"text-align: right;\">          452064609</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9145</td><td>TERMINATED</td><td>130.203.136.143:4004379</td><td style=\"text-align: right;\">95873</td><td style=\"text-align: right;\">13212</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.960054   </td><td style=\"text-align: right;\">    1.18222e+08</td><td style=\"text-align: right;\">          0.95873</td><td style=\"text-align: right;\">         1266674076</td></tr>\n",
       "<tr><td>evaluate_config_a8ed9146</td><td>TERMINATED</td><td>130.203.136.143:4004412</td><td style=\"text-align: right;\">94433</td><td style=\"text-align: right;\">13318</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213a4</td><td>TERMINATED</td><td>130.203.136.143:4004257</td><td style=\"text-align: right;\">91275</td><td style=\"text-align: right;\">14152</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.914024   </td><td style=\"text-align: right;\">    3.93756e+07</td><td style=\"text-align: right;\">          0.91275</td><td style=\"text-align: right;\">         1291723800</td></tr>\n",
       "<tr><td>evaluate_config_aa2213a5</td><td>TERMINATED</td><td>130.203.136.143:4004263</td><td style=\"text-align: right;\">97962</td><td style=\"text-align: right;\">13928</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213a6</td><td>TERMINATED</td><td>130.203.136.143:4004282</td><td style=\"text-align: right;\">99109</td><td style=\"text-align: right;\">13488</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213a7</td><td>TERMINATED</td><td>130.203.136.143:4004415</td><td style=\"text-align: right;\">97596</td><td style=\"text-align: right;\">13138</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213a8</td><td>TERMINATED</td><td>130.203.136.143:4004434</td><td style=\"text-align: right;\">98110</td><td style=\"text-align: right;\">14391</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213a9</td><td>TERMINATED</td><td>130.203.136.143:4004358</td><td style=\"text-align: right;\">89547</td><td style=\"text-align: right;\">13962</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213aa</td><td>TERMINATED</td><td>130.203.136.143:4004246</td><td style=\"text-align: right;\">90258</td><td style=\"text-align: right;\">14402</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213ab</td><td>TERMINATED</td><td>130.203.136.143:4004426</td><td style=\"text-align: right;\">99230</td><td style=\"text-align: right;\">14377</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213ac</td><td>TERMINATED</td><td>130.203.136.143:4004315</td><td style=\"text-align: right;\">93468</td><td style=\"text-align: right;\">46755</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213ad</td><td>TERMINATED</td><td>130.203.136.143:4004253</td><td style=\"text-align: right;\">46193</td><td style=\"text-align: right;\">14087</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">     0.462764   </td><td style=\"text-align: right;\">    1.50598e+09</td><td style=\"text-align: right;\">          0.46193</td><td style=\"text-align: right;\">          650720791</td></tr>\n",
       "<tr><td>evaluate_config_aa2213ae</td><td>TERMINATED</td><td>130.203.136.143:4004285</td><td style=\"text-align: right;\">90467</td><td style=\"text-align: right;\">14122</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213af</td><td>TERMINATED</td><td>130.203.136.143:4004307</td><td style=\"text-align: right;\">88443</td><td style=\"text-align: right;\">13145</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213b0</td><td>TERMINATED</td><td>130.203.136.143:4004334</td><td style=\"text-align: right;\">88802</td><td style=\"text-align: right;\">45681</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213b1</td><td>TERMINATED</td><td>130.203.136.143:4004431</td><td style=\"text-align: right;\">93776</td><td style=\"text-align: right;\">54526</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213b2</td><td>TERMINATED</td><td>130.203.136.143:4004202</td><td style=\"text-align: right;\">87643</td><td style=\"text-align: right;\">29110</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213b3</td><td>TERMINATED</td><td>130.203.136.143:4004272</td><td style=\"text-align: right;\">87901</td><td style=\"text-align: right;\">14572</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213b4</td><td>TERMINATED</td><td>130.203.136.143:4004391</td><td style=\"text-align: right;\">87185</td><td style=\"text-align: right;\">28843</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213b5</td><td>TERMINATED</td><td>130.203.136.143:4004235</td><td style=\"text-align: right;\">86586</td><td style=\"text-align: right;\">29416</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213b6</td><td>TERMINATED</td><td>130.203.136.143:4004267</td><td style=\"text-align: right;\">88723</td><td style=\"text-align: right;\">28896</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213b7</td><td>TERMINATED</td><td>130.203.136.143:4004422</td><td style=\"text-align: right;\">87678</td><td style=\"text-align: right;\">45079</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213b8</td><td>TERMINATED</td><td>130.203.136.143:4004292</td><td style=\"text-align: right;\">85010</td><td style=\"text-align: right;\">27733</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213b9</td><td>TERMINATED</td><td>130.203.136.143:4004241</td><td style=\"text-align: right;\">79122</td><td style=\"text-align: right;\">47867</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213ba</td><td>TERMINATED</td><td>130.203.136.143:4004253</td><td style=\"text-align: right;\">84691</td><td style=\"text-align: right;\">30414</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "<tr><td>evaluate_config_aa2213bb</td><td>TERMINATED</td><td>                       </td><td style=\"text-align: right;\">84393</td><td style=\"text-align: right;\">26294</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">                 </td><td style=\"text-align: right;\">                   </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 04:05:11,081\tINFO tune.py:747 -- Total run time: 11.84 seconds (10.54 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 25229.14119804401, 'evaluation_cost': 0.84841, 'constraint_metric': 138799876, 'time_this_iter_s': 0.8488931655883789, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 1, 'trial_id': 'a694ab52', 'experiment_id': 'fd9619caaad1438884ac27a5c6171e14', 'date': '2022-07-07_04-05-04', 'timestamp': 1657191904, 'time_total_s': 0.8488931655883789, 'pid': 4004241, 'hostname': 'i4-l-qxw5138-01.ad.psu.edu', 'node_ip': '130.203.136.143', 'config': {'x': 84841, 'y': 1636}, 'time_since_restore': 0.8488931655883789, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'warmup_time': 0.00529789924621582, 'experiment_tag': '48_x=84841,y=1636'}\n",
      "{'x': 84841, 'y': 1636}\n"
     ]
    }
   ],
   "source": [
    "# require: pip install flaml[ray]\n",
    "analysis = tune.run(\n",
    "    evaluate_config,  # the function to evaluate a config\n",
    "    config=config_search_space,  # the search space defined\n",
    "    metric=\"score\",\n",
    "    mode=\"min\",  # the optimization mode, \"min\" or \"max\"\n",
    "    num_samples=-1,  # the maximal number of configs to try, -1 means infinite\n",
    "    time_budget_s=10,  # the time budget in seconds\n",
    "    use_ray=True,\n",
    "    resources_per_trial={\"cpu\": 2}  # limit resources allocated per trial\n",
    ")\n",
    "print(analysis.best_trial.last_result)  # the best trial's result\n",
    "print(analysis.best_config)  # the best config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 04:09:43,543\tWARNING optuna.py:297 -- You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-07-07 04:09:43,547]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "2022-07-07 04:09:43,549\tWARNING optuna.py:297 -- You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-07-07 04:09:43,552]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 07-07 04:09:43] {506} INFO - trial 1 config: {'b': 0.8, 'a': 3.0}\n",
      "[flaml.tune.tune: 07-07 04:09:43] {506} INFO - trial 2 config: {'b': 0.8, 'a': 2.0}\n",
      "[flaml.tune.tune: 07-07 04:09:43] {506} INFO - trial 3 config: {'a': 0.7636074368340785, 'b': 0.0622558480782045}\n",
      "[flaml.tune.tune: 07-07 04:09:43] {506} INFO - trial 4 config: {'a': 0.6273117525770127, 'b': 2.246411647615836}\n",
      "[flaml.tune.tune: 07-07 04:09:43] {506} INFO - trial 5 config: {'a': 0.4935219421795645, 'b': 0.674389936592543}\n",
      "[flaml.tune.tune: 07-07 04:09:43] {506} INFO - trial 6 config: {'a': 0.19608223611202774, 'b': 2.2815921365968763}\n",
      "[flaml.tune.tune: 07-07 04:09:43] {506} INFO - trial 7 config: {'a': 0.1674197281969101, 'b': 0.2650194425220308}\n",
      "[flaml.tune.tune: 07-07 04:09:43] {506} INFO - trial 8 config: {'a': 0.6785062201841192, 'b': 2.8601800385848097}\n",
      "[flaml.tune.tune: 07-07 04:09:43] {506} INFO - trial 9 config: {'a': 0.003908783664635307, 'b': 1.53657679015733}\n",
      "[flaml.tune.tune: 07-07 04:09:43] {506} INFO - trial 10 config: {'a': 0.8044947520355924, 'b': 1.8375782004881644}\n"
     ]
    }
   ],
   "source": [
    "from flaml import tune\n",
    "\n",
    "config_search_space = {\n",
    "    \"a\": tune.uniform(lower=0, upper=0.99),\n",
    "    \"b\": tune.uniform(lower=0, upper=3),\n",
    "}\n",
    "\n",
    "def simple_obj(config):\n",
    "    return config[\"a\"] + config[\"b\"]\n",
    "\n",
    "points_to_evaluate = [\n",
    "    {\"b\": .99, \"a\": 3},\n",
    "    {\"b\": .99, \"a\": 2},\n",
    "    {\"b\": .80, \"a\": 3},\n",
    "    {\"b\": .80, \"a\": 2},\n",
    "]\n",
    "evaluated_rewards = [3.99, 2.99]\n",
    "\n",
    "analysis = tune.run(\n",
    "    simple_obj,\n",
    "    config=config_search_space,\n",
    "    mode=\"max\",\n",
    "    points_to_evaluate=points_to_evaluate,\n",
    "    evaluated_rewards=evaluated_rewards,\n",
    "    num_samples=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial scheduling\n",
    "\n",
    "###  An authentic scheduler implemented in FLAML (`scheduler='flaml'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "        \"n_estimators\": tune.lograndint(lower=4, upper=32768),\n",
    "        \"max_leaves\": tune.lograndint(lower=4, upper=32768),\n",
    "        \"learning_rate\": tune.loguniform(lower=1 / 1024, upper=1.0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Set a evaluation function with resource dimension'''\n",
    "def obj_from_resource_attr(resource_attr, X_train, X_test, y_train, y_test, config):\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # in this example sample size is our resource dimension\n",
    "    resource = int(config[resource_attr])\n",
    "    sampled_X_train = X_train.iloc[:resource]\n",
    "    sampled_y_train = y_train[:resource]\n",
    "\n",
    "    # construct a LGBM model from the config\n",
    "    # note that you need to first remove the resource_attr field\n",
    "    # from the config as it is not part of the original search space\n",
    "    model_config = config.copy()\n",
    "    del model_config[resource_attr]\n",
    "    model = LGBMClassifier(**model_config)\n",
    "\n",
    "    model.fit(sampled_X_train, sampled_y_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    test_loss = 1.0 - accuracy_score(y_test, y_test_predict)\n",
    "    return {\"loss\": test_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 04:19:14,463\tWARNING optuna.py:297 -- You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-07-07 04:19:14,465]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 1 config: {'n_estimators': 9, 'max_leaves': 1364, 'learning_rate': 0.012074374674294664, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 2 config: {'n_estimators': 4048, 'max_leaves': 4, 'learning_rate': 0.07891713267442702, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 3 config: {'n_estimators': 3295, 'max_leaves': 334, 'learning_rate': 0.004638797085780012, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 4 config: {'n_estimators': 21, 'max_leaves': 3668, 'learning_rate': 0.003153366048206083, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 5 config: {'n_estimators': 8, 'max_leaves': 1845, 'learning_rate': 0.7239356970260848, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset from openml_task7592.pkl\n",
      "X_train.shape: (43957, 14), y_train.shape: (43957,),\n",
      "X_test.shape: (4885, 14), y_test.shape: (4885,)\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1364 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=334 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=3668 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1845 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 6 config: {'n_estimators': 4, 'max_leaves': 379, 'learning_rate': 0.2728556109672425, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 7 config: {'n_estimators': 948, 'max_leaves': 2573, 'learning_rate': 0.0073847289359894605, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 8 config: {'n_estimators': 15449, 'max_leaves': 2409, 'learning_rate': 0.04196829547317673, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 9 config: {'n_estimators': 13, 'max_leaves': 106, 'learning_rate': 0.10448271169801053, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 10 config: {'n_estimators': 199, 'max_leaves': 185, 'learning_rate': 0.07069097177435173, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=379 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=2573 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=2409 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=106 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=185 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 11 config: {'n_estimators': 382, 'max_leaves': 1340, 'learning_rate': 0.06295171682621144, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 12 config: {'n_estimators': 5520, 'max_leaves': 413, 'learning_rate': 0.5308914484951052, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:14] {506} INFO - trial 13 config: {'n_estimators': 3503, 'max_leaves': 7, 'learning_rate': 0.0010918443163764437, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 14 config: {'n_estimators': 54, 'max_leaves': 30204, 'learning_rate': 0.004360679238440181, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 15 config: {'n_estimators': 49, 'max_leaves': 23677, 'learning_rate': 0.0010641529214071718, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 16 config: {'n_estimators': 1534, 'max_leaves': 37, 'learning_rate': 0.006371183957388993, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1340 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=413 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=7 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=30204 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=23677 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=37 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 17 config: {'n_estimators': 29723, 'max_leaves': 9340, 'learning_rate': 0.0027991149620651954, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 18 config: {'n_estimators': 70, 'max_leaves': 34, 'learning_rate': 0.011193803613244459, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=9340 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 19 config: {'n_estimators': 7696, 'max_leaves': 6735, 'learning_rate': 0.0171883008494944, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 20 config: {'n_estimators': 24847, 'max_leaves': 13127, 'learning_rate': 0.0022947034584149804, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=34 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=6735 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=13127 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 21 config: {'n_estimators': 167, 'max_leaves': 15, 'learning_rate': 0.01693528096911362, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 22 config: {'n_estimators': 10494, 'max_leaves': 746, 'learning_rate': 0.02385060065057464, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 23 config: {'n_estimators': 1934, 'max_leaves': 92, 'learning_rate': 0.0019836952742413195, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 24 config: {'n_estimators': 26875, 'max_leaves': 4, 'learning_rate': 0.0017068232742646725, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=15 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=746 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=92 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 25 config: {'n_estimators': 281, 'max_leaves': 688, 'learning_rate': 0.016552541070398875, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:15] {506} INFO - trial 26 config: {'n_estimators': 1778, 'max_leaves': 81, 'learning_rate': 0.03175152998663522, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 27 config: {'n_estimators': 688, 'max_leaves': 7, 'learning_rate': 0.001542522148885942, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 28 config: {'n_estimators': 3797, 'max_leaves': 791, 'learning_rate': 0.007264101943760989, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 29 config: {'n_estimators': 630, 'max_leaves': 177, 'learning_rate': 0.14424489344601685, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 30 config: {'n_estimators': 1174, 'max_leaves': 34, 'learning_rate': 0.03769197598985876, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=688 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=81 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=7 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=791 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=177 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=34 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 31 config: {'n_estimators': 3554, 'max_leaves': 12, 'learning_rate': 0.005723824290933867, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 32 config: {'n_estimators': 540, 'max_leaves': 970, 'learning_rate': 0.2234297355835903, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 33 config: {'n_estimators': 988, 'max_leaves': 207, 'learning_rate': 0.16430394221281475, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 34 config: {'n_estimators': 2835, 'max_leaves': 23, 'learning_rate': 0.004113773682186522, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 35 config: {'n_estimators': 480, 'max_leaves': 13, 'learning_rate': 0.3286382866833518, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 36 config: {'n_estimators': 5897, 'max_leaves': 254, 'learning_rate': 0.9259903592746499, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=12 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=970 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=207 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=23 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=13 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=254 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 37 config: {'n_estimators': 2526, 'max_leaves': 1332, 'learning_rate': 0.19284215718355668, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 38 config: {'n_estimators': 12671, 'max_leaves': 4, 'learning_rate': 0.0018253161972409146, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 39 config: {'n_estimators': 199, 'max_leaves': 439, 'learning_rate': 0.011304611020148745, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 40 config: {'n_estimators': 103, 'max_leaves': 88, 'learning_rate': 0.003539923584406662, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1332 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=439 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=88 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 41 config: {'n_estimators': 18778, 'max_leaves': 3702, 'learning_rate': 0.027602122008566297, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 42 config: {'n_estimators': 270, 'max_leaves': 62, 'learning_rate': 0.05507878569900855, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 43 config: {'n_estimators': 918, 'max_leaves': 564, 'learning_rate': 0.011450265080289271, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=3702 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=62 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=564 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 44 config: {'n_estimators': 1817, 'max_leaves': 313, 'learning_rate': 0.008383218707494321, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 45 config: {'n_estimators': 663, 'max_leaves': 178, 'learning_rate': 0.10140492706094423, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:16] {506} INFO - trial 46 config: {'n_estimators': 4785, 'max_leaves': 137, 'learning_rate': 0.0013296286140323664, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 47 config: {'n_estimators': 1109, 'max_leaves': 6, 'learning_rate': 0.09122606727247846, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 48 config: {'n_estimators': 778, 'max_leaves': 54, 'learning_rate': 0.04335186975552169, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 49 config: {'n_estimators': 3992, 'max_leaves': 14, 'learning_rate': 0.005902481455333757, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=313 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=178 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=137 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=6 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=54 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=14 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 50 config: {'n_estimators': 1332, 'max_leaves': 2032, 'learning_rate': 0.005114224731719409, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 51 config: {'n_estimators': 584, 'max_leaves': 39, 'learning_rate': 0.4763308566342319, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 52 config: {'n_estimators': 394, 'max_leaves': 1349, 'learning_rate': 0.15573324989369033, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 53 config: {'n_estimators': 1137, 'max_leaves': 22, 'learning_rate': 0.30657057312024644, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 54 config: {'n_estimators': 2881, 'max_leaves': 19, 'learning_rate': 0.003592649684962099, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 55 config: {'n_estimators': 424, 'max_leaves': 11, 'learning_rate': 0.2826008095299387, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=2032 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=39 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1349 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=22 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=19 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=11 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 56 config: {'n_estimators': 7415, 'max_leaves': 9, 'learning_rate': 0.41144344654042997, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 57 config: {'n_estimators': 5525, 'max_leaves': 278, 'learning_rate': 0.9784854203265464, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 58 config: {'n_estimators': 2407, 'max_leaves': 257, 'learning_rate': 0.7924698570749448, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 59 config: {'n_estimators': 2586, 'max_leaves': 1133, 'learning_rate': 0.668218029499765, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=9 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=278 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=257 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1133 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 60 config: {'n_estimators': 5525, 'max_leaves': 443, 'learning_rate': 0.16378510208856667, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 61 config: {'n_estimators': 9220, 'max_leaves': 4, 'learning_rate': 0.36062762370731777, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 62 config: {'n_estimators': 13127, 'max_leaves': 2778, 'learning_rate': 0.00222017541525974, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=443 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=2778 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 63 config: {'n_estimators': 30, 'max_leaves': 1436, 'learning_rate': 0.0026028422881987055, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 64 config: {'n_estimators': 201, 'max_leaves': 475, 'learning_rate': 0.011324773041374265, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:17] {506} INFO - trial 65 config: {'n_estimators': 18941, 'max_leaves': 4223, 'learning_rate': 0.025865362181268114, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 66 config: {'n_estimators': 146, 'max_leaves': 4821, 'learning_rate': 0.0034154784329390535, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1436 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=475 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4223 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 67 config: {'n_estimators': 101, 'max_leaves': 7778, 'learning_rate': 0.052572695809586165, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 68 config: {'n_estimators': 275, 'max_leaves': 2819, 'learning_rate': 0.07081648034307593, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 69 config: {'n_estimators': 110, 'max_leaves': 65, 'learning_rate': 0.012107530127793, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 70 config: {'n_estimators': 73, 'max_leaves': 587, 'learning_rate': 0.008061889806716868, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 71 config: {'n_estimators': 12, 'max_leaves': 134, 'learning_rate': 0.009322413215086983, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 72 config: {'n_estimators': 216, 'max_leaves': 122, 'learning_rate': 0.020857393898663115, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4821 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=7778 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=2819 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=65 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=587 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=134 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=122 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 73 config: {'n_estimators': 312, 'max_leaves': 186, 'learning_rate': 0.014177007227519758, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 74 config: {'n_estimators': 1473, 'max_leaves': 20, 'learning_rate': 0.5282804782911118, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 75 config: {'n_estimators': 364, 'max_leaves': 23, 'learning_rate': 0.005958043358657801, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 76 config: {'n_estimators': 446, 'max_leaves': 43, 'learning_rate': 0.004775130134948399, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 77 config: {'n_estimators': 1219, 'max_leaves': 10, 'learning_rate': 0.3779589262687463, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 78 config: {'n_estimators': 1401, 'max_leaves': 10, 'learning_rate': 0.28038134184632646, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=186 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=20 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=23 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=43 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=10 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=10 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 79 config: {'n_estimators': 6628, 'max_leaves': 6, 'learning_rate': 0.47891449595724667, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 80 config: {'n_estimators': 8308, 'max_leaves': 30, 'learning_rate': 0.447042664449934, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 81 config: {'n_estimators': 2232, 'max_leaves': 302, 'learning_rate': 0.9413848630987627, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 82 config: {'n_estimators': 3008, 'max_leaves': 19, 'learning_rate': 0.6617776883804151, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=6 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=30 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=302 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=19 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 83 config: {'n_estimators': 4676, 'max_leaves': 831, 'learning_rate': 0.729098750582734, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 84 config: {'n_estimators': 9073, 'max_leaves': 7, 'learning_rate': 0.6999001097029152, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 85 config: {'n_estimators': 12097, 'max_leaves': 365, 'learning_rate': 0.23076401336141383, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=831 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=7 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=365 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:18] {506} INFO - trial 86 config: {'n_estimators': 6076, 'max_leaves': 15976, 'learning_rate': 0.3771793556881001, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 87 config: {'n_estimators': 4, 'max_leaves': 1072, 'learning_rate': 0.8133197504691136, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 88 config: {'n_estimators': 15851, 'max_leaves': 1532, 'learning_rate': 0.0026562675065994125, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=15976 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1072 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1532 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 89 config: {'n_estimators': 10539, 'max_leaves': 469, 'learning_rate': 0.0020422601196322786, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 90 config: {'n_estimators': 35, 'max_leaves': 2692, 'learning_rate': 0.0025090165260535893, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 91 config: {'n_estimators': 31, 'max_leaves': 3981, 'learning_rate': 0.0030253535104938114, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 92 config: {'n_estimators': 18188, 'max_leaves': 4341, 'learning_rate': 0.0013359200355607022, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=469 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=2692 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=3981 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4341 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 93 config: {'n_estimators': 115, 'max_leaves': 6603, 'learning_rate': 0.021098867037444867, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 94 config: {'n_estimators': 153, 'max_leaves': 5730, 'learning_rate': 0.12902679796448774, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 95 config: {'n_estimators': 109, 'max_leaves': 2582, 'learning_rate': 0.07080984320878844, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 96 config: {'n_estimators': 86, 'max_leaves': 8478, 'learning_rate': 0.038435592425912324, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 97 config: {'n_estimators': 59, 'max_leaves': 5035, 'learning_rate': 0.007798167307370056, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 98 config: {'n_estimators': 16, 'max_leaves': 10730, 'learning_rate': 0.009894614910177672, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 99 config: {'n_estimators': 131, 'max_leaves': 127, 'learning_rate': 0.015268661873095089, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=6603 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=5730 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=2582 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=8478 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=5035 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=10730 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=127 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 100 config: {'n_estimators': 211, 'max_leaves': 57, 'learning_rate': 0.019426510247163038, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 101 config: {'n_estimators': 282, 'max_leaves': 127, 'learning_rate': 0.013917381016486404, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 102 config: {'n_estimators': 82, 'max_leaves': 213, 'learning_rate': 0.03215891352653318, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 103 config: {'n_estimators': 298, 'max_leaves': 73, 'learning_rate': 0.008842202108353148, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 104 config: {'n_estimators': 232, 'max_leaves': 102, 'learning_rate': 0.0066980336616668445, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 105 config: {'n_estimators': 392, 'max_leaves': 45, 'learning_rate': 0.004550516087330994, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 106 config: {'n_estimators': 8, 'max_leaves': 28, 'learning_rate': 0.013639473182140692, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=57 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=127 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=213 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=73 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=102 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=45 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=28 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 107 config: {'n_estimators': 1308, 'max_leaves': 71, 'learning_rate': 0.0050708287994836255, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 108 config: {'n_estimators': 879, 'max_leaves': 41, 'learning_rate': 0.006461510915459239, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:19] {506} INFO - trial 109 config: {'n_estimators': 1642, 'max_leaves': 5, 'learning_rate': 0.009620046518012432, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 110 config: {'n_estimators': 759, 'max_leaves': 10, 'learning_rate': 0.5582224182204506, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 111 config: {'n_estimators': 528, 'max_leaves': 16, 'learning_rate': 0.47482418104411844, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 112 config: {'n_estimators': 2055, 'max_leaves': 28, 'learning_rate': 0.5549732420567667, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 113 config: {'n_estimators': 2169, 'max_leaves': 19, 'learning_rate': 0.5973102809665856, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=71 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=41 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=5 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=10 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=16 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=28 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=19 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 114 config: {'n_estimators': 4191, 'max_leaves': 29, 'learning_rate': 0.45841248810094576, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 115 config: {'n_estimators': 3067, 'max_leaves': 8, 'learning_rate': 0.6950226593911881, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 116 config: {'n_estimators': 6417, 'max_leaves': 6, 'learning_rate': 0.8645386073451609, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 117 config: {'n_estimators': 8474, 'max_leaves': 5, 'learning_rate': 0.24803611166147882, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=29 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=8 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=6 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=5 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 118 config: {'n_estimators': 4634, 'max_leaves': 321, 'learning_rate': 0.34666942819830854, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 119 config: {'n_estimators': 6910, 'max_leaves': 1005, 'learning_rate': 0.38785398836958446, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 120 config: {'n_estimators': 3199, 'max_leaves': 6, 'learning_rate': 0.75166286138699, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 121 config: {'n_estimators': 11147, 'max_leaves': 23703, 'learning_rate': 0.6564634512210011, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=321 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1005 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=6 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=23703 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 122 config: {'n_estimators': 15171, 'max_leaves': 851, 'learning_rate': 0.9749384452988281, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 123 config: {'n_estimators': 9592, 'max_leaves': 382, 'learning_rate': 0.8134403889913343, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 124 config: {'n_estimators': 11708, 'max_leaves': 1687, 'learning_rate': 0.0022641547592865186, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=851 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=382 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1687 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:20] {506} INFO - trial 125 config: {'n_estimators': 29155, 'max_leaves': 653, 'learning_rate': 0.0009770550865846573, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 126 config: {'n_estimators': 22500, 'max_leaves': 2035, 'learning_rate': 0.00153183685334048, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=653 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=2035 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 127 config: {'n_estimators': 29, 'max_leaves': 16840, 'learning_rate': 0.001964529732491673, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 128 config: {'n_estimators': 4, 'max_leaves': 3882, 'learning_rate': 0.001284644752246744, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 129 config: {'n_estimators': 22968, 'max_leaves': 6645, 'learning_rate': 0.21111485149822817, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 130 config: {'n_estimators': 15982, 'max_leaves': 5815, 'learning_rate': 0.12860984198671235, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=16840 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=3882 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=6645 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=5815 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 131 config: {'n_estimators': 44, 'max_leaves': 2998, 'learning_rate': 0.0030200234940365236, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 132 config: {'n_estimators': 39, 'max_leaves': 9202, 'learning_rate': 0.0811019584239895, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 133 config: {'n_estimators': 60, 'max_leaves': 5666, 'learning_rate': 0.004007829946037066, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 134 config: {'n_estimators': 20, 'max_leaves': 11870, 'learning_rate': 0.0027344474841943514, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 135 config: {'n_estimators': 153, 'max_leaves': 3318, 'learning_rate': 0.045335813727047994, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 136 config: {'n_estimators': 126, 'max_leaves': 4537, 'learning_rate': 0.0025274530893320225, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 137 config: {'n_estimators': 82, 'max_leaves': 2232, 'learning_rate': 0.035753038394389515, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 138 config: {'n_estimators': 167, 'max_leaves': 8771, 'learning_rate': 0.02146693016567059, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 139 config: {'n_estimators': 85, 'max_leaves': 5015, 'learning_rate': 0.01836949217228744, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=2998 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=9202 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=5666 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=11870 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=3318 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4537 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=2232 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=8771 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=5015 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 140 config: {'n_estimators': 55, 'max_leaves': 221, 'learning_rate': 0.02957686754386779, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 141 config: {'n_estimators': 110, 'max_leaves': 148, 'learning_rate': 0.015375135067511985, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 142 config: {'n_estimators': 230, 'max_leaves': 77, 'learning_rate': 0.009844835271589789, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 143 config: {'n_estimators': 238, 'max_leaves': 93, 'learning_rate': 0.0073902998306187104, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 144 config: {'n_estimators': 138, 'max_leaves': 52, 'learning_rate': 0.019378392365890264, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 145 config: {'n_estimators': 9, 'max_leaves': 113, 'learning_rate': 0.013815871105396057, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 146 config: {'n_estimators': 181, 'max_leaves': 11664, 'learning_rate': 0.0052156503794167225, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 147 config: {'n_estimators': 343, 'max_leaves': 43, 'learning_rate': 0.006936450889135225, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 148 config: {'n_estimators': 6, 'max_leaves': 56, 'learning_rate': 0.012493396501243509, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=221 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=148 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=77 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=93 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=52 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=113 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=11664 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=43 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=56 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 149 config: {'n_estimators': 1648, 'max_leaves': 149, 'learning_rate': 0.010012277560594009, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 150 config: {'n_estimators': 821, 'max_leaves': 35, 'learning_rate': 0.009159978735267736, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 151 config: {'n_estimators': 526, 'max_leaves': 16, 'learning_rate': 0.008275920668378171, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 152 config: {'n_estimators': 816, 'max_leaves': 74, 'learning_rate': 0.006482067494868841, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:21] {506} INFO - trial 153 config: {'n_estimators': 1044, 'max_leaves': 99, 'learning_rate': 0.004397862236362672, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 154 config: {'n_estimators': 2148, 'max_leaves': 28, 'learning_rate': 0.005388498250955563, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 155 config: {'n_estimators': 464, 'max_leaves': 30, 'learning_rate': 0.4883386107761221, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 156 config: {'n_estimators': 637, 'max_leaves': 27, 'learning_rate': 0.6009989664388208, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=149 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=35 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=16 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=74 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=99 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=28 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=30 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 157 config: {'n_estimators': 1860, 'max_leaves': 15, 'learning_rate': 0.5409959333947137, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 158 config: {'n_estimators': 3492, 'max_leaves': 8, 'learning_rate': 0.5630385099257847, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 159 config: {'n_estimators': 4170, 'max_leaves': 5, 'learning_rate': 0.006205352481265516, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 160 config: {'n_estimators': 1349, 'max_leaves': 5, 'learning_rate': 0.004656096935804429, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 161 config: {'n_estimators': 2490, 'max_leaves': 12, 'learning_rate': 0.3501975907340783, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=27 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=15 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=8 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=5 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=5 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=12 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 162 config: {'n_estimators': 5056, 'max_leaves': 47, 'learning_rate': 0.0037448469596170035, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 163 config: {'n_estimators': 7706, 'max_leaves': 8, 'learning_rate': 0.4262802620058607, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 164 config: {'n_estimators': 3220, 'max_leaves': 5, 'learning_rate': 0.40615361388208804, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 165 config: {'n_estimators': 6878, 'max_leaves': 4, 'learning_rate': 0.6151997433753406, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=47 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=8 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=5 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 166 config: {'n_estimators': 4306, 'max_leaves': 17, 'learning_rate': 0.8844710716095144, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 167 config: {'n_estimators': 2898, 'max_leaves': 362, 'learning_rate': 0.7565061224429761, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 168 config: {'n_estimators': 10255, 'max_leaves': 22, 'learning_rate': 0.6688521012095087, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 169 config: {'n_estimators': 12928, 'max_leaves': 6, 'learning_rate': 0.8920365358541912, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=17 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=362 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=22 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=6 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 170 config: {'n_estimators': 5754, 'max_leaves': 830, 'learning_rate': 0.3053831719008097, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 171 config: {'n_estimators': 10672, 'max_leaves': 596, 'learning_rate': 0.9904703098611144, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:22] {506} INFO - trial 172 config: {'n_estimators': 28948, 'max_leaves': 644, 'learning_rate': 0.0010021800865329749, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=830 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=596 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=644 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:23] {506} INFO - trial 173 config: {'n_estimators': 22018, 'max_leaves': 27846, 'learning_rate': 0.001520413461764809, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:23] {506} INFO - trial 174 config: {'n_estimators': 31314, 'max_leaves': 1677, 'learning_rate': 0.0013007529098430645, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=27846 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1677 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:23] {506} INFO - trial 175 config: {'n_estimators': 23789, 'max_leaves': 19038, 'learning_rate': 0.24245421132864492, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:23] {506} INFO - trial 176 config: {'n_estimators': 8483, 'max_leaves': 1016, 'learning_rate': 0.0016595298283853261, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=19038 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1016 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:23] {506} INFO - trial 177 config: {'n_estimators': 15895, 'max_leaves': 1863, 'learning_rate': 0.001292415677672366, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:23] {506} INFO - trial 178 config: {'n_estimators': 19283, 'max_leaves': 1124, 'learning_rate': 0.21009062955579472, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1863 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1124 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:23] {506} INFO - trial 179 config: {'n_estimators': 15077, 'max_leaves': 4, 'learning_rate': 0.001116720666995303, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:23] {506} INFO - trial 180 config: {'n_estimators': 25744, 'max_leaves': 3066, 'learning_rate': 0.13462790568725672, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=3066 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:24] {506} INFO - trial 181 config: {'n_estimators': 14379, 'max_leaves': 21532, 'learning_rate': 0.11249756313060533, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:24] {506} INFO - trial 182 config: {'n_estimators': 43, 'max_leaves': 6487, 'learning_rate': 0.17296950883370182, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:24] {506} INFO - trial 183 config: {'n_estimators': 22, 'max_leaves': 7280, 'learning_rate': 0.258852421157622, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:24] {506} INFO - trial 184 config: {'n_estimators': 45, 'max_leaves': 3571, 'learning_rate': 0.08732512289838663, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:24] {506} INFO - trial 185 config: {'n_estimators': 30, 'max_leaves': 14583, 'learning_rate': 0.002891946623707599, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:24] {506} INFO - trial 186 config: {'n_estimators': 25, 'max_leaves': 3464, 'learning_rate': 0.002358433026191249, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=21532 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=6487 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=7280 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=3571 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=14583 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=3464 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:24] {506} INFO - trial 187 config: {'n_estimators': 66, 'max_leaves': 10033, 'learning_rate': 0.001881199853774848, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:24] {506} INFO - trial 188 config: {'n_estimators': 45, 'max_leaves': 2290, 'learning_rate': 0.0032255721973679058, 'sample_size': 1000}\n",
      "[flaml.tune.tune: 07-07 04:19:24] {506} INFO - trial 189 config: {'n_estimators': 21382, 'max_leaves': 2208, 'learning_rate': 0.04681316555326558, 'sample_size': 1000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=10033 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=2290 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=2208 will be ignored. Current value: num_leaves=31\n",
      "best result w/ flaml scheduler (in 10s):  {'loss': 0.2393039918116684, 'training_iteration': 0, 'config': {'n_estimators': 9, 'max_leaves': 1364, 'learning_rate': 0.012074374674294664, 'sample_size': 1000}, 'config/n_estimators': 9, 'config/max_leaves': 1364, 'config/learning_rate': 0.012074374674294664, 'config/sample_size': 1000, 'experiment_tag': 'exp', 'time_total_s': 0.022912979125976562}\n"
     ]
    }
   ],
   "source": [
    "from flaml import tune\n",
    "from functools import partial\n",
    "from flaml.data import load_openml_task\n",
    "    \n",
    "X_train, X_test, y_train, y_test = load_openml_task(task_id=7592, data_dir=\"\")\n",
    "max_resource = len(y_train)\n",
    "resource_attr = \"sample_size\"\n",
    "min_resource = 1000\n",
    "analysis = tune.run(\n",
    "    partial(\n",
    "        obj_from_resource_attr, resource_attr, X_train, X_test, y_train, y_test\n",
    "    ),\n",
    "    config=search_space,\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    resource_attr=resource_attr,\n",
    "    scheduler=\"flaml\",\n",
    "    max_resource=max_resource,\n",
    "    min_resource=min_resource,\n",
    "    reduction_factor=2,\n",
    "    time_budget_s=10,\n",
    "    num_samples=-1,\n",
    ")\n",
    "print(\"best result w/ flaml scheduler (in 10s): \", analysis.best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ASHA scheduler (`scheduler='asha'`) or a custom scheduler of the  [`TrialScheduler`](https://docs.ray.io/en/latest/tune/api_docs/schedulers.html#tune-schedulers) class from `ray.tune`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_w_intermediate_report(\n",
    "        resource_attr,\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        min_resource,\n",
    "        max_resource,\n",
    "        config,\n",
    "    ):\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # a customized schedule to perform the evaluation\n",
    "    eval_schedule = [res for res in range(min_resource, max_resource, 5000)] + [\n",
    "        max_resource\n",
    "    ]\n",
    "    for resource in eval_schedule:\n",
    "        sampled_X_train = X_train.iloc[:resource]\n",
    "        sampled_y_train = y_train[:resource]\n",
    "\n",
    "        # construct a LGBM model from the config\n",
    "        model = LGBMClassifier(**config)\n",
    "\n",
    "        model.fit(sampled_X_train, sampled_y_train)\n",
    "        y_test_predict = model.predict(X_test)\n",
    "        test_loss = 1.0 - accuracy_score(y_test, y_test_predict)\n",
    "        # need to report the resource attribute used and the corresponding intermediate results\n",
    "        try:\n",
    "            tune.report(sample_size=resource, loss=test_loss)\n",
    "        except StopIteration:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 04:19:32,319\tWARNING optuna.py:297 -- You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2022-07-07 04:19:32,321]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "[flaml.tune.tune: 07-07 04:19:32] {506} INFO - trial 1 config: {'n_estimators': 9, 'max_leaves': 1364, 'learning_rate': 0.012074374674294664}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset from openml_task7592.pkl\n",
      "X_train.shape: (43957, 14), y_train.shape: (43957,),\n",
      "X_test.shape: (4885, 14), y_test.shape: (4885,)\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1364 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1364 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1364 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1364 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1364 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1364 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1364 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1364 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1364 will be ignored. Current value: num_leaves=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 07-07 04:19:33] {506} INFO - trial 2 config: {'n_estimators': 4048, 'max_leaves': 4, 'learning_rate': 0.07891713267442702}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=1364 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "[LightGBM] [Warning] num_leaves is set=31, max_leaves=4 will be ignored. Current value: num_leaves=31\n",
      "best result w/ asha scheduler (in 10s):  {'sample_size': 43957, 'loss': 0.13920163766632554, 'training_iteration': 9, 'config': {'n_estimators': 4048, 'max_leaves': 4, 'learning_rate': 0.07891713267442702}, 'config/n_estimators': 4048, 'config/max_leaves': 4, 'config/learning_rate': 0.07891713267442702, 'experiment_tag': 'exp', 'time_total_s': 66.68751931190491}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = load_openml_task(task_id=7592, data_dir=\"\")\n",
    "resource_attr = \"sample_size\"\n",
    "min_resource = 1000\n",
    "max_resource = len(y_train)\n",
    "analysis = tune.run(\n",
    "    partial(\n",
    "        obj_w_intermediate_report,\n",
    "        resource_attr,\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        min_resource,\n",
    "        max_resource,\n",
    "    ),\n",
    "    config=search_space,\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    resource_attr=resource_attr,\n",
    "    scheduler=\"asha\",\n",
    "    max_resource=max_resource,\n",
    "    min_resource=min_resource,\n",
    "    reduction_factor=2,\n",
    "    time_budget_s=10,\n",
    "    num_samples=-1,\n",
    ")\n",
    "print(\"best result w/ asha scheduler (in 10s): \", analysis.best_result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61dacc07bdd67a6bd133ad154042152699ffea5858044733f84b495e7a4b9e6a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('myflaml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
