{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune neural networks \n",
    "This example is to tune neural networks model. \n",
    "\n",
    "**Requirements.** This notebook requires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch torchvision flaml[blendsearch,ray] thop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import thop\n",
    "import torch.nn as nn\n",
    "from flaml import tune\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
    "data_dir = os.path.abspath(\"data\")\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    data_dir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(train_dataset, list(range(N_TRAIN_EXAMPLES))),\n",
    "    batch_size=BATCHSIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_dataset = torchvision.datasets.FashionMNIST(\n",
    "    data_dir, train=False, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.Subset(val_dataset, list(range(N_VALID_EXAMPLES))),\n",
    "    batch_size=BATCHSIZE,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(configuration):\n",
    "    n_layers = configuration[\"n_layers\"]\n",
    "    layers = []\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = configuration[\"n_units_l{}\".format(i)]\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = configuration[\"dropout_{}\".format(i)]\n",
    "        layers.append(nn.Dropout(p))\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, 10))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        F.nll_loss(model(data), target).backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, valid_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    import time\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "            data, target = data.view(-1, 28 * 28).to(DEVICE), target.to(DEVICE)\n",
    "            pred = model(data).argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    avg_batch_pred_time = (time.time() - start) / len(valid_loader)\n",
    "\n",
    "    accuracy = correct / N_VALID_EXAMPLES\n",
    "    flops, params = thop.profile(\n",
    "        model, inputs=(torch.randn(1, 28 * 28).to(DEVICE),), verbose=False\n",
    "    )\n",
    "    return np.log2(flops), 1 - accuracy, params, avg_batch_pred_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_function(configuration):\n",
    "    model = define_model(configuration).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), configuration[\"lr\"])\n",
    "    n_epoch = configuration[\"n_epoch\"]\n",
    "    for epoch in range(n_epoch):\n",
    "        train_model(model, optimizer, train_loader)\n",
    "    flops, error_rate, params, avg_batch_pred_time = eval_model(model, val_loader)\n",
    "    return {\"error_rate\": error_rate, \"flops\": flops, \"params\": params, \"avg_batch_pred_time\": avg_batch_pred_time}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"n_layers\": tune.randint(lower=1, upper=3),\n",
    "    \"n_units_l0\": tune.randint(lower=4, upper=128),\n",
    "    \"n_units_l1\": tune.randint(lower=4, upper=128),\n",
    "    \"n_units_l2\": tune.randint(lower=4, upper=128),\n",
    "    \"dropout_0\": tune.uniform(lower=0.2, upper=0.5),\n",
    "    \"dropout_1\": tune.uniform(lower=0.2, upper=0.5),\n",
    "    \"dropout_2\": tune.uniform(lower=0.2, upper=0.5),\n",
    "    \"lr\": tune.loguniform(lower=1e-5, upper=1e-1),\n",
    "    \"n_epoch\": tune.randint(lower=1, upper=20),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "\u001b[32m[I 2023-01-08 10:37:37,596]\u001b[0m A new study created in memory with name: optuna\u001b[0m\n",
      "2023-01-08 10:37:41,817\tWARNING function_runner.py:603 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "2023-01-08 10:37:43,628\tWARNING tune.py:668 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n",
      "2023-01-08 10:37:46,222\tWARNING worker.py:1404 -- Warning: The actor ImplicitFunc is very large (52 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2023-01-08 10:37:50 (running for 00:00:07.31)<br>Memory usage on this node: 49.7/503.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/48 CPUs, 0/4 GPUs, 0.0/312.8 GiB heap, 0.0/138.05 GiB objects (0.0/1.0 accelerator_type:RTX)<br>Result logdir: /home/qxw5138/ray_results/evaluate_function_2023-01-08_10-37-42<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial evaluate_function_89f95f20 reported error_rate=0.79 with parameters={'n_layers': 1, 'n_units_l0': 4, 'n_units_l1': 4, 'n_units_l2': 4, 'n_epoch': 1, 'dropout_0': 0.22922962186368476, 'dropout_1': 0.3941798243996576, 'dropout_2': 0.3088427685434228, 'lr': 0.00029828938661167917}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2023-01-08 10:37:51 (running for 00:00:07.93)<br>Memory usage on this node: 49.7/503.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/48 CPUs, 0/4 GPUs, 0.0/312.8 GiB heap, 0.0/138.05 GiB objects (0.0/1.0 accelerator_type:RTX)<br>Current best trial: 89f95f20 with error_rate=0.79375 and parameters={'n_layers': 1, 'n_units_l0': 4, 'n_units_l1': 4, 'n_units_l2': 4, 'n_epoch': 1, 'dropout_0': 0.22922962186368476, 'dropout_1': 0.3941798243996576, 'dropout_2': 0.3088427685434228, 'lr': 0.00029828938661167917}<br>Result logdir: /home/qxw5138/ray_results/evaluate_function_2023-01-08_10-37-42<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial evaluate_function_89f95f20 completed. Last result: error_rate=0.79375,flops=11.632995197142957,params=3190.0,avg_batch_pred_time=0.013302230834960937\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2023-01-08 10:37:51 (running for 00:00:07.95)<br>Memory usage on this node: 49.7/503.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/48 CPUs, 0/4 GPUs, 0.0/312.8 GiB heap, 0.0/138.05 GiB objects (0.0/1.0 accelerator_type:RTX)<br>Current best trial: 89f95f20 with error_rate=0.79375 and parameters={'n_layers': 1, 'n_units_l0': 4, 'n_units_l1': 4, 'n_units_l2': 4, 'n_epoch': 1, 'dropout_0': 0.22922962186368476, 'dropout_1': 0.3941798243996576, 'dropout_2': 0.3088427685434228, 'lr': 0.00029828938661167917}<br>Result logdir: /home/qxw5138/ray_results/evaluate_function_2023-01-08_10-37-42<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status    </th><th>loc                    </th><th style=\"text-align: right;\">  dropout_0</th><th style=\"text-align: right;\">  dropout_1</th><th style=\"text-align: right;\">  dropout_2</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  n_epoch</th><th style=\"text-align: right;\">  n_layers</th><th style=\"text-align: right;\">  n_units_l0</th><th style=\"text-align: right;\">  n_units_l1</th><th style=\"text-align: right;\">  n_units_l2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  error_rate</th><th style=\"text-align: right;\">  flops</th><th style=\"text-align: right;\">  params</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>evaluate_function_89f95f20</td><td>TERMINATED</td><td>130.203.136.143:1366904</td><td style=\"text-align: right;\">    0.22923</td><td style=\"text-align: right;\">    0.39418</td><td style=\"text-align: right;\">   0.308843</td><td style=\"text-align: right;\">0.000298289</td><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">         1</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.607912</td><td style=\"text-align: right;\">     0.79375</td><td style=\"text-align: right;\"> 11.633</td><td style=\"text-align: right;\">    3190</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 10:37:51,683\tINFO tune.py:747 -- Total run time: 9.87 seconds (7.94 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error_rate': 0.79375, 'flops': 11.632995197142957, 'params': 3190.0, 'avg_batch_pred_time': 0.013302230834960937, 'time_this_iter_s': 0.6079120635986328, 'done': True, 'timesteps_total': None, 'episodes_total': None, 'training_iteration': 1, 'trial_id': '89f95f20', 'experiment_id': 'ec552f15cd404633a7a916e39c2847f0', 'date': '2023-01-08_10-37-51', 'timestamp': 1673203071, 'time_total_s': 0.6079120635986328, 'pid': 1366904, 'hostname': 'i4-l-qxw5138-01.ad.psu.edu', 'node_ip': '130.203.136.143', 'config': {'n_layers': 1, 'n_units_l0': 4, 'n_units_l1': 4, 'n_units_l2': 4, 'n_epoch': 1, 'dropout_0': 0.22922962186368476, 'dropout_1': 0.3941798243996576, 'dropout_2': 0.3088427685434228, 'lr': 0.00029828938661167917}, 'time_since_restore': 0.6079120635986328, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'warmup_time': 0.00460052490234375, 'experiment_tag': '1_dropout_0=0.2292,dropout_1=0.3942,dropout_2=0.3088,lr=0.0003,n_epoch=1,n_layers=1,n_units_l0=4,n_units_l1=4,n_units_l2=4'}\n"
     ]
    }
   ],
   "source": [
    "low_cost_partial_config = {\n",
    "    \"n_layers\": 1,\n",
    "    \"n_units_l0\": 4,\n",
    "    \"n_units_l1\": 4,\n",
    "    \"n_units_l2\": 4,\n",
    "    \"n_epoch\": 1,\n",
    "}\n",
    "\n",
    "pred_time_constraints = [('avg_batch_pred_time', \"<=\", 1)]\n",
    "analysis = tune.run(\n",
    "    evaluate_function,\n",
    "    metric=\"error_rate\",\n",
    "    mode=\"min\",\n",
    "    time_budget_s=100,\n",
    "    config=search_space,\n",
    "    low_cost_partial_config=low_cost_partial_config, # provide low cost initial config for cost related hyperparameters\n",
    "    metric_constraints = pred_time_constraints, # add constratints on one or more of the metrics: here adding a constraint on the avg predict time per batch\n",
    "    use_ray=True,  # using ray as the backend to do parallel tuning\n",
    "    resources_per_trial={\"cpu\": 2},\n",
    ")\n",
    "result = analysis.best_result\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
